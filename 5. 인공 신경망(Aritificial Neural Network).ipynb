{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled6.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyP2sDvJEjJhB6gT8FBokMQm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Namsik-Yoon/pytorch_basic/blob/master/5.%20%EC%9D%B8%EA%B3%B5%20%EC%8B%A0%EA%B2%BD%EB%A7%9D(Aritificial%20Neural%20Network).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XowNT8gGlf0G",
        "colab_type": "text"
      },
      "source": [
        "# 5. 인공 신경망(Aritificial Neural Network)\n",
        "\n",
        "이번 챕터에서는 인공 신경망에 대한 전반적인 개념을 이해합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hC3vwDKzlk16",
        "colab_type": "text"
      },
      "source": [
        "## 5.1 머신 러닝 용어 이해하기\n",
        "\n",
        "이번 챕터에서는 머신 러닝의 특징들에 대해서 배웁니다. 딥 러닝 또한 머신 러닝에 속하므로, 아래의 머신 러닝의 특징들은 모두 딥 러닝의 특징이기도 합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtPa4zdIloqR",
        "colab_type": "text"
      },
      "source": [
        "### 5.1.1 머신 러닝 모델의 평가\n",
        "\n",
        "![대체 텍스트](https://wikidocs.net/images/page/24987/%EB%8D%B0%EC%9D%B4%ED%84%B0.PNG)\n",
        "\n",
        "실제 모델을 평가하기 위해서 데이터를 훈련용, 검증용, 테스트용 이렇게 세 가지로 분리하는 것이 일반적입니다. 다만, 이 책의 목적은 개념 학습이므로 일부 실습에서는 별도로 세 가지로 분리하지 않고 훈련용, 테스트용으로만 분리해서 사용합니다. 그렇다면 훈련용, 테스트용 두 가지로만 나눠서 테스트 데이터로 한 번만 테스트하면 더 편할텐데 굳이 왜 검증용 데이터를 만들어 놓는 것일까요?\n",
        "\n",
        "검증용 데이터는 모델의 성능을 평가하기 위한 용도가 아니라, 모델의 성능을 조정하기 위한 용도입니다. 더 정확히는 과적합이 되고 있는지 판단하거나 하이퍼파라미터의 조정을 위한 용도입니다. 하이퍼파라미터(초매개변수)란 값에 따라서 모델의 성능에 영향을 주는 매개변수들을 말합니다. 반면, 가중치와 편향과 같은 학습을 통해 바뀌어져가는 변수를 이 책에서는 매개변수라고 부릅니다.\n",
        "\n",
        "이 두 값 하이퍼파라미터와 매개변수의 가장 큰 차이는 하이퍼파라미터는 보통 사용자가 직접 정해줄 수 있는 변수라는 점입니다. 선형 회귀 챕터에서 배우게 되는 경사 하강법에서 학습률(learning rate)이 이에 해당되며 딥 러닝에서는 은닉층의 수, 뉴런의 수, 드롭아웃 비율 등이 이에 해당됩니다. 반면 매개변수는 사용자가 결정해주는 값이 아니라 모델이 학습하는 과정에서 얻어지는 값입니다. 정리하면 하이퍼파라미터는 사람이 정하는 변수인 반면, 매개변수는 기계가 훈련을 통해서 바꾸는 변수라고 할 수 있으며 이 책에서는 이와 같은 기준으로 변수의 이름을 명명합니다.\n",
        "\n",
        "훈련용 데이터로 훈련을 모두 시킨 모델은 검증용 데이터를 사용하여 정확도를 검증하며 하이퍼파라미터를 튜닝(tuning)합니다. 또한 이 모델의 매개변수는 검증용 데이터로 정확도가 검증되는 과정에서 점차 검증용 데이터에 점점 맞추어져 가기 시작합니다.\n",
        "\n",
        "하이퍼파라미터 튜닝이 끝났다면, 이제 검증용 데이터로 모델을 평가하는 것은 적합하지 않습니다. 이제 모델은 검증용 데이터에 대해서도 일정 부분 최적화가 되어있기 때문입니다. 모델에 대한 평가는 모델이 아직까지 보지 못한 데이터로 하는 것이 가장 바람직합니다. 검증이 끝났다면 테스트 데이터를 가지고 모델의 진짜 성능을 평가합니다. 비유하자면 훈련 데이터는 문제지, 검증 데이터는 모의고사, 테스트 데이터는 실력을 최종적으로 평가하는 수능 시험이라고 볼 수 있습니다.\n",
        "\n",
        "만약, 검증 데이터와 테스트 데이터를 나눌 만큼 데이터가 충분하지 않다면 k-폴드 교차 검증이라는 또 다른 방법을 사용하기도 합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fomti3I6mDnx",
        "colab_type": "text"
      },
      "source": [
        "### 5.1.2 분류(Classification)와 회귀(Regression)\n",
        "\n",
        "전부라고는 할 수 없지만, 머신 러닝의 많은 문제는 분류 또는 회귀 문제에 속합니다. 이 책에서는 앞서 머신 러닝 기법 중 선형 회귀(Lineare Regression)과 로지스틱 회귀(Logistic Rgression)를 다루는데 선형 회귀를 통해 회귀 문제에 대해서 학습하고, 로지스틱 회귀를 통해 (이름은 회귀이지만) 분류 문제를 학습합니다.\n",
        "\n",
        "분류는 또한 이진 분류(Binary Classification)과 다중 클래스 분류(Multi-Class Classification)로 나뉩니다. 엄밀히는 다중 레이블 분류(Multi-lable Classification)라는 또 다른 문제가 존재하지만, 이 책에서는 이진 분류와 다중 클래스 분류만 다룹니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKFl9hVVmHTo",
        "colab_type": "text"
      },
      "source": [
        "1) 이진 분류 문제(Binary Classification)\n",
        "\n",
        "이진 분류는 주어진 입력에 대해서 둘 중 하나의 답을 정하는 문제입니다. 시험 성적에 대해서 합격, 불합격인지 판단하고 메일로부터 정상 메일, 스팸 메일인지를 판단하는 문제 등이 이에 속합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKIFoE6WmLSN",
        "colab_type": "text"
      },
      "source": [
        "2) 다중 클래스 분류(Multi-class Classification)\n",
        "\n",
        "다중 클래스 분류는 주어진 입력에 대해서 세 개 이상의 정해진 선택지 중에서 답을 정하는 문제입니다. 예를 들어 서점 아르바이트를 하는데 과학, 영어, IT, 학습지, 만화라는 레이블이 각각 붙여져 있는 5개의 책장이 있다고 합시다. 새 책이 입고되면, 이 책은 다섯 개의 책장 중에서 분야에 맞는 적절한 책장에 책을 넣어야 합니다. 이 때의 다섯 개의 선택지를 주로 카테고리 또는 범주 또는 클래스라고 하며, 주어진 입력으로부터 정해진 클래스 중 하나로 판단하는 것을 다중 클래스 분류 문제라고 합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozhBVPzXmOiT",
        "colab_type": "text"
      },
      "source": [
        "3) 회귀 문제(Regression)\n",
        "\n",
        "회귀 문제는 분류 문제처럼 0 또는 1이나 과학 책장, IT 책장 등과 같이 분리된(비연속적인) 답이 결과가 아니라 연속된 값을 결과로 가집니다. 예를 들어 시험 성적을 예측하는데 5시간 공부하였을 때 80점, 5시간 1분 공부하였을 때는 80.5점, 7시간 공부하였을 때는 90점 등이 나오는 것과 같은 문제가 있습니다. 그 외에도 시계열 데이터를 이용한 주가 예측, 생산량 예측, 지수 예측 등이 이에 속합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLCk7vytmRst",
        "colab_type": "text"
      },
      "source": [
        "### 5.1.3 지도 학습(Supervised Learning)과 비지도 학습(Unsupervised Learning)\n",
        "\n",
        "머신 러닝은 크게 지도 학습, 비지도 학습, 강화 학습으로 나눕니다. 하지만 강화 학습은 이 책의 범위를 벗어나므로 설명하지 않습니다. 또한 이 책은 주로 지도 학습에 대해서 다룹니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9efw-RHmVMC",
        "colab_type": "text"
      },
      "source": [
        "1) 지도 학습\n",
        "\n",
        "지도 학습이란 레이블(Label)이라는 정답과 함께 학습하는 것을 말합니다. 이는 앞서 2챕터의 데이터의 분리 챕터에서 상세히 설명한 바 있습니다. 레이블이라는 말 외에도 $y$, 실제값 등으로 부르기도 하는데 이 책에서는 이 용어들을 상황에 따라서 바꿔서 사용합니다.\n",
        "\n",
        "이때 기계는 예측값과 실제값의 차이인 오차를 줄이는 방식으로 학습을 하게 되는데 예측값은 $\\hat{y}$과 같이 표현하기도 합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygQzte8UmdeP",
        "colab_type": "text"
      },
      "source": [
        "2) 비지도 학습\n",
        "\n",
        "비지도 학습은 기본적으로 목적 데이터(또는 레이블)이 없는 학습 방법입니다. 대표적으로 군집(clustering)이나 차원 축소와 같은 학습 방법들을 비지도 학습이라고 합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ItQkBNwumiqR",
        "colab_type": "text"
      },
      "source": [
        "3) 강화 학습\n",
        "\n",
        "강화 학습은 이 책에서는 다루지 않는 내용입니다. 강화 학습은 어떤 환경 내에서 정의된 에이전트가 현재의 상태를 인식하여, 선택 가능한 행동들 중 보상을 최대화하는 행동 혹은 행동 순서를 선택하는 방법입니다. (출처 : 위키 백과)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFID5Myzmlie",
        "colab_type": "text"
      },
      "source": [
        "### 5.1.4 샘플(Sample)과 특성(Feature)\n",
        "\n",
        "많은 머신 러닝 문제가 1개 이상의 독립 변수 $x$를 가지고 종속 변수 $y$를 예측하는 문제입니다. 많은 머신 러닝 모델들, 특히 인공 신경망 모델은 독립 변수, 종속 변수, 가중치, 편향 등을 행렬 연산을 통해 연산하는 경우가 많습니다. 그래서 앞으로 인공 신경망을 배우게되면 훈련 데이터를 행렬로 표현하는 경우를 많이 보게 될 겁니다. 독립 변수 $x$의 행렬을 X라고 하였을 때, 독립 변수의 개수가 n개이고 데이터의 개수가 m인 행렬 X는 다음과 같습니다.\n",
        "\n",
        "![대체 텍스트](https://wikidocs.net/images/page/35821/n_x_m.PNG)\n",
        "\n",
        "## 이때 머신 러닝에서는 하나의 데이터, 하나의 행을 샘플(Sample)이라고 부릅니다. (데이터베이스에서는 레코드라고 부르는 단위입니다.) 종속 변수 $y$를 예측하기 위한 각각의 독립 변수 $x$를 특성(Feature)이라고 부릅니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4PvDOPemzEa",
        "colab_type": "text"
      },
      "source": [
        "### 5.1.5 혼동 행렬(Confusion Matrix)\n",
        "\n",
        "머신 러닝에서는 맞춘 문제수를 전체 문제수로 나눈 값을 정확도(Accuracy)라고 합니다. 하지만 정확도는 맞춘 결과와 틀린 결과에 대한 세부적인 내용을 알려주지는 않습니다. 이를 위해서 사용하는 것이 혼동 행렬(Confusion Matrix)입니다.\n",
        "\n",
        "예를 들어 양성(Positive)과 음성(Negative)을 구분하는 이진 분류가 있다고 하였을 때 혼동 행렬은 다음과 같습니다. 각 열은 예측값을 나타내며, 각 행은 실제값을 나타냅니다.\n",
        "\n",
        "|-|참|거짓|\n",
        "|---|---|---|\n",
        "|참|TP|FN|\n",
        "|거짓|FP|TN|\n",
        "\n",
        "이를 각각 TP(True Positive), TN(True Negative), FP(False Postivie), FN(False Negative)라고 하는데 True는 정답을 맞춘 경우고 False는 정답을 맞추지 못한 경우입니다. 그리고 Positive와 Negative는 각각 제시했던 정답입니다. 즉, TP는 양성(Postive)이라고 대답하였고 실제로 양성이라서 정답을 맞춘 경우입니다. TN은 음성(Negative)이라고 대답하였는데 실제로 음성이라서 정답을 맞춘 경우입니다.\n",
        "\n",
        "그럼 FP는 양성이라고 대답하였는데, 음성이라서 정답을 틀린 경우이며 FN은 음성이라고 대답하였는데 양성이라서 정답을 틀린 경우가 됩니다. 그리고 이 개념을 사용하면 또 새로운 개념인 정밀도(Precision)과 재현률(Recall)이 됩니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SELLU4JnUIB",
        "colab_type": "text"
      },
      "source": [
        "1) 정밀도(Precision)\n",
        "정밀도은 양성이라고 대답한 전체 케이스에 대한 TP의 비율입니다. 즉, 정밀도를 수식으로 표현하면 다음과 같습니다.\n",
        "\n",
        "정밀도 = $\\frac{TP}{TP + FP}$\n",
        "\n",
        "2) 재현률(Recall)\n",
        "재현률은 실제값이 양성인 데이터의 전체 개수에 대해서 TP의 비율입니다. 즉, 양성인 데이터 중에서 얼마나 양성인지를 예측(재현)했는지를 나타냅니다.\n",
        "\n",
        "재현률 = $\\frac{TP}{TP + FN}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JeyP99eEndpe",
        "colab_type": "text"
      },
      "source": [
        "### 5.1.6 과적합(Overfitting)과 과소 적합(Underfitting)\n",
        "\n",
        "학생의 입장이 되어 같은 문제지를 과하게 많이 풀어서 문제 번호만 봐도 정답을 맞출 수 있게 되었다고 가정합시다. 그런데 다른 문제지나 시험을 보면 점수가 안 좋다면 그게 의미가 있을까요?\n",
        "\n",
        "머신 러닝에서 과적합(Overfitting)이란 훈련 데이터를 과하게 학습한 경우를 말합니다. 훈련 데이터는 실제로 존재하는 많은 데이터의 일부에 불과합니다. 그런데 기계가 훈련 데이터에 대해서만 과하게 학습하면 테스트 데이터나 실제 서비스에서의 데이터에 대해서는 정확도가 좋지 않은 현상이 발생합니다.\n",
        "\n",
        "예를 들어 강아지 사진과 고양이 사진을 구분하는 기계가 있을 때, 검은색 강아지 사진 훈련 데이터를 과하게 학습하면 기계는 나중에 가서는 흰색 강아지나, 갈색 강아지를 보고도 강아지가 아니라고 판단하게 됩니다. 이는 훈련 데이터에 대해서 지나친 일반화를 한 상황입니다.\n",
        "\n",
        "과적합 상황에서는 훈련 데이터에 대해서는 오차가 낮지만, 테스트 데이터에 대해서는 오차가 높아지는 상황이 발생합니다. 아래의 그래프는 과적합 상황에서 발생할 수 있는 훈련 횟수에 따른 훈련 데이터의 오차와 테스트 데이터의 오차의 변화를 보여줍니다.\n",
        "\n",
        "![대체 텍스트](https://wikidocs.net/images/page/32012/%EC%8A%A4%ED%8C%B8_%EB%A9%94%EC%9D%BC_%EC%98%A4%EC%B0%A8.png)\n",
        "\n",
        "X축의 에포크(epoch)는 전체 훈련 데이터에 대한 훈련 횟수를 의미합니다. 위의 그래프는 에포크가 3~4를 넘어가게 되면 과적합이 발생합니다. 위의 그래프는 테스트 데이터에 대한 오차가 점차 증가하는 양상을 보여줍니다. 반대로 말하면 훈련 데이터에 대한 정확도는 높지만, 테스트 데이터는 정확도가 낮은 상황이라고 말할 수도 있습니다. 즉, 테스트 데이터의 오차가 증가하기 전이나, 정확도가 감소하기 전에 훈련을 멈추는 것이 바람직합니다.\n",
        "\n",
        "과적합 방지를 위해 테스트 데이터의 성능이 낮아지기 전에 훈련을 멈추는 것이 바람직하다고 했는데, 테스트 데이터의 성능이 올라갈 여지가 있음에도 훈련을 덜 한 상태를 반대로 과소적합(Underfitting)이라고 합니다. 과소 적합은 훈련 자체가 부족한 상태이므로 과대 적합과는 달리 훈련 데이터에 대해서도 보통 정확도가 낮다는 특징이 있습니다.\n",
        "\n",
        "이러한 두 가지 현상을 과적합과 과소 적합이라고 부르는 이유는 머신 러닝에서 학습 또는 훈련이라고 하는 과정을 적합(fitting)이라고도 부를 수 있기 때문입니다. 모델이 주어진 데이터에 대해서 적합해져가는 과정이기 때문입니다.\n",
        "\n",
        "딥 러닝을 할 때는 과적합을 막을 수 있는 드롭아웃(Dropout), 조기 종료(Early Stopping)과 같은 몇 가지 방법이 존재하는데 이는 인공 신경망 챕터에서 소개합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pc_Ac-HQnqK_",
        "colab_type": "text"
      },
      "source": [
        "## 5.2 퍼셉트론(Perceptron)\n",
        "\n",
        "인공 신경망은 수많은 머신 러닝 방법 중 하나입니다. 하지만 최근 인공 신경망을 복잡하게 쌓아 올린 딥 러닝이 다른 머신 러닝 방법들을 뛰어넘는 성능을 보여주는 사례가 늘면서, 전통적인 머신 러닝과 딥 러닝을 구분해서 이해해야 한다는 목소리가 커지고 있습니다. 딥 러닝을 이해하기 위해서는 우선 인공 신경망에 대한 이해가 필요한데, 이번 챕터에서는 초기의 인공 신경망인 퍼셉트론(Perceptron)에 대해서 이해합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1uIbH4Qny6E",
        "colab_type": "text"
      },
      "source": [
        "### 5.2.1 퍼셉트론(Perceptron)\n",
        "\n",
        "퍼셉트론(Perceptron)은 프랑크 로젠블라트(Frank Rosenblatt)가 1957년에 제안한 초기 형태의 인공 신경망으로 다수의 입력으로부터 하나의 결과를 내보내는 알고리즘입니다. 퍼셉트론은 실제 뇌를 구성하는 신경 세포 뉴런의 동작과 유사한데, 신경 세포 뉴런의 그림을 먼저 보도록 하겠습니다. 뉴런은 가지돌기에서 신호를 받아들이고, 이 신호가 일정치 이상의 크기를 가지면 축삭돌기를 통해서 신호를 전달합니다.\n",
        "\n",
        "![대체 텍스트](https://wikidocs.net/images/page/24958/%EB%89%B4%EB%9F%B0.PNG)\n",
        "\n",
        "이제 다수의 입력을 받는 퍼셉트론의 그림을 보겠습니다. 신경 세포 뉴런의 입력 신호와 출력 신호가 퍼셉트론에서 각각 입력값과 출력값에 해당됩니다.\n",
        "\n",
        "![대체 텍스트](https://wikidocs.net/images/page/24958/perceptrin1_final.PNG)\n",
        "\n",
        "$x$는 입력값을 의미하며, $W$는 가중치(Weight), $y$는 출력값입니다. 그림 안의 원은 인공 뉴런에 해당됩니다. 실제 신경 세포 뉴런에서의 신호를 전달하는 축삭돌기의 역할을 퍼셉트론에서는 가중치가 대신합니다. 각각의 인공 뉴런에서 보내진 입력값 $x$는 각각의 가중치 $W$와 함께 종착지인 인공 뉴런에 전달되고 있습니다.\n",
        "\n",
        "각각의 입력값에는 각각의 가중치가 존재하는데, 이때 가중치의 값이 크면 클수록 해당 입력 값이 중요하다는 것을 의미합니다.\n",
        "\n",
        "각 입력값이 가중치와 곱해져서 인공 뉴런에 보내지고, 각 입력값과 그에 해당되는 가중치의 곱의 전체 합이 임계치(threshold)를 넘으면 종착지에 있는 인공 뉴런은 출력 신호로서 1을 출력하고, 그렇지 않을 경우에는 0을 출력합니다. 이러한 함수를 계단 함수(Step function)라고 하며, 아래는 그래프는 계단 함수의 하나의 예를 보여줍니다.\n",
        "\n",
        "![대체 텍스트](https://wikidocs.net/images/page/24987/step_function.PNG)\n",
        "\n",
        "이때 계단 함수에 사용된 이 임계치값을 수식으로 표현할 때는 보통 세타(Θ)로 표현합니다. 이를 식으로 표현하면 다음과 같습니다.\n",
        "\n",
        "if $\\sum_i^{n} W_{i}x_{i}$ ≥ $\\theta$ → $y=1$\n",
        "\n",
        "if $\\sum_i^{n} W_{i}x_{i}$ < $\\theta$ → $y=0$\n",
        "\n",
        "단, 위의 식에서 임계치를 좌변으로 넘기고 편향 $b$(bias)로 표현할 수도 있습니다. 편향 $b$ 또한 퍼셉트론의 입력으로 사용됩니다. 보통 그림으로 표현할 때는 입력값이 1로 고정되고 편향 $b$가 곱해지는 변수로 표현됩니다.\n",
        "\n",
        "![대체 텍스트](https://wikidocs.net/images/page/24958/perceptron2_final.PNG)\n",
        "\n",
        "if $\\sum_i^{n} W_{i}x_{i} + b$ ≥ $0$ → $y=1$\n",
        "\n",
        "if $\\sum_i^{n} W_{i}x_{i} + b$ < $0$ → $y=0$\n",
        "\n",
        "이 책을 포함한 많은 인공 신경망 자료에서 편의상 편향 $b$가 그림이나 수식에서 생략되서 표현되기도 하지만 실제로는 편향 $b$ 또한 딥 러닝이 최적의 값을 찾아야 할 변수 중 하나입니다.\n",
        "\n",
        "다음 챕터에서 배우겠지만 이렇게 뉴런에서 출력값을 변경시키는 함수를 활성화 함수(Activation Function)라고 합니다. 초기 인공 신경망 모델인 퍼셉트론은 활성화 함수로 계단 함수를 사용하였지만, 그 뒤에 등장한 여러가지 발전된 신경망들은 계단 함수 외에도 여러 다양한 활성화 함수를 사용하기 시작했습니다. 사실 앞서 배운 시그모이드 함수나 소프트맥스 함수 또한 활성화 함수 중 하나입니다.\n",
        "\n",
        "퍼셉트론을 배우기 전에 로지스틱 회귀를 먼저 배운 이유도 여기에 있습니다. 퍼셉트론의 활성화 함수는 계단 함수이지만 여기서 활성화 함수를 시그모이드 함수로 변경하면 방금 배운 퍼셉트론은 곧 이진 분류를 수행하는 로지스틱 회귀와 동일함을 알 수 있습니다.\n",
        "\n",
        "다시 말하면 로지스틱 회귀 모델이 인공 신경망에서는 하나의 인공 뉴런으로 볼 수 있습니다. 로지스틱 회귀를 수행하는 인공 뉴런과 위에서 배운 퍼셉트론의 차이는 오직 활성화 함수의 차이입니다.\n",
        "\n",
        "\n",
        "\n",
        "*   인공 뉴런 : 활성화 함수 $f(\\sum_i^{n} W_{i}x_{i} + b)$\n",
        "*   위의 퍼셉트론(인공 뉴런 종류 중 하나) : 계단 함수 $f(\\sum_i^{n} W_{i}x_{i} + b)$ \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69FSSqAyor-X",
        "colab_type": "text"
      },
      "source": [
        "### 5.2.2 단층 퍼셉트론(Single-Layer Perceptron)\n",
        "\n",
        "위에서 배운 퍼셉트론을 단층 퍼셉트론이라고 합니다. 퍼셉트론은 단층 퍼셉트론과 다층 퍼셉트론으로 나누어지는데, 단층 퍼셉트론은 값을 보내는 단계과 값을 받아서 출력하는 두 단계로만 이루어집니다. 이때 이 각 단계를 보통 층(layer)라고 부르며, 이 두 개의 층을 입력층(input layer)과 출력층(output layer)이라고 합니다.\n",
        "\n",
        "![대체 텍스트](https://wikidocs.net/images/page/24958/perceptron3_final.PNG)\n",
        "\n",
        "단층 퍼셉트론의 한계를 개선하기 위해 향후에 나온 다층 퍼셉트론을 배우게 되면 단층과 다층 이 두 퍼셉트론이 어떤 차이를 가지는지 쉽게 이해할 수 있습니다. 단층 퍼셉트론이 어떤 일을 할 수 있으며 한계는 무엇인지 학습해보겠습니다.\n",
        "\n",
        "단층 퍼셉트론을 이용하면 AND, NAND, OR 게이트를 쉽게 구현할 수 있습니다. 게이트 연산에 쓰이는 것은 두 개의 입력값과 하나의 출력값입니다. 예를 들어 AND 게이트의 경우에는 두 개의 입력 값이 모두 1인 경우에만 출력값이 1이 나오는 구조를 갖고 있습니다.\n",
        "\n",
        "![대체 텍스트](https://wikidocs.net/images/page/24958/andgate.PNG)\n",
        "\n",
        "단층 퍼셉트론의 식을 통해 AND 게이트를 만족하는 두 개의 가중치와 편향 값에는 뭐가 있을까요? 각각 w1, w2, b라고 한다면 [0.5, 0.5, -0.7], [0.5, 0.5, -0.8] 또는 [1.0, 1.0, -1.0] 등 이 외에도 다양한 가중치와 편향의 조합이 나올 수 있습니다. 이해를 돕기 위해서 AND 게이트를 위한 매개변수 값을 가진 단층 퍼셉트론의 식을 파이썬 코드로 간단하게 구현해봅시다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZW2DgTu0ljTy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def AND_gate(x1, x2):\n",
        "    w1=0.5\n",
        "    w2=0.5\n",
        "    b=-0.7\n",
        "    result = x1*w1 + x2*w2 + b\n",
        "    if result <= 0:\n",
        "        return 0\n",
        "    else:\n",
        "        return 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7j7sRTTJo_ja",
        "colab_type": "text"
      },
      "source": [
        "위의 함수에 AND 게이트의 입력값을 모두 넣어보면 오직 두 개의 입력값이 1인 경우에만 1을 출력합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_yFnwplo960",
        "colab_type": "code",
        "outputId": "776885c7-c629-4f07-faf9-e3b7758ff609",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "AND_gate(0, 0), AND_gate(0, 1), AND_gate(1, 0), AND_gate(1, 1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 0, 0, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11nnZQ7_pCgg",
        "colab_type": "text"
      },
      "source": [
        "그렇다면 두 개의 입력값이 1인 경우에만 출력값이 0, 나머지 입력값의 쌍(pair)에 대해서는 모두 출력값이 1이 나오는 NAND 게이트는 어떨까요?\n",
        "\n",
        "![대체 텍스트](https://wikidocs.net/images/page/24958/nandgate.PNG)\n",
        "\n",
        "앞서 언급했던 AND 게이트를 충족하는 가중치와 편향값인 [0.5, 0.5, -0.7]에 -를 붙여서 [-0.5, -0.5, +0.7]을 단층 퍼셉트론의 식에 넣어보면 NAND 게이트를 충족합니다. 파이썬 코드를 통해서 이를 확인해봅시다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sw8eub2FpA2g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def NAND_gate(x1, x2):\n",
        "    w1=-0.5\n",
        "    w2=-0.5\n",
        "    b=0.7\n",
        "    result = x1*w1 + x2*w2 + b\n",
        "    if result <= 0:\n",
        "        return 0\n",
        "    else:\n",
        "        return 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MrJsItcpJdU",
        "colab_type": "text"
      },
      "source": [
        "단지 같은 코드에 함수 이름과 가중치와 편향만 바꿨을 뿐입니다. 퍼셉트론의 구조는 같기때문입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfJeYg5OpH7Y",
        "colab_type": "code",
        "outputId": "289d6291-2db9-4961-ec9a-90b2d2adff6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "NAND_gate(0, 0), NAND_gate(0, 1), NAND_gate(1, 0), NAND_gate(1, 1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1, 1, 0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xoq9SNCpMzf",
        "colab_type": "text"
      },
      "source": [
        "NAND 게이트를 구현한 파이썬 코드에 입력값을 넣자, 두 개의 입력값이 1인 경우에만 0이 나오는 것을 확인할 수 있습니다. 퍼셉트론으로 NAND 게이트를 구현한 것입니다. [-0.5, -0.5, -0.7] 외에도 퍼셉트론이 NAND 게이트의 동작을 하도록 하는 다양한 가중치와 편향의 값들이 있을 것입니다.\n",
        "\n",
        "두 개의 입력이 모두 0인 경우에 출력값이 0이고 나머지 경우에는 모두 출력값이 1인 OR 게이트 또한 적절한 가중치 값과 편향 값만 찾으면 단층 퍼셉트론의 식으로 구현할 수 있습니다.\n",
        "\n",
        "![대체 텍스트](https://wikidocs.net/images/page/24958/orgate.PNG)\n",
        "\n",
        "예를 들어 각각 가중치와 편향에 대해서 [0.6, 0.6, -0.5]를 선택하면 OR 게이트를 충족합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jz4_1v_bpLQS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def OR_gate(x1, x2):\n",
        "    w1=0.6\n",
        "    w2=0.6\n",
        "    b=-0.5\n",
        "    result = x1*w1 + x2*w2 + b\n",
        "    if result <= 0:\n",
        "        return 0\n",
        "    else:\n",
        "        return 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMfLhLsvpTQZ",
        "colab_type": "code",
        "outputId": "e39a77af-080c-4e76-b520-3fb24decf20b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "OR_gate(0, 0), OR_gate(0, 1), OR_gate(1, 0), OR_gate(1, 1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 1, 1, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCPiT1k8pVxX",
        "colab_type": "text"
      },
      "source": [
        "물론, 이 외에도 이를 충족하는 다양한 가중치와 편향의 값이 있습니다.\n",
        "\n",
        "이처럼 단층 퍼셉트론은 AND 게이트, NAND 게이트, OR 게이트 또한 구현할 수 있습니다. 하지만 단층 퍼셉트론으로 구현이 불가능한 게이트가 있는데 바로 XOR 게이트입니다. XOR 게이트는 입력값 두 개가 서로 다른 값을 갖고 있을때에만 출력값이 1이 되고, 입력값 두 개가 서로 같은 값을 가지면 출력값이 0이 되는 게이트입니다. 위의 파이썬 코드에 아무리 수많은 가중치와 편향을 넣어봐도 XOR 게이트를 구현하는 것은 불가능합니다. 그 이유는 단층 퍼셉트론은 직선 하나로 두 영역을 나눌 수 있는 문제에 대해서만 구현이 가능하기 때문입니다.\n",
        "\n",
        "예를 들어 AND 게이트에 대한 단층 퍼셉트론을 시각화해보면 다음과 같습니다.\n",
        "\n",
        "![대체 텍스트](https://wikidocs.net/images/page/24958/andgraphgate.PNG)\n",
        "\n",
        "그림에서는 출력값 0을 하얀색 원, 1을 검은색 원으로 표현했습니다. AND 게이트를 충족하려면 하얀색 원과 검은색 원을 직선으로 나누게 됩니다. 마찬가지로 NAND 게이트나 OR 게이트에 대해서도 시각화를 했을 때 직선으로 나누는 것이 가능합니다.\n",
        "\n",
        "![대체 텍스트](https://wikidocs.net/images/page/24958/oragateandnandgate.PNG)\n",
        "\n",
        "그렇다면 XOR 게이트는 어떨까요? XOR 게이트는 입력값 두 개가 서로 다른 값을 갖고 있을때에만 출력값이 1이 되고, 입력값 두 개가 서로 같은 값을 가지면 출력값이 0이 되는 게이트입니다. XOR 게이트를 시각화해보면 다음과 같습니다.\n",
        "\n",
        "\n",
        "![대체 텍스트](https://wikidocs.net/images/page/24958/xorgraphandxorgate.PNG)\n",
        "\n",
        "하얀색 원과 검은색 원을 직선 하나로 나누는 것은 불가능합니다. 즉, 단층 퍼셉트론으로는 XOR 게이트를 구현하는 것이 불가능합니다. 이를 단층 퍼셉트론은 선형 영역에 대해서만 분리가 가능하다고 말합니다. 사실 XOR 게이트는 직선이 아닌 곡선. 비선형 영역으로 분리하면 구현이 가능합니다.\n",
        "\n",
        "![대체 텍스트](https://wikidocs.net/images/page/24958/xorgate_nonlinearity.PNG)\n",
        "\n",
        "위의 그림은 곡선을 사용한다면 하얀색 원과 검은색 원을 나눌 수 있음을 보여줍니다. 이제 XOR 게이트를 만들 수 있는 다층 퍼셉트론에 대해서 알아보도록 하겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHTNeW4fpvdh",
        "colab_type": "text"
      },
      "source": [
        "### 5.2.3 다층 퍼셉트론(MultiLayer Perceptron, MLP)\n",
        "\n",
        "XOR 게이트는 기존의 AND, NAND, OR 게이트를 조합하면 만들 수 있습니다. 퍼셉트론 관점에서 말하면, 층을 더 쌓으면 만들 수 있습니다. 다층 퍼셉트론과 단층 퍼셉트론의 차이는 단층 퍼셉트론은 입력층과 출력층만 존재하지만, 다층 퍼셉트론은 중간에 층을 더 추가하였다는 점입니다. 이렇게 입력층과 출력층 사이에 존재하는 층을 은닉층(hidden layer)이라고 합니다. 즉, 다층 퍼셉트론은 중간에 은닉층이 존재한다는 점이 단층 퍼셉트론과 다릅니다. 다층 퍼셉트론은 줄여서 MLP라고도 부릅니다.\n",
        "\n",
        "![대체 텍스트](https://wikidocs.net/images/page/24958/perceptron_4image.jpg)\n",
        "\n",
        "위의 그림은 AND, NAND, OR 게이트를 조합하여 XOR 게이트를 구현한 다층 퍼셉트론의 예입니다. (실제 구현은 숙제로 남겨두겠습니다. 힌트를 드리자면 위의 단층 퍼셉트론에서 사용한 함수들을 그대로 사용하면 됩니다.) XOR 예제에서는 은닉층 1개만으로 문제를 해결할 수 있었지만, 다층 퍼셉트론은 본래 은닉층이 1개 이상인 퍼셉트론을 말합니다. 즉, XOR 문제보다 더욱 복잡한 문제를 해결하기 위해서 다층 퍼셉트론은 중간에 수많은 은닉층을 더 추가할 수 있습니다. 은닉층의 개수는 2개일 수도 있고, 수십 개일수도 있고 사용자가 설정하기 나름입니다. 아래는 더 어려운 문제를 풀기 위해서 은닉층이 하나 더 추가되고(이 경우에는 은닉층이 2개), 뉴런의 개수를 늘린 다층 퍼셉트론의 모습을 보여줍니다.\n",
        "\n",
        "\n",
        "![대체 텍스트](https://wikidocs.net/images/page/24958/%EC%9E%85%EC%9D%80%EC%B8%B5.PNG)\n",
        "\n",
        "위와 같이 은닉층이 2개 이상인 신경망을 심층 신경망(Deep Neural Network, DNN)이라고 합니다. 심층 신경망은 다층 퍼셉트론만 이야기 하는 것이 아니라, 여러 변형된 다양한 신경망들도 은닉층이 2개 이상이 되면 심층 신경망이라고 합니다.\n",
        "\n",
        "지금까지는 OR, AND, XOR 게이트 등. 퍼셉트론이 가야할 정답을 참고로 퍼셉트론이 정답을 출력할 때까지 가중치를 바꿔보면서 맞는 가중치를 찾았습니다. 즉, 가중치를 수동으로 찾았습니다. 하지만 이제는 기계가 가중치를 스스로 찾아내도록 자동화시켜야하는데, 이것이 머신 러닝에서 말하는 학습(training) 단계에 해당됩니다. 앞서 선형 회귀와 로지스틱 회귀에서 보았듯이 손실 함수(Loss function)와 옵티마이저(Optimizer)를 사용합니다. 그리고 만약 학습을 시키는 인공 신경망이 심층 신경망일 경우에는 이를 심층 신경망을 학습시킨다고 하여, 딥 러닝(Deep Learning)이라고 합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Kb1UEHGp-qE",
        "colab_type": "text"
      },
      "source": [
        "## 5.3 XOR 문제 - 단층 퍼셉트론 구현하기\n",
        "\n",
        "이번 챕터에서는 파이토치를 사용해서 단층 퍼셉트론을 구현하여 XOR 문제를 풀어보는 것을 시도해보겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7EgNReABqDL1",
        "colab_type": "text"
      },
      "source": [
        "### 5.3.1 파이토치로 단층 퍼셉트론 구현하기\n",
        "\n",
        "우선 필요한 도구를 임포트하고, GPU 연산이 가능할 경우에는 GPU 연산을 할 수 있도록 설정해줍니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_78REjBpUYg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "torch.manual_seed(777)\n",
        "if device == 'cuda':\n",
        "    torch.cuda.manual_seed_all(777)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2pfMgW5qKlA",
        "colab_type": "text"
      },
      "source": [
        "이제 XOR 문제에 해당되는 입력과 출력을 정의합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDyVe5rQqIxa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = torch.FloatTensor([[0, 0], [0, 1], [1, 0], [1, 1]]).to(device)\n",
        "Y = torch.FloatTensor([[0], [1], [1], [0]]).to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_aOiM3YAqObJ",
        "colab_type": "text"
      },
      "source": [
        "이제 1개의 뉴런을 가지는 단층 퍼셉트론을 구현해봅시다. 단층 퍼셉트론이 처음 소개되었을 때는 계단 함수였지만, 우리는 이미 또 다른 활성화 함수인 시그모이드 함수를 알고 있으므로 시그모이드 함수를 사용해보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3opJdoaFqNG7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "linear = nn.Linear(2, 1, bias=True)\n",
        "sigmoid = nn.Sigmoid()\n",
        "model = nn.Sequential(linear, sigmoid).to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8nrs4BqqWYR",
        "colab_type": "text"
      },
      "source": [
        "0 또는 1을 예측하는 이진 분류 문제이므로 비용 함수로는 크로스엔트로피 함수를 사용합니다.\n",
        "nn.BCELoss()는 이진 분류에서 사용하는 크로스엔트로피 함수입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69Utp-ZTqQCj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 비용 함수와 옵티마이저 정의\n",
        "criterion = torch.nn.BCELoss().to(device)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOTRJz3gqX5o",
        "colab_type": "code",
        "outputId": "11620831-c173-4145-a146-9846f49c589e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#10,001번의 에포크 수행. 0번 에포크부터 10,000번 에포크까지.\n",
        "for step in range(10001): \n",
        "    optimizer.zero_grad()\n",
        "    hypothesis = model(X)\n",
        "\n",
        "    # 비용 함수\n",
        "    cost = criterion(hypothesis, Y)\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if step % 100 == 0: # 100번째 에포크마다 비용 출력\n",
        "        print(step, cost.item())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 0.7273974418640137\n",
            "100 0.6931475400924683\n",
            "200 0.6931471824645996\n",
            "300 0.6931471824645996\n",
            "400 0.6931471824645996\n",
            "500 0.6931471824645996\n",
            "600 0.6931471824645996\n",
            "700 0.6931471824645996\n",
            "800 0.6931471824645996\n",
            "900 0.6931471824645996\n",
            "1000 0.6931471824645996\n",
            "1100 0.6931471824645996\n",
            "1200 0.6931471824645996\n",
            "1300 0.6931471824645996\n",
            "1400 0.6931471824645996\n",
            "1500 0.6931471824645996\n",
            "1600 0.6931471824645996\n",
            "1700 0.6931471824645996\n",
            "1800 0.6931471824645996\n",
            "1900 0.6931471824645996\n",
            "2000 0.6931471824645996\n",
            "2100 0.6931471824645996\n",
            "2200 0.6931471824645996\n",
            "2300 0.6931471824645996\n",
            "2400 0.6931471824645996\n",
            "2500 0.6931471824645996\n",
            "2600 0.6931471824645996\n",
            "2700 0.6931471824645996\n",
            "2800 0.6931471824645996\n",
            "2900 0.6931471824645996\n",
            "3000 0.6931471824645996\n",
            "3100 0.6931471824645996\n",
            "3200 0.6931471824645996\n",
            "3300 0.6931471824645996\n",
            "3400 0.6931471824645996\n",
            "3500 0.6931471824645996\n",
            "3600 0.6931471824645996\n",
            "3700 0.6931471824645996\n",
            "3800 0.6931471824645996\n",
            "3900 0.6931471824645996\n",
            "4000 0.6931471824645996\n",
            "4100 0.6931471824645996\n",
            "4200 0.6931471824645996\n",
            "4300 0.6931471824645996\n",
            "4400 0.6931471824645996\n",
            "4500 0.6931471824645996\n",
            "4600 0.6931471824645996\n",
            "4700 0.6931471824645996\n",
            "4800 0.6931471824645996\n",
            "4900 0.6931471824645996\n",
            "5000 0.6931471824645996\n",
            "5100 0.6931471824645996\n",
            "5200 0.6931471824645996\n",
            "5300 0.6931471824645996\n",
            "5400 0.6931471824645996\n",
            "5500 0.6931471824645996\n",
            "5600 0.6931471824645996\n",
            "5700 0.6931471824645996\n",
            "5800 0.6931471824645996\n",
            "5900 0.6931471824645996\n",
            "6000 0.6931471824645996\n",
            "6100 0.6931471824645996\n",
            "6200 0.6931471824645996\n",
            "6300 0.6931471824645996\n",
            "6400 0.6931471824645996\n",
            "6500 0.6931471824645996\n",
            "6600 0.6931471824645996\n",
            "6700 0.6931471824645996\n",
            "6800 0.6931471824645996\n",
            "6900 0.6931471824645996\n",
            "7000 0.6931471824645996\n",
            "7100 0.6931471824645996\n",
            "7200 0.6931471824645996\n",
            "7300 0.6931471824645996\n",
            "7400 0.6931471824645996\n",
            "7500 0.6931471824645996\n",
            "7600 0.6931471824645996\n",
            "7700 0.6931471824645996\n",
            "7800 0.6931471824645996\n",
            "7900 0.6931471824645996\n",
            "8000 0.6931471824645996\n",
            "8100 0.6931471824645996\n",
            "8200 0.6931471824645996\n",
            "8300 0.6931471824645996\n",
            "8400 0.6931471824645996\n",
            "8500 0.6931471824645996\n",
            "8600 0.6931471824645996\n",
            "8700 0.6931471824645996\n",
            "8800 0.6931471824645996\n",
            "8900 0.6931471824645996\n",
            "9000 0.6931471824645996\n",
            "9100 0.6931471824645996\n",
            "9200 0.6931471824645996\n",
            "9300 0.6931471824645996\n",
            "9400 0.6931471824645996\n",
            "9500 0.6931471824645996\n",
            "9600 0.6931471824645996\n",
            "9700 0.6931471824645996\n",
            "9800 0.6931471824645996\n",
            "9900 0.6931471824645996\n",
            "10000 0.6931471824645996\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4O76IbeVqdwX",
        "colab_type": "text"
      },
      "source": [
        "200번 에포크에 비용이 0.6931471824645996가 출력된 이후에는 10,000번 에포크가 되는 순간까지 더 이상 비용이 줄어들지 않습니다. 이는 단층 퍼셉트론은 XOR 문제를 풀 수 없기 때문입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZuYkNiNDqgim",
        "colab_type": "text"
      },
      "source": [
        "### 5.3.2 학습된 단층 퍼셉트론의 예측값 확인하기\n",
        "\n",
        "총 10,001회 학습한 단층 퍼셉트론의 예측값도 확인해보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYNVACTMqavq",
        "colab_type": "code",
        "outputId": "fd0a5a78-1b0f-4f2b-88e4-dae3b038c87b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        }
      },
      "source": [
        "with torch.no_grad():\n",
        "    hypothesis = model(X)\n",
        "    predicted = (hypothesis > 0.5).float()\n",
        "    accuracy = (predicted == Y).float().mean()\n",
        "    print('모델의 출력값(Hypothesis): ', hypothesis.detach().cpu().numpy())\n",
        "    print('모델의 예측값(Predicted): ', predicted.detach().cpu().numpy())\n",
        "    print('실제값(Y): ', Y.cpu().numpy())\n",
        "    print('정확도(Accuracy): ', accuracy.item())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "모델의 출력값(Hypothesis):  [[0.5]\n",
            " [0.5]\n",
            " [0.5]\n",
            " [0.5]]\n",
            "모델의 예측값(Predicted):  [[0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]]\n",
            "실제값(Y):  [[0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]]\n",
            "정확도(Accuracy):  0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5f_F4SV5qpp5",
        "colab_type": "text"
      },
      "source": [
        "실제값은 0, 1, 1, 0임에도 예측값은 0, 0, 0, 0으로 문제를 풀지 못하는 모습을 보여줍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1uXU20FquON",
        "colab_type": "text"
      },
      "source": [
        "## 5.4 역전파(BackPropagation)\n",
        "\n",
        "인공 신경망이 순전파 과정을 진행하여 예측값과 실제값의 오차를 계산하였을 때 어떻게 역전파 과정에서 경사 하강법을 사용하여 가중치를 업데이트하는지 직접 계산을 통해 이해해봅시다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24QZ55N7qyTy",
        "colab_type": "text"
      },
      "source": [
        "### 5.4.1 인공 신경망의 이해(Neural Network Overview)\n",
        "\n",
        "우선 예제를 위해 사용될 인공 신경망을 소개합니다. 역전파의 이해를 위해서 여기서 사용할 인공 신경망은 입력층, 은닉층, 출력층 이렇게 3개의 층을 가집니다. 또한 해당 인공 신경망은 두 개의 입력과, 두 개의 은닉층 뉴런, 두 개의 출력층 뉴런을 사용합니다. 은닉층과 출력층의 모든 뉴런은 활성화 함수로 시그모이드 함수를 사용합니다.\n",
        "\n",
        "![대체 텍스트](https://wikidocs.net/images/page/37406/nn1_final.PNG)\n",
        "\n",
        "위의 그림은 여기서 사용할 인공 신경망의 모습을 보여줍니다. 은닉층과 출력층의 모든 뉴런에서 변수 $z$가 존재하는데 여기서 변수 $z$는 이전층의 모든 입력이 각각의 가중치와 곱해진 값들이 모두 더해진 가중합을 의미합니다. 이 값은 뉴런에서 아직 시그모이드 함수를 거치지 않은 상태입니다. 즉, 활성화 함수의 입력을 의미합니다. $z$ 우측의 |를 지나서 존재하는 변수 $h$ 또는 $o$는 $z$가 시그모이드 함수를 지난 후의 값으로 각 뉴런의 출력값을 의미합니다. 이번 역전파 예제에서는 인공 신경망에 존재하는 모든 가중치 W에 대해서 역전파를 통해 업데이트하는 것을 목표로합니다. 해당 인공 신경망은 편향 b는 고려하지 않습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnR08w-LredM",
        "colab_type": "text"
      },
      "source": [
        "### 5.4.2 순전파(Forward Propagation)\n",
        "\n",
        "![대체 텍스트](https://wikidocs.net/images/page/37406/nn2_final_final.PNG)\n",
        "\n",
        "주어진 값이 위의 그림과 같을 때 순전파를 진행해봅시다. 위의 그림에서 소수점 앞의 0은 생략하였습니다. 예를 들어 .25는 0.25를 의미합니다. 파란색 숫자는 입력값을 의미하며, 빨간색 숫자는 각 가중치의 값을 의미합니다. 앞으로 진행하는 계산의 결과값은 소수점 아래 여덟번째 자리까지 반올림하여 표기합니다.\n",
        "\n",
        "각 입력은 입력층에서 은닉층 방향으로 향하면서 각 입력에 해당하는 가중치와 곱해지고, 결과적으로 가중합으로 계산되어 은닉층 뉴런의 시그모이드 함수의 입력값이 됩니다. $z_1$과 $z_2$는 시그모이드 함수의 입력으로 사용되는 각각의 값에 해당됩니다.\n",
        "\n",
        "$z_{1}=W_{1}x_{1} + W_{2}x_{2}=0.3 \\text{×} 0.1 + 0.25 \\text{×} 0.2= 0.08$\n",
        "\n",
        "$z_{2}=W_{3}x_{1} + W_{4}x_{2}=0.4 \\text{×} 0.1 + 0.35 \\text{×} 0.2= 0.11$\n",
        "\n",
        "$z_1$과 $z_2$는 각각의 은닉층 뉴런에서 시그모이드 함수를 지나게 되는데 시그모이드 함수가 리턴하는 결과값은 은닉층 뉴런의 최종 출력값입니다. 식에서는 각각 $h_1$과 $h_2$에 해당되며, 아래의 결과와 같습니다.\n",
        "\n",
        "$h_{1}=sigmoid(z_{1}) = 0.51998934$\n",
        "\n",
        "$h_{2}=sigmoid(z_{2}) = 0.52747230$\n",
        "\n",
        "$h_1$과 $h_2$ 이 두 값은 다시 출력층의 뉴런으로 향하게 되는데 이때 다시 각각의 값에 해당되는 가중치와 곱해지고, 다시 가중합 되어 출력층 뉴런의 시그모이드 함수의 입력값이 됩니다. 식에서는 각각 $z_3$과 $z_4$에 해당됩니다.\n",
        "\n",
        "$z_{3}=W_{5}h_{1}+W_{6}h_{2} = 0.45 \\text{×} h_{1} + 0.4 \\text{×} h_{2} = 0.44498412$\n",
        "\n",
        "$z_{4}=W_{7}h_{1}+W_{8}h_{2} = 0.7 \\text{×} h_{1} + 0.6 \\text{×} h_{2} = 0.68047592$\n",
        "\n",
        "$z_3$과 $z_4$이 출력층 뉴런에서 시그모이드 함수를 지난 값은 이 인공 신경망이 최종적으로 계산한 출력값입니다. 실제값을 예측하기 위한 값으로서 예측값이라고도 부릅니다.\n",
        "\n",
        "$o_{1}=sigmoid(z_{3})=0.60944600$\n",
        "\n",
        "$o_{2}=sigmoid(z_{4})=0.66384491$\n",
        "\n",
        "이제 해야할 일은 예측값과 실제값의 오차를 계산하기 위한 오차 함수를 선택하는 것입니다. 오차(Error)를 계산하기 위한 손실 함수(Loss function)로는 평균 제곱 오차 MSE를 사용합니다. 식에서는 실제값을 target이라고 표현하였으며, 순전파를 통해 나온 예측값을 output으로 표현하였습니다. 그리고 각 오차를 모두 더하면 전체 오차 $E_{total}$가 됩니다.\n",
        "\n",
        "$E_{o1}=\\frac{1}{2}(target_{o1}-output_{o1})^{2}=0.02193381$\n",
        "\n",
        "$E_{o2}=\\frac{1}{2}(target_{o2}-output_{o2})^{2}=0.00203809$\n",
        "\n",
        "$E_{total}=E_{o1}+E_{o2}=0.02397190$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fN8WhlT1tz6A",
        "colab_type": "text"
      },
      "source": [
        "### 5.4.3 역전파 1단계(BackPropagation Step 1)\n",
        "\n",
        "순전파가 입력층에서 출력층으로 향한다면 역전파는 반대로 출력층에서 입력층 방향으로 계산하면서 가중치를 업데이트해갑니다. 출력층 바로 이전의 은닉층을 N층이라고 하였을 때, 출력층과 N층 사이의 가중치를 업데이트하는 단계를 역전파 1단계, 그리고 N층과 N층의 이전층 사이의 가중치를 업데이트 하는 단계를 역전파 2단계라고 해봅시다.\n",
        "\n",
        "![대체 텍스트](https://wikidocs.net/images/page/37406/nn3_final.PNG)\n",
        "\n",
        "역전파 1단계에서 업데이트 해야 할 가중치는 $W_5,W_6,W_7,W_{8}$ 총 4개입니다. 원리 자체는 동일하므로 우선 $W_{5}$에 대해서 먼저 업데이트를 진행해보겠습니다. 경사 하강법을 수행하려면 가중치 $W_{5}$를 업데이트 하기 위해서 $ \\frac{\\partial E_{total}}{\\partial W_{5}}$를 계산해야 합니다.\n",
        "\n",
        "$\\frac{\\partial E_{total}}{\\partial W_{5}}$를 계산하기 위해 미분의 연쇄 법칙(Chain rule)에 따라서 이와 같이 풀어 쓸 수 있습니다.\n",
        "\n",
        "$\\frac{\\partial E_{total}}{\\partial W_{5}} = \\frac{\\partial E_{total}}{\\partial o_{1}} \\text{×} \\frac{\\partial o_{1}}{\\partial z_{3}} \\text{×} \\frac{\\partial z_{3}}{\\partial W_{5}}$\n",
        "\n",
        "위의 식에서 우변의 세 개의 각 항에 대해서 순서대로 계산해봅시다. 우선 첫번째 항에 대해서 계산해보겠습니다. 미분을 진행하기 전에 $E_{total}$의 값을 상기해봅시다. $E_{total}$은 앞서 순전파를 진행하고 계산했던 전체 오차값입니다. 식은 다음과 같습니다.\n",
        "\n",
        "$E_{total}=\\frac{1}{2}(target_{o1}-output_{o1})^{2} + \\frac{1}{2}(target_{o2}-output_{o2})^{2}$\n",
        "\n",
        "이에 $\\frac{\\partial E_{total}}{\\partial o_{1}}$는 다음과 같습니다.\n",
        "\n",
        "$\\frac{\\partial E_{total}}{\\partial o_{1}}=2 \\text{×} \\frac{1}{2}(target_{o1}-output_{o1})^{2-1} \\text{×} (-1) + 0$\n",
        "\n",
        "$\\frac{\\partial E_{total}}{\\partial o_{1}}=-(target_{o1}-output_{o1})=-(0.4-0.60944600)=0.20944600$\n",
        "\n",
        "이제 두번째 항을 주목해봅시다. $o_1$이라는 값은 시그모이드 함수의 출력값입니다. 그런데 시그모이드 함수의 미분은 $f(x)×(1−f(x))$입니다. 앞으로의 계산 과정에서도 계속해서 시그모이드 함수를 미분해야 하는 상황이 생기므로 기억해둡시다. 이에 따라서 두번째 항의 미분 결과는 다음과 같습니다.\n",
        "(시그모이드 함수 미분 참고 링크 : https://en.wikipedia.org/wiki/Logistic_function#Derivative)\n",
        "\n",
        "$\\frac{\\partial o_{1}}{∂z_{3}}=o_{1}\\text{×}(1-o_{1})=0.60944600(1-0.60944600)=0.23802157$\n",
        "\n",
        "마지막으로 세번째 항은 $h_1$의 값과 동일합니다.\n",
        "\n",
        "$\\frac{\\partial z_{3}}{∂W_{5}}=h_{1}=0.51998934$\n",
        "\n",
        "우변의 모든 항을 계산하였습니다. 이제 이 값을 모두 곱해주면 됩니다.\n",
        "\n",
        "$\\frac{\\partial E_{total}}{\\partial W_{5}} = 0.20944600 \\text{×} 0.23802157 \\text{×} 0.51998934 = 0.02592286$\n",
        "\n",
        "이제 앞서 배웠던 경사 하강법을 통해 가중치를 업데이트 할 때가 왔습니다! 하이퍼파라미터에 해당되는 학습률(learning rate) $α$는 0.5라고 가정합니다.\n",
        "\n",
        "$W_{5}^{+}=W_{5}-α\\frac{\\partial E_{total}}{\\partial W_{5}}=0.45- 0.5 \\text{×} 0.02592286=0.43703857$\n",
        "\n",
        "이와 같은 원리로 $W_{6}^{+},\\ W_{7}^{+},\\ W_{8}^{+}$을 계산할 수 있습니다.\n",
        "\n",
        "$\\frac{\\partial E_{total}}{\\partial W_{6}} = \\frac{\\partial E_{total}}{\\partial o_{1}} \\text{×} \\frac{\\partial o_{1}}{\\partial z_{3}} \\text{×} \\frac{\\partial z_{3}}{\\partial W_{6}} → W_{6}^{+}=0.38685205$\n",
        "\n",
        "$\\frac{\\partial E_{total}}{\\partial W_{7}} = \\frac{\\partial E_{total}}{\\partial o_{2}} \\text{×} \\frac{\\partial o_{2}}{\\partial z_{4}} \\text{×} \\frac{\\partial z_{4}}{\\partial W_{7}} → W_{7}^{+}=0.69629578$\n",
        "\n",
        "$\\frac{\\partial E_{total}}{\\partial W_{8}} = \\frac{\\partial E_{total}}{\\partial o_{2}} \\text{×} \\frac{\\partial o_{2}}{\\partial z_{4}} \\text{×} \\frac{\\partial z_{4}}{\\partial W_{8}} → W_{8}^{+}=0.59624247$\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYQOTXoVvuM2",
        "colab_type": "text"
      },
      "source": [
        "### 5.4.4 역전파 2단계(BackPropagation Step 2)\n",
        "\n",
        "![대체 텍스트](https://wikidocs.net/images/page/37406/nn4.PNG)\n",
        "\n",
        "1단계를 완료하였다면 이제 입력층 방향으로 이동하며 다시 계산을 이어갑니다. 위의 그림에서 빨간색 화살표는 순전파의 정반대 방향인 역전파의 방향을 보여줍니다. 현재 인공 신경망은 은닉층이 1개밖에 없으므로 이번 단계가 마지막 단계입니다. 하지만 은닉층이 더 많은 경우라면 입력층 방향으로 한 단계씩 계속해서 계산해가야 합니다.\n",
        "\n",
        "이번 단계에서 계산할 가중치는 $W_{1}, W_{2}, W_{3}, W_{4}$입니다. 원리 자체는 동일하므로 우선 $W_1$에 대해서 먼저 업데이트를 진행해보겠습니다. 경사 하강법을 수행하려면 가중치$W_1$를 업데이트 하기 위해서 $\\frac{\\partial E_{total}}{\\partial W_{1}}$를 계산해야 합니다.\n",
        "\n",
        "$\\frac{\\partial E_{total}}{\\partial W_{1}}$를 계산하기 위해 미분의 연쇄 법칙(Chain rule)에 따라서 이와 같이 풀어 쓸 수 있습니다.\n",
        "\n",
        "$\\frac{\\partial E_{total}}{\\partial W_{1}} = \\frac{\\partial E_{total}}{\\partial h_{1}} \\text{×} \\frac{\\partial h_{1}}{\\partial z_{1}} \\text{×} \\frac{\\partial z_{1}}{\\partial W_{1}}$\n",
        "\n",
        "위의 식에서 우변의 첫번째항인 $\\frac{\\partial E_{total}}{\\partial h_{1}}$는 다음과 같이 다시 식을 풀어서 쓸 수 있습니다.\n",
        "\n",
        "$\\frac{\\partial E_{total}}{\\partial h_{1}} = \\frac{\\partial E_{o1}}{\\partial h_{1}} + \\frac{\\partial E_{o2}}{\\partial h_{1}}$\n",
        "\n",
        "\n",
        "위의 식의 우변의 두 항을 각각 구해봅시다. 우선 첫번째 항 $\\frac{\\partial E_{o1}}{\\partial h_{1}}$에 대해서 항을 분해 및 계산해보겠습니다.\n",
        "\n",
        "$\\frac{\\partial E_{o1}}{\\partial h_{1}} = \\frac{\\partial E_{o1}}{\\partial z_{3}} \\text{×} \\frac{{\\partial z_{3}}}{\\partial h_{1}} = \\frac{\\partial E_{o1}}{\\partial o_{1}} \\text{×} \\frac{\\partial o_{1}}{\\partial z_{3}} \\text{×} \\frac{{\\partial z_{3}}}{\\partial h_{1}}$\n",
        "\n",
        "$= -(target_{o1}-output_{o1}) \\text{×} o_{1}\\text{×}(1-o_{1}) \\text{×} W_{5}$\n",
        "\n",
        "$= 0.20944600 \\text{×} 0.23802157 \\text{×} 0.45 = 0.02243370$\n",
        "\n",
        "이와 같은 원리로 $\\frac{\\partial E_{o2}}{\\partial h_{1}}$ 또한 구합니다.\n",
        "\n",
        "$\\frac{\\partial E_{o2}}{\\partial h_{1}} = \\frac{\\partial E_{o2}}{\\partial z_{4}} \\text{×} \\frac{{\\partial z_{4}}}{\\partial h_{1}} = \\frac{\\partial E_{o2}}{\\partial o_{2}} \\text{×} \\frac{\\partial o_{2}}{\\partial z_{4}} \\text{×} \\frac{{\\partial z_{4}}}{\\partial h_{1}} = 0.00997311$\n",
        "\n",
        "$\\frac{\\partial E_{total}}{\\partial h_{1}} = 0.02243370 + 0.00997311 = 0.03240681$\n",
        "\n",
        "이제 $\\frac{\\partial E_{total}}{\\partial W_{1}}$를 구하기 위해서 필요한 첫번째 항을 구했습니다. 나머지 두 항에 대해서 구해보도록 하겠습니다.\n",
        "\n",
        "$\\frac{\\partial h_{1}}{\\partial z_{1}} = h_{1}\\text{×}(1-h_{1}) = 0.51998934(1-0.51998934)=0.24960043$\n",
        "\n",
        "$\\frac{\\partial z_{1}}{\\partial W_{1}} = x_{1} = 0.1$\n",
        "\n",
        "즉, $\\frac{\\partial E_{total}}{\\partial W_{1}}$는 다음과 같습니다.\n",
        "\n",
        "$\\frac{\\partial E_{total}}{\\partial W_{1}} = 0.03240681 \\text{×} 0.24960043 \\text{×} 0.1 = 0.00080888$\n",
        "\n",
        "이제 앞서 배웠던 경사 하강법을 통해 가중치를 업데이트 할 수 있습니다.\n",
        "\n",
        "$W_{1}^{+}=W_{1}-α\\frac{\\partial E_{total}}{\\partial W_{1}}=0.1- 0.5 \\text{×} 0.00080888=0.29959556$\n",
        "\n",
        "이와 같은 원리로 $W_{2}^{+},\\ W_{3}^{+},\\ W_{4}^{+}$을 계산할 수 있습니다.\n",
        "\n",
        "$\\frac{\\partial E_{total}}{\\partial W_{2}} = \\frac{\\partial E_{total}}{\\partial h_{1}} \\text{×} \\frac{\\partial h_{1}}{\\partial z_{1}} \\text{×} \\frac{\\partial z_{1}}{\\partial W_{2}}  → W_{2}^{+}=0.24919112$\n",
        "\n",
        "$\\frac{\\partial E_{total}}{\\partial W_{3}} = \\frac{\\partial E_{total}}{\\partial h_{2}} \\text{×} \\frac{\\partial h_{2}}{\\partial z_{2}} \\text{×} \\frac{\\partial z_{2}}{\\partial W_{3}}  → W_{3}^{+}=0.39964496$\n",
        "\n",
        "$\\frac{\\partial E_{total}}{\\partial W_{4}} = \\frac{\\partial E_{total}}{\\partial h_{2}} \\text{×} \\frac{\\partial h_{2}}{\\partial z_{2}} \\text{×} \\frac{\\partial z_{2}}{\\partial W_{4}} → W_{4}^{+}=0.34928991$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZmU9dlGxr0Q",
        "colab_type": "text"
      },
      "source": [
        "### 5.4.5 결과 확인\n",
        "\n",
        "![대체 텍스트](https://wikidocs.net/images/page/37406/nn1_final.PNG)\n",
        "\n",
        "업데이트 된 가중치에 대해서 다시 한 번 순전파를 진행하여 오차가 감소하였는지 확인해보겠습니다.\n",
        "\n",
        "$z_{1}=W_{1}x_{1} + W_{2}x_{2}=0.29959556 \\text{×} 0.1 + 0.24919112 \\text{×} 0.2= 0.07979778$\n",
        "\n",
        "$z_{2}=W_{3}x_{1} + W_{4}x_{2}=0.39964496 \\text{×} 0.1 + 0.34928991 \\text{×} 0.2= 0.10982248$\n",
        "\n",
        "$h_{1}=sigmoid(z_{1}) = 0.51993887$\n",
        "\n",
        "$h_{2}=sigmoid(z_{2}) = 0.52742806$\n",
        "\n",
        "$z_{3}=W_{5}h_{1}+W_{6}h_{2} = 0.43703857 \\text{×} h_{1} + 0.38685205 \\text{×} h_{2} = 0.43126996$\n",
        "\n",
        "$z_{4}=W_{7}h_{1}+W_{8}h_{2} = 0.69629578 \\text{×} h_{1} + 0.59624247 \\text{×} h_{2} = 0.67650625$\n",
        "\n",
        "$o_{1}=sigmoid(z_{3})=0.60617688$\n",
        "\n",
        "$o_{2}=sigmoid(z_{4})=0.66295848$\n",
        "\n",
        "$E_{o1}=\\frac{1}{2}(target_{o1}-output_{o1})^{2}=0.02125445$\n",
        "\n",
        "$E_{o2}=\\frac{1}{2}(target_{o2}-output_{o2})^{2}=0.00198189$\n",
        "\n",
        "$E_{total}=E_{o1}+E_{o2}=0.02323634$\n",
        "\n",
        "기존의 전체 오차 $E_{total}$가 0.02397190였으므로 1번의 역전파로 오차가 감소한 것을 확인할 수 있습니다. 인공 신경망의 학습은 오차를 최소화하는 가중치를 찾는 목적으로 순전파와 역전파를 반복하는 것을 말합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpUxChZLzSoY",
        "colab_type": "text"
      },
      "source": [
        "## 5.5 XOR 문제 - 다층 퍼셉트론 구현하기\n",
        "\n",
        "이번 챕터에서는 파이토치를 사용해서 다층 퍼셉트론을 구현하여 XOR 문제를 풀어보는 것을 시도해보겠습니다. 파이토치에서는 앞에서 배운 역전파가 아래의 두 줄의 코드로서 구현됩니다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HyPSCVObzWlv",
        "colab_type": "text"
      },
      "source": [
        "### 5.5.1 파이토치로 다층 퍼셉트론 구현하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPnqD7XhqmxI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xjq5eJ3Dza15",
        "colab_type": "text"
      },
      "source": [
        "GPU 연산이 가능하다면 GPU 연산을 하도록 하고, 랜덤 시드를 고정해줍니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oF0WAXGzaa3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# for reproducibility\n",
        "torch.manual_seed(777)\n",
        "if device == 'cuda':\n",
        "    torch.cuda.manual_seed_all(777)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgAqYFJRzdsB",
        "colab_type": "text"
      },
      "source": [
        "XOR 문제를 풀기 위한 입력과 출력을 정의해줍니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rty-zQd6zch2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = torch.FloatTensor([[0, 0], [0, 1], [1, 0], [1, 1]]).to(device)\n",
        "Y = torch.FloatTensor([[0], [1], [1], [0]]).to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWzP54Pwzgfo",
        "colab_type": "text"
      },
      "source": [
        "이제 다층 퍼셉트론을 설계합니다. 아래는 입력층, 은닉층1, 은닉층2, 은닉층3, 출력층을 가지는 은닉층이 3개인 인공 신경망입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UeNHtbcQzfQW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = nn.Sequential(\n",
        "          nn.Linear(2, 10, bias=True), # input_layer = 2, hidden_layer1 = 10\n",
        "          nn.Sigmoid(),\n",
        "          nn.Linear(10, 10, bias=True), # hidden_layer1 = 10, hidden_layer2 = 10\n",
        "          nn.Sigmoid(),\n",
        "          nn.Linear(10, 10, bias=True), # hidden_layer2 = 10, hidden_layer3 = 10\n",
        "          nn.Sigmoid(),\n",
        "          nn.Linear(10, 1, bias=True), # hidden_layer3 = 10, output_layer = 1\n",
        "          nn.Sigmoid()\n",
        "          ).to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "012IiTg9zj-w",
        "colab_type": "text"
      },
      "source": [
        "위 인공 신경망을 그림으로 표현하면 아래와 같습니다.\n",
        "\n",
        "![대체 텍스트](https://wikidocs.net/images/page/61010/ann.PNG)\n",
        "\n",
        "이제 비용 함수와 옵타마이저를 선언합니다. nn.BCELoss()는 이진 분류에서 사용하는 크로스엔트로피 함수입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYI8ngsiziVB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = torch.nn.BCELoss().to(device)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1)  # modified learning rate from 0.1 to 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPGW7zD7zqkU",
        "colab_type": "text"
      },
      "source": [
        "총 10,001번의 에포크를 수행합니다. 각 에포크마다 역전파가 수행된다고 보면 되겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2F8tNlRHzp5m",
        "colab_type": "code",
        "outputId": "143140f5-0e77-4270-bdfb-0cd800abc5e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for epoch in range(10001):\n",
        "    optimizer.zero_grad()\n",
        "    # forward 연산\n",
        "    hypothesis = model(X)\n",
        "\n",
        "    # 비용 함수\n",
        "    cost = criterion(hypothesis, Y)\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # 100의 배수에 해당되는 에포크마다 비용을 출력\n",
        "    if epoch % 100 == 0:\n",
        "        print(epoch, cost.item())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 0.6948983669281006\n",
            "100 0.693155825138092\n",
            "200 0.6931535601615906\n",
            "300 0.6931513547897339\n",
            "400 0.693149209022522\n",
            "500 0.6931473016738892\n",
            "600 0.6931453943252563\n",
            "700 0.6931434273719788\n",
            "800 0.6931416988372803\n",
            "900 0.6931397914886475\n",
            "1000 0.6931380033493042\n",
            "1100 0.6931361556053162\n",
            "1200 0.6931343078613281\n",
            "1300 0.6931324005126953\n",
            "1400 0.6931304931640625\n",
            "1500 0.6931284666061401\n",
            "1600 0.6931264400482178\n",
            "1700 0.6931242942810059\n",
            "1800 0.6931220889091492\n",
            "1900 0.6931196451187134\n",
            "2000 0.6931172013282776\n",
            "2100 0.6931145191192627\n",
            "2200 0.6931116580963135\n",
            "2300 0.6931084394454956\n",
            "2400 0.6931051015853882\n",
            "2500 0.6931014657020569\n",
            "2600 0.6930974721908569\n",
            "2700 0.6930930018424988\n",
            "2800 0.6930880546569824\n",
            "2900 0.6930825710296631\n",
            "3000 0.6930762529373169\n",
            "3100 0.6930692791938782\n",
            "3200 0.6930611729621887\n",
            "3300 0.6930519342422485\n",
            "3400 0.6930411458015442\n",
            "3500 0.6930283904075623\n",
            "3600 0.6930133104324341\n",
            "3700 0.6929951310157776\n",
            "3800 0.6929728984832764\n",
            "3900 0.6929453015327454\n",
            "4000 0.6929102540016174\n",
            "4100 0.6928649544715881\n",
            "4200 0.6928046941757202\n",
            "4300 0.692721962928772\n",
            "4400 0.692604124546051\n",
            "4500 0.6924278736114502\n",
            "4600 0.692147970199585\n",
            "4700 0.6916664242744446\n",
            "4800 0.6907395124435425\n",
            "4900 0.6886202692985535\n",
            "5000 0.6820817589759827\n",
            "5100 0.6472519040107727\n",
            "5200 0.4494302272796631\n",
            "5300 0.040939610451459885\n",
            "5400 0.00970230158418417\n",
            "5500 0.005025273654609919\n",
            "5600 0.003292433451861143\n",
            "5700 0.0024142316542565823\n",
            "5800 0.0018906600307673216\n",
            "5900 0.0015457108383998275\n",
            "6000 0.0013025678927078843\n",
            "6100 0.0011226193746551871\n",
            "6200 0.0009844244923442602\n",
            "6300 0.000875213067047298\n",
            "6400 0.0007868328830227256\n",
            "6500 0.000713969231583178\n",
            "6600 0.0006528761005029082\n",
            "6700 0.0006009864155203104\n",
            "6800 0.0005564499879255891\n",
            "6900 0.000517789856530726\n",
            "7000 0.00048388709546998143\n",
            "7100 0.0004540106747299433\n",
            "7200 0.0004274595994502306\n",
            "7300 0.0004037267644889653\n",
            "7400 0.0003823647275567055\n",
            "7500 0.00036304540117271245\n",
            "7600 0.00034555993624962866\n",
            "7700 0.0003295952337794006\n",
            "7800 0.00031497233430854976\n",
            "7900 0.0003015123074874282\n",
            "8000 0.00028917036252096295\n",
            "8100 0.0002777080226223916\n",
            "8200 0.000267095398157835\n",
            "8300 0.0002572430530562997\n",
            "8400 0.0002480615512467921\n",
            "8500 0.0002394912444287911\n",
            "8600 0.00023144265287555754\n",
            "8700 0.00022394562256522477\n",
            "8800 0.00021683613886125386\n",
            "8900 0.00021017386461608112\n",
            "9000 0.00020392893929965794\n",
            "9100 0.00019799702567979693\n",
            "9200 0.00019236328080296516\n",
            "9300 0.0001871021231636405\n",
            "9400 0.0001820496836444363\n",
            "9500 0.00017726552323438227\n",
            "9600 0.00017273474077228457\n",
            "9700 0.0001683977316133678\n",
            "9800 0.00016428431263193488\n",
            "9900 0.00016034975124057382\n",
            "10000 0.00015660893404856324\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrCl_S-OzwLk",
        "colab_type": "text"
      },
      "source": [
        "비용이 최소화 되는 방향으로 가중치와 편향이 업데이트 됩니다. 100배수의 에포크마다 비용이 줄어드는 과정을 보여줍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJDU8-78z4RZ",
        "colab_type": "text"
      },
      "source": [
        "### 5.5.2 학습된 다층 퍼셉트론의 예측값 확인하기\n",
        "\n",
        "이제 모델이 XOR 문제를 풀 수 있는지 테스트 해봅시다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7Lf9vIgzspt",
        "colab_type": "code",
        "outputId": "cbbe48a2-4e27-4abe-b3cd-87ba4f0f13cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        }
      },
      "source": [
        "with torch.no_grad():\n",
        "    hypothesis = model(X)\n",
        "    predicted = (hypothesis > 0.5).float()\n",
        "    accuracy = (predicted == Y).float().mean()\n",
        "    print('모델의 출력값(Hypothesis): ', hypothesis.detach().cpu().numpy())\n",
        "    print('모델의 예측값(Predicted): ', predicted.detach().cpu().numpy())\n",
        "    print('실제값(Y): ', Y.cpu().numpy())\n",
        "    print('정확도(Accuracy): ', accuracy.item())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "모델의 출력값(Hypothesis):  [[1.1174745e-04]\n",
            " [9.9982870e-01]\n",
            " [9.9984229e-01]\n",
            " [1.8542720e-04]]\n",
            "모델의 예측값(Predicted):  [[0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]]\n",
            "실제값(Y):  [[0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]]\n",
            "정확도(Accuracy):  1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52nHgyllz-0_",
        "colab_type": "text"
      },
      "source": [
        "실제값은 0, 1, 1, 0이며 예측값은 0, 1, 1, 0으로 문제를 해결하는 모습을 보여줍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEL85rjk0Np3",
        "colab_type": "text"
      },
      "source": [
        "## 5.6 비선형 활성화 함수(Activation function)\n",
        "\n",
        "비선형 활성화 함수(Activation function)는 입력을 받아 수학적 변환을 수행하고 출력을 생성하는 함수입니다. 앞서 배운 시그모이드 함수나 소프트맥스 함수는 대표적인 활성화 함수 중 하나입니다.\n",
        "\n",
        "이번 챕터에서는 인공 신경망의 은닉층에서 왜 활성화 함수로 시그모이드(sigmoid) 함수를 사용하는 것을 왜 지양해야 하는지와 은닉층에서 주로 사용되는 함수인 렐루(ReLU) 함수를 소개하고 그 외의 다른 활성화 함수들에 대해서도 소개합니다.\n",
        "\n",
        "이번 챕터에서는 그래프를 직접 그리면서 이해해보겠습니다. 우선 아래의 도구들을 모두 임포트했다고 가정합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blvxnQXOz9Qi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np # 넘파이 사용\n",
        "import matplotlib.pyplot as plt # 맷플롯립 사용"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUen7PKO0TTo",
        "colab_type": "text"
      },
      "source": [
        "### 5.6.1 활성화 함수의 특징 - 비선형 함수(Nonlinear function)\n",
        "\n",
        "활성화 함수의 특징은 선형 함수가 아닌 비선형 함수여야 한다는 점입니다. 선형 함수란 출력이 입력의 상수배만큼 변하는 함수를 선형함수라고 합니다. 예를 들어 $f(x)=Wx+b$라는 함수가 있을 때, $W$와 $b$는 상수입니다. 이 식은 그래프를 그리면 직선이 그려집니다. 반대로 비선형 함수는 직선 1개로는 그릴 수 없는 함수를 말합니다.\n",
        "\n",
        "인공 신경망의 능력을 높이기 위해서는 은닉층을 계속해서 추가해야 합니다. 그런데 만약 활성화 함수로 선형 함수를 사용하게 되면 은닉층을 쌓을 수가 없습니다. 예를 들어 활성화 함수로 선형 함수를 선택하고, 층을 계속 쌓는다고 가정해보겠습니다. 활성화 함수는 $f(x)=Wx$라고 가정합니다. 여기다가 은닉층을 두 개 추가한다고하면 출력층을 포함해서 $y(x)=f(f(f(x)))$가 됩니다. 이를 식으로 표현하면 $W$x$W$x$W$x$x$입니다. 그런데 이는 잘 생각해보면 W의 세 제곱값을 $k$라고 정의해버리면 $y(x)=kx$와 같이 다시 표현이 가능합니다. 즉, 선형 함수로는 은닉층을 여러번 추가하더라도 1회 추가한 것과 차이를 줄 수 없습니다.\n",
        "\n",
        "선형 함수를 사용한 은닉층을 1회 추가한 것과 연속으로 추가한 것이 차이가 없다는 뜻이지, 선형 함수를 사용한 층이 아무 의미가 없다는 뜻이 아닙니다. 학습 가능한 가중치가 새로 생긴다는 점에서 분명히 의미가 있습니다. 이와 같이 선형 함수를 사용한 층을 활성화 함수를 사용하는 은닉층과 구분하기 위해서 선형층(linear layer)이나 투사층(projection layer) 등의 다른 표현을 사용하여 표현하기도 합니다. 활성화 함수를 사용하는 일반적인 은닉층을 선형층과 대비되는 표현을 사용하면 비선형층(nonlinear layer)입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29uwM30A0ov5",
        "colab_type": "text"
      },
      "source": [
        "### 5.6.2 시그모이드 함수(Sigmoid function)와 기울기 소실\n",
        "\n",
        "시그모이드 함수를 사용한 어떤 인공 신경망이 있다고 가정해보겠습니다.\n",
        "\n",
        "![대체 텍스트](https://wikidocs.net/images/page/60683/simple-neural-network.png)\n",
        "\n",
        "위 인공 신경망의 학습 과정은 다음과 같습니다. 우선 인공 신경망은 입력에 대해서 순전파(forward propagation) 연산을 하고, 그리고 순전파 연산을 통해 나온 예측값과 실제값의 오차를 손실 함수(loss function)을 통해 계산하고, 그리고 이 손실(loss)을 미분을 통해서 기울기(gradient)를 구하고, 이를 통해 역전파(back propagation)를 수행합니다.\n",
        "\n",
        "그리고 시그모이드 함수의 문제점은 미분을 해서 기울기(gradient)를 구할 때 발생합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzZ2TxDn0Sg3",
        "colab_type": "code",
        "outputId": "076efbd3-c527-40c9-f921-f8f22824b2cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "# 시그모이드 함수 그래프를 그리는 코드\n",
        "def sigmoid(x):\n",
        "    return 1/(1+np.exp(-x))\n",
        "x = np.arange(-5.0, 5.0, 0.1)\n",
        "y = sigmoid(x)\n",
        "\n",
        "plt.plot(x, y)\n",
        "plt.plot([0,0],[1.0,0.0], ':') # 가운데 점선 추가\n",
        "plt.title('Sigmoid Function')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JJotcp501-l",
        "colab_type": "text"
      },
      "source": [
        "위의 그래프는 시그모이드 함수의 그래프를 보여줍니다. 위 그래프를 시그모이드 함수의 출력값이 0 또는 1에 가까워지면, 그래프의 기울기가 완만해지는 모습을 볼 수 있습니다. 기울기가 완만해지는 구간을 주황색, 그렇지 않은 구간을 초록색으로 칠해보겠습니다.\n",
        "\n",
        "![대체 텍스트](https://wikidocs.net/images/page/60683/%EC%8B%9C%EA%B7%B8%EB%AA%A8%EC%9D%B4%EB%93%9C%ED%95%A8%EC%88%982.PNG)\n",
        "\n",
        "주황색 부분은 기울기를 계산하면 0에 가까운 아주 작은 값이 나오게 됩니다. 그런데 역전파 과정에서 0에 가까운 아주 작은 기울기가 곱해지게 되면, 앞단에는 기울기가 잘 전달되지 않게 됩니다. 이러한 현상을 기울기 소실(Vanishing Gradient) 문제라고 합니다.\n",
        "\n",
        "시그모이드 함수를 사용하는 은닉층의 개수가 다수가 될 경우에는 0에 가까운 기울기가 계속 곱해지면 앞단에서는 거의 기울기를 전파받을 수 없게 됩니다. 다시 말해 매개변수 $W$가 업데이트 되지 않아 학습이 되지를 않습니다.\n",
        "\n",
        "![대체 텍스트](https://wikidocs.net/images/page/60683/%EA%B8%B0%EC%9A%B8%EA%B8%B0_%EC%86%8C%EC%8B%A4.png)\n",
        "\n",
        "위의 그림은 은닉층이 깊은 신경망에서 기울기 소실 문제로 인해 출력층과 가까운 은닉층에서는 기울기가 잘 전파되지만, 앞단으로 갈수록 기울기가 제대로 전파되지 않는 모습을 보여줍니다. 결론적으로 시그모이드 함수를 은닉층에서 사용하는 것은 지양됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juf4ZKts1MLY",
        "colab_type": "text"
      },
      "source": [
        "### 5.6.3 하이퍼볼릭탄젠트 함수(Hyperbolic tangent function)\n",
        "\n",
        "하이퍼볼릭탄젠트 함수(tanh)는 입력값을 -1과 1사이의 값으로 변환합니다. 그래프를 그려보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avcAhG1-0wVF",
        "colab_type": "code",
        "outputId": "cb999d50-3b82-4789-a667-d74d062fb316",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "x = np.arange(-5.0, 5.0, 0.1) # -5.0부터 5.0까지 0.1 간격 생성\n",
        "y = np.tanh(x)\n",
        "\n",
        "plt.plot(x, y)\n",
        "plt.plot([0,0],[1.0,-1.0], ':')\n",
        "plt.axhline(y=0, color='orange', linestyle='--')\n",
        "plt.title('Tanh Function')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEICAYAAABS0fM3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRCAikuGUCEREMpwSgYhIhlMiEBHJcP8fea8YxRLayMoAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91lVX6TJ1SDC",
        "colab_type": "text"
      },
      "source": [
        "하이퍼볼릭탄젠트 함수도 -1과 1에 가까운 출력값을 출력할 때, 시그모이드 함수와 같은 문제가 발생합니다. 그러나 하이퍼볼릭탄젠트 함수의 경우에는 시그모이드 함수와는 달리 0을 중심으로 하고 있는데, 이때문에 시그모이드 함수와 비교하면 반환값의 변화폭이 더 큽니다. 그래서 시그모이드 함수보다는 기울기 소실 증상이 적은 편입니다. 그래서 은닉층에서 시그모이드 함수보다는 많이 사용됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YV8FV571YXn",
        "colab_type": "text"
      },
      "source": [
        "### 5.6.4 렐루 함수(ReLU)\n",
        "\n",
        "인공 신경망에서 가장 최고의 인기를 얻고 있는 함수입니다. 수식은 $f(x)=max(0,x)$로 아주 간단합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjnS-V6B1QwD",
        "colab_type": "code",
        "outputId": "3ba6b9dd-93fa-4a2e-8d90-579e48482b3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "def relu(x):\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "x = np.arange(-5.0, 5.0, 0.1)\n",
        "y = relu(x)\n",
        "\n",
        "plt.plot(x, y)\n",
        "plt.plot([0,0],[5.0,0.0], ':')\n",
        "plt.title('Relu Function')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAEICAYAAAB25L6yAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNRFRyP0/6vZNhqUEEicAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKGTUYe81hWb",
        "colab_type": "text"
      },
      "source": [
        "렐루 함수는 음수를 입력하면 0을 출력하고, 양수를 입력하면 입력값을 그대로 반환합니다. 렐루 함수는 특정 양수값에 수렴하지 않으므로 깊은 신경망에서 시그모이드 함수보다 훨씬 더 잘 작동합니다. 뿐만 아니라, 렐루 함수는 시그모이드 함수와 하이퍼볼릭탄젠트 함수와 같이 어떤 연산이 필요한 것이 아니라 단순 임계값이므로 연산 속도도 빠릅니다.\n",
        "\n",
        "하지만 여전히 문제점이 존재하는데, 입력값이 음수면 기울기도 0이 됩니다. 그리고 이 뉴런은 다시 회생하는 것이 매우 어렵습니다. 이 문제를 죽은 렐루(dying ReLU)라고 합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJ57182T1inL",
        "colab_type": "text"
      },
      "source": [
        "### 5.6.5 리키 렐루(Leaky ReLU)\n",
        "\n",
        "죽은 렐루를 보완하기 위해 ReLU의 변형 함수들이 등장하기 시작했습니다. 변형 함수는 여러 개가 있지만 여기서는 Leaky ReLU에 대해서만 소개합니다. Leaky ReLU는 입력값이 음수일 경우에 0이 아니라 0.001과 같은 매우 작은 수를 반환하도록 되어있습니다.\n",
        "\n",
        "수식은 $f(x)=max(ax,x)$로 아주 간단합니다. a는 하이퍼파라미터로 Leaky('새는') 정도를 결정하며 일반적으로는 0.01의 값을 가집니다. 여기서 말하는 '새는 정도'라는 것은 입력값의 음수일 때의 기울기를 비유하고 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqUZ1GaS1fZr",
        "colab_type": "code",
        "outputId": "c2e0def3-9fd4-404c-b88a-c03cad60790a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "a = 0.1\n",
        "\n",
        "def leaky_relu(x):\n",
        "    return np.maximum(a*x, x)\n",
        "\n",
        "x = np.arange(-5.0, 5.0, 0.1)\n",
        "y = leaky_relu(x)\n",
        "\n",
        "plt.plot(x, y)\n",
        "plt.plot([0,0],[5.0,0.0], ':')\n",
        "plt.title('Leaky ReLU Function')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAEICAYAAAB25L6yAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\np0ItIhLjVKhFRGLc/wd9Xqe6EWpNhgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JfAC4Ee1rw4",
        "colab_type": "text"
      },
      "source": [
        "위의 그래프에서는 새는 모습을 확실히 보여주기 위해 a를 0.1로 잡았습니다. 위와 같이 입력값이 음수라도 기울기가 0이 되지 않으면 ReLU는 죽지 않습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iC6ht30d1tWt",
        "colab_type": "text"
      },
      "source": [
        "### 5.6.6 소프트맥스 함수(Softamx function)\n",
        "\n",
        "은닉층에서 ReLU(또는 ReLU 변형) 함수들을 사용하는 것이 일반적이지만 그렇다고 해서 앞서 배운 시그모이드 함수나 소프트맥스 함수가 사용되지 않는다는 의미는 아닙니다. 분류 문제를 로지스틱 회귀와 소프트맥스 회귀를 출력층에 적용하여 사용합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OeRsS9Ua1pe-",
        "colab_type": "code",
        "outputId": "74715ea8-f4fb-41e9-e993-f81a67d6e234",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "x = np.arange(-5.0, 5.0, 0.1) # -5.0부터 5.0까지 0.1 간격 생성\n",
        "y = np.exp(x) / np.sum(np.exp(x))\n",
        "\n",
        "plt.plot(x, y)\n",
        "plt.title('Softmax Function')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/X96ttOuNeBQYwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvzZAa811yZf",
        "colab_type": "text"
      },
      "source": [
        "소프트맥스 함수는 시그모이드 함수처럼 출력층의 뉴런에서 주로 사용되는데, 시그모이드 함수가 두 가지 선택지 중 하나를 고르는 이진 분류 (Binary Classification) 문제에 사용된다면 세 가지 이상의 (상호 배타적인) 선택지 중 하나를 고르는 다중 클래스 분류(MultiClass Classification) 문제에 주로 사용됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cx_jNIv610FD",
        "colab_type": "text"
      },
      "source": [
        "### 6.6.7 출력층의 활성화 함수와 오차 함수의 관계\n",
        "\n",
        "은닉층의 활성화 함수로는 ReLU 또는 Leaky ReLU와 같은 ReLU의 변형을 사용하라고 정리해봤습니다. 그렇다면 출력층은 어떨까요? 각 문제에 따른 출력층의 활성화 함수와 비용 함수의 관계를 정리해보면 다음과 같습니다. 이 외에도 다중 레이블 분류도 있지만 여기서는 다루지 않겠습니다.\n",
        "\n",
        "|문제|활성화 함수|비용 함수|\n",
        "|---|---|---|\n",
        "|이진 분류|시그모이드|nn.BCELoss()|\n",
        "|다중 클래스 분류|소프트맥스|nn.CrossEntropyLoss()|\n",
        "|회귀|없음|nn.MSELoss()|\n",
        "\n",
        "주의할 점은 nn.CrossEntropyLoss()는 소프트맥스 함수를 이미 포함하고 있습니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-kb4t862eCi",
        "colab_type": "text"
      },
      "source": [
        "참고 자료 : https://excelsior-cjh.tistory.com/177\n",
        "\n",
        "\n",
        "\n",
        "*   시그모이드 함수의 또 다른 문제점은 원점 중심이 아니라는 점입니다(Not zero-centered). 따라서, 평균이 0이 아니라 0.5이며, 시그모이드 함수는 항상 양수를 출력하기 때문에 출력의 가중치 합이 입력의 가중치 합보다 커질 가능성이 높습니다. 이것을 편향 이동(bias shift)이라 하며, 이러한 이유로 각 레이어를 지날 때마다 분산이 계속 커져 가장 높은 레이어에서는 활성화 함수의 출력이 0이나 1로 수렴하게 되어 기울기 소실 문제가 일어날 수 있습니다.\n",
        "\n",
        "\n",
        "*   하이퍼볼릭탄젠트 함수는 원점 중심(zero-centered)이기 때문에, 시그모이드와 달리 편향 이동은 일어나지 않습니다. 하지만, 하이퍼볼릭탄젠트 함수 또한 입력의 절대값이 클 경우 -1이나 1로 수렴하게 되는데 시그모이드 함수와 마찬가지로 이때 기울기가 완만해지므로 역시나 기울기 소실 문제가 일어날 수 있습니다.\n",
        "\n",
        "\n",
        "*    스탠포드 대학교의 딥 러닝 강의 cs231n에서는 ReLU를 먼저 시도해보고, 그다음으로 LeakyReLU나 ELU 같은 ReLU의 변형들을 시도해보며, sigmoid는 사용하지 말라고 권장합니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVOtdO5Y8IjU",
        "colab_type": "text"
      },
      "source": [
        "## 5.7 다층 퍼셉트론으로 손글씨 분류하기\n",
        "\n",
        "이번 챕터에서는 다층 퍼셉트론을 구현하고, 딥 러닝을 통해서 숫자 필기 데이터를 분류해봅시다.\n",
        "\n",
        "MNIST 데이터랑 다른 데이터입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPCrvEB_82W5",
        "colab_type": "text"
      },
      "source": [
        "### 5.7.1 숫자 필기 데이터 소개\n",
        "\n",
        "숫자 필기 데이터는 사이킷런 패키지에서 제공하는 분류용 예제 데이터입니다. 0부터 9까지의 숫자를 손으로 쓴 이미지 데이터로 load_digits() 명령으로 로드할 수 있습니다. 각 이미지는 0부터 15까지의 명암을 가지는 8 × 8 = 64 픽셀 해상도의 흑백 이미지입니다. 그리고 해당 이미지가 1,797개가 있습니다.\n",
        "\n",
        "load_digits()를 통해 이미지 데이터를 로드할 수 있습니다. 로드한 전체 데이터를 digits에 저장합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8eYVmmuq1xB9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt # 시각화를 위한 맷플롯립\n",
        "from sklearn.datasets import load_digits\n",
        "digits = load_digits() # 1,979개의 이미지 데이터 로드"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fF-PFb3O88lm",
        "colab_type": "text"
      },
      "source": [
        "첫번째 샘플을 출력해보겠습니다. .images[인덱스]를 사용하면 해당 인덱스의 이미지를 행렬로서 출력할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kzmcura987DV",
        "colab_type": "code",
        "outputId": "91d6d7e1-7d85-43da-b0f8-f617b211a31f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        }
      },
      "source": [
        "print(digits.images[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.  0.  5. 13.  9.  1.  0.  0.]\n",
            " [ 0.  0. 13. 15. 10. 15.  5.  0.]\n",
            " [ 0.  3. 15.  2.  0. 11.  8.  0.]\n",
            " [ 0.  4. 12.  0.  0.  8.  8.  0.]\n",
            " [ 0.  5.  8.  0.  0.  9.  8.  0.]\n",
            " [ 0.  4. 11.  0.  1. 12.  7.  0.]\n",
            " [ 0.  2. 14.  5. 10. 12.  0.  0.]\n",
            " [ 0.  0.  6. 13. 10.  0.  0.  0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pu8P5IHE8_Az",
        "colab_type": "text"
      },
      "source": [
        "첫번째 샘플이 8 × 8 행렬로 출력된 것을 볼 수 있습니다. 0을 흰색 도화지, 0보다 큰 숫자들을 검은색 점이라고 상상해보면 숫자 0의 실루엣처럼 보입니다. 실제로 레이블도 숫자 0인지 첫번째 샘플의 레이블을 확인해봅시다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZ-ehEw089x0",
        "colab_type": "code",
        "outputId": "961a290b-bb12-4fcf-f072-86eda05e364d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(digits.target[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-F8mXMW9Bhk",
        "colab_type": "text"
      },
      "source": [
        "첫번째 샘플의 레이블은 0인 것을 확인할 수 있습니다. 이런 샘플이 몇 개 있는지 확인해봅시다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqW_brkS9AWj",
        "colab_type": "code",
        "outputId": "598c62b6-8e14-4cbd-893f-056c6ed596f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print('전체 샘플의 수 : {}'.format(len(digits.images)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "전체 샘플의 수 : 1797\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPCdnSxT9EQy",
        "colab_type": "text"
      },
      "source": [
        "전체 샘플의 개수는 1,797개입니다. 전체 샘플 중에서 상위 5개의 샘플만 시각화해봅시다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yI7z_udN9Ct8",
        "colab_type": "code",
        "outputId": "f4f57fa2-3371-4e89-dd07-5ca475d0f6f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "images_and_labels = list(zip(digits.images, digits.target))\n",
        "for index, (image, label) in enumerate(images_and_labels[:5]): # 5개의 샘플만 출력\n",
        "    plt.subplot(2, 5, index + 1)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
        "    plt.title('sample: %i' % label)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV4AAABYCAYAAAC9BZ+zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmlCuy631qKUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTG1rugq9IMk",
        "colab_type": "text"
      },
      "source": [
        "상위 5개의 샘플을 시각화해봤는데, 순서대로 숫자 0, 1, 2, 3, 4의 손글씨인 것처럼 보입니다.\n",
        "상위 5개 샘플의 레이블을 확인해보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etNRegyR9GBC",
        "colab_type": "code",
        "outputId": "a4a32f74-c334-4234-c8ff-bd79ad99e83e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "for i in range(5):\n",
        "  print(i,'번 인덱스 샘플의 레이블 : ',digits.target[i])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 번 인덱스 샘플의 레이블 :  0\n",
            "1 번 인덱스 샘플의 레이블 :  1\n",
            "2 번 인덱스 샘플의 레이블 :  2\n",
            "3 번 인덱스 샘플의 레이블 :  3\n",
            "4 번 인덱스 샘플의 레이블 :  4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZqepXsM9Kep",
        "colab_type": "text"
      },
      "source": [
        "이제 훈련 데이터와 레이블을 각각 X, Y에 저장해봅시다. digits.images는 모든 샘플을 8 × 8 행렬로 저장하고 있습니다. 더 나은 방법은 digts.data를 사용하는 것입니다. 이는 8 × 8 행렬을 전부 64차원의 벡터로 변환해서 저장한 상태입니다. digits.data를 이용해서 첫번째 샘플을 출력해보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWWq76uW9Jre",
        "colab_type": "code",
        "outputId": "e5d0f168-ee41-46a7-8370-3db8b92cf60a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "print(digits.data[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0.  0.  5. 13.  9.  1.  0.  0.  0.  0. 13. 15. 10. 15.  5.  0.  0.  3.\n",
            " 15.  2.  0. 11.  8.  0.  0.  4. 12.  0.  0.  8.  8.  0.  0.  5.  8.  0.\n",
            "  0.  9.  8.  0.  0.  4. 11.  0.  1. 12.  7.  0.  0.  2. 14.  5. 10. 12.\n",
            "  0.  0.  0.  0.  6. 13. 10.  0.  0.  0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BkR58dP9Nl_",
        "colab_type": "text"
      },
      "source": [
        "8 × 8 행렬이 아니라 64차원의 벡터로 저장된 것을 볼 수 있습니다. 이를 X로 저장하고, 레이블을 Y에 저장합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcPDV6Am9MSv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = digits.data # 이미지. 즉, 특성 행렬\n",
        "Y = digits.target # 각 이미지에 대한 레이블"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xy90uido9P1u",
        "colab_type": "text"
      },
      "source": [
        "### 5.7.2 다층 퍼셉트론 분류기 만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTuwat899O2y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYsoZu_D9SjI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Linear(64, 32), # input_layer = 64, hidden_layer1 = 32\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(32, 16), # hidden_layer2 = 32, hidden_layer3 = 16\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(16, 10) # hidden_layer3 = 16, output_layer = 10\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0ZmbzXH9Tgr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = torch.tensor(X, dtype=torch.float32)\n",
        "Y = torch.tensor(Y, dtype=torch.int64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-Ukw2lC9Ua6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_fn = nn.CrossEntropyLoss() # 이 비용 함수는 소프트맥스 함수를 포함하고 있음.\n",
        "optimizer = optim.Adam(model.parameters())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evbdjC879WVT",
        "colab_type": "code",
        "outputId": "f47f83fb-b9d2-4841-b513-4c2b39d135bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "losses = []\n",
        "\n",
        "for epoch in range(200):\n",
        "  optimizer.zero_grad()\n",
        "  y_pred = model(X) # forwar 연산\n",
        "  loss = loss_fn(y_pred, Y)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  if epoch % 10 == 0:\n",
        "    print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
        "            epoch, 100, loss.item()\n",
        "        ))\n",
        "\n",
        "  losses.append(loss.item())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch    0/100 Cost: 0.029391\n",
            "Epoch   10/100 Cost: 0.022306\n",
            "Epoch   20/100 Cost: 0.017184\n",
            "Epoch   30/100 Cost: 0.013156\n",
            "Epoch   40/100 Cost: 0.010077\n",
            "Epoch   50/100 Cost: 0.007787\n",
            "Epoch   60/100 Cost: 0.006107\n",
            "Epoch   70/100 Cost: 0.004874\n",
            "Epoch   80/100 Cost: 0.003957\n",
            "Epoch   90/100 Cost: 0.003266\n",
            "Epoch  100/100 Cost: 0.002739\n",
            "Epoch  110/100 Cost: 0.002329\n",
            "Epoch  120/100 Cost: 0.002005\n",
            "Epoch  130/100 Cost: 0.001744\n",
            "Epoch  140/100 Cost: 0.001532\n",
            "Epoch  150/100 Cost: 0.001356\n",
            "Epoch  160/100 Cost: 0.001208\n",
            "Epoch  170/100 Cost: 0.001083\n",
            "Epoch  180/100 Cost: 0.000976\n",
            "Epoch  190/100 Cost: 0.000884\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DzEFqVQ9ZC6",
        "colab_type": "code",
        "outputId": "fb0b90e2-3452-4283-803c-fe7b330b2b4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "plt.plot(losses)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCgARkTilABARiVMKABGROPV/Y42qp+sr9XkAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCRf7ycX_yrR",
        "colab_type": "text"
      },
      "source": [
        "## 5.8 과적합(Overfitting)을 막는 방법들\n",
        "\n",
        "학습 데이터에 모델이 과적합되는 현상은 모델의 성능을 떨어트리는 주요 이슈입니다. 모델이 과적합되면 훈련 데이터에 대한 정확도는 높을지라도, 새로운 데이터. 즉, 검증 데이터나 테스트 데이터에 대해서는 제대로 동작하지 않습니다. 이는 모델이 학습 데이터를 불필요할정도로 과하게 암기하여 훈련 데이터에 포함된 노이즈까지 학습한 상태라고 해석할 수 있습니다. 이번 챕터에서는 모델의 과적합을 막을 수 있는 여러가지 방법에 대해서 논의합니다.\n",
        "\n",
        "특히 이 책은 딥 러닝을 다루고 있으므로, 인공 신경망의 과적합을 막는 방법에 초점을 둡니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ypVISky_3pY",
        "colab_type": "text"
      },
      "source": [
        "### 5.8.1 데이터의 양을 늘리기\n",
        "\n",
        "모델은 데이터의 양이 적을 경우, 해당 데이터의 특정 패턴이나 노이즈까지 쉽게 암기하기 되므로 과적합 현상이 발생할 확률이 늘어납니다. 그렇기 때문에 데이터의 양을 늘릴 수록 모델은 데이터의 일반적인 패턴을 학습하여 과적합을 방지할 수 있습니다.\n",
        "\n",
        "만약, 데이터의 양이 적을 경우에는 의도적으로 기존의 데이터를 조금씩 변형하고 추가하여 데이터의 양을 늘리기도 하는데 이를 데이터 증식 또는 증강(Data Augmentation)이라고 합니다. 이미지의 경우에는 데이터 증식이 많이 사용되는데 이미지를 돌리거나 노이즈를 추가하고, 일부분을 수정하는 등으로 데이터를 증식시킵니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYTnvWzk_7X5",
        "colab_type": "text"
      },
      "source": [
        "### 5.8.2 모델의 복잡도 줄이기\n",
        "\n",
        "인공 신경망의 복잡도는 은닉층(hidden layer)의 수나 매개변수의 수 등으로 결정됩니다. 과적합 현상이 포착되었을 때, 인공 신경망 모델에 대해서 할 수 있는 한 가지 조치는 인공 신경망의 복잡도를 줄이는 것 입니다. 예를 들어보겠습니다.\n",
        "\n",
        "다음과 같이 클래스를 사용하여 구현한 인공 신경망이 있다고 가정해봅시다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogSwGD9s9arb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Architecture1(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(Architecture1, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
        "        self.relu = nnReLU()\n",
        "        self.fc3 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc3(out)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFY1VsM1AHOT",
        "colab_type": "text"
      },
      "source": [
        "위 인공 신경망은 3개의 선형 레이어(Linear)를 가지고 있습니다. 위 인공 신경망이 입력 데이터에 과적합 현상을 보인다면, 다음과 같이 인공 신경망의 복잡도를 줄일 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUVf6zIk__Ed",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Architecture1(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(Architecture1, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nh2iEEuSANUI",
        "colab_type": "text"
      },
      "source": [
        "위 인공 신경망은 2개의 선형 레이어(Linear)를 가지고 있습니다.\n",
        "\n",
        "인공 신경망에서는 모델에 있는 매개변수들의 수를 모델의 수용력(capacity)이라고 하기도 합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_x_N6n9ARd6",
        "colab_type": "text"
      },
      "source": [
        "### 5.8.3 가중치 규제(Regularization) 적용하기\n",
        "\n",
        "복잡한 모델이 간단한 모델보다 과적합될 가능성이 높습니다. 그리고 간단한 모델은 적은 수의 매개변수를 가진 모델을 말합니다. 복잡한 모델을 좀 더 간단하게 하는 방법으로 가중치 규제(Regularizaiton)가 있습니다.\n",
        "\n",
        "\n",
        "*   L1 규제 : 가중치 w들의 절대값 합계를 비용 함수에 추가합니다. L1 노름이라고도 합니다.\n",
        "*   L2 규제 : 모든 가중치 w들의 제곱합을 비용 함수에 추가합니다. L2 노름이라고도 합니다.\n",
        "\n",
        "\n",
        "L1 규제는 기존의 비용 함수에 모든 가중치에 대해서 $\\lambda \\mid w \\mid$를 더 한 값을 비용 함수로 하고, L2 규제는 기존의 비용 함수에 모든 가중치에 대해서 $\\frac{1}{2} \\lambda w^2$를 더 한 값을 비용 함수로 합니다. $\\lambda$는 규제의 강도를 정하는 하이퍼파라미터입니다. $\\lambda$가 크다면 모델이 훈련 데이터에 대해서 적합한 매개 변수를 찾는 것보다 규제를 위해 추가된 항들을 작게 유지하는 것을 우선한다는 의미가 됩니다.\n",
        "\n",
        "이 두 식 모두 비용 함수를 최소화하기 위해서는 가중치 w들의 값이 작아져야 한다는 특징이 있습니다. L1 규제로 예를 들어봅시다. L1 규제를 사용하면 비용 함수가 최소가 되게 하는 가중치와 편향을 찾는 동시에 가중치들의 절대값의 합도 최소가 되어야 합니다. 이렇게 되면, 가중치 w의 값들은 0 또는 0에 가까이 작아져야 하므로 어떤 특성들은 모델을 만들 때 거의 사용되지 않게 됩니다.\n",
        "\n",
        "예를 들어 $H(x) = w_{1}x_{1} + w_{2}x_{2} + w_{3}x_{3} + w_{4}x_{4}$ 라는 수식이 있다고 해봅시다. 여기에 L1 규제를 사용하였더니, $w_3$의 값이 0이 되었다고 해봅시다. 이는 $x_3$ 특성은 사실 모델의 결과에 별 영향을 주지 못하는 특성임을 의미합니다.\n",
        "\n",
        "L2 규제는 L1 규제와는 달리 가중치들의 제곱을 최소화하므로 w의 값이 완전히 0이 되기보다는 0에 가까워지는 경향을 띕니다. L1 규제는 어떤 특성들이 모델에 영향을 주고 있는지를 정확히 판단하고자 할 때 유용합니다. 만약, 이런 판단이 필요없다면 경험적으로는 L2 규제가 더 잘 동작하므로 L2 규제를 더 권장합니다. 인공 신경망에서 L2 규제는 가중치 감쇠(weight decay)라고도 부릅니다.\n",
        "\n",
        "파이토치에서는 옵티마이저의 weight_decay 매개변수를 설정하므로서 L2 규제를 적용합니다. weight_decay 매개변수의 기본값은 0입니다. weight_decay 매개변수에 다른 값을 설정할 수도 있습니다.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "model = Architecture1(10, 20, 2)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "*   책에 따라서는 Regularization를 정규화로 번역하기도 하지만, 이는 정규화(Normalization)와 혼동될 수 있으므로 규제 또는 정형화라는 번역이 바람직한 것 같습니다. 정규화에 대한 설명은 링크 : http://blog.naver.com/angryking/221330145300 를 참고.\n",
        "*   인공 신경망에서 정규화(Normalization)라는 용어가 쓰이는 기법으로는 또 배치 정규화, 층 정규화 등이 있습니다.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqIjJRgdEHX7",
        "colab_type": "text"
      },
      "source": [
        "### 5.8.4 드롭아웃(Dropout)\n",
        "\n",
        "드롭아웃은 학습 과정에서 신경망의 일부를 사용하지 않는 방법입니다.\n",
        "\n",
        "![대체 텍스트](https://wikidocs.net/images/page/60751/%EB%93%9C%EB%A1%AD%EC%95%84%EC%9B%832.PNG)\n",
        "\n",
        "예를 들어 드롭아웃의 비율을 0.5로 한다면 학습 과정마다 랜덤으로 절반의 뉴런을 사용하지 않고, 절반의 뉴런만을 사용합니다.\n",
        "\n",
        "![대체 텍스트](https://wikidocs.net/images/page/60751/%EB%93%9C%EB%A1%AD%EC%95%84%EC%9B%83.PNG)\n",
        "\n",
        "드롭아웃은 신경망 학습 시에만 사용하고, 예측 시에는 사용하지 않는 것이 일반적입니다. 학습 시에 인공 신경망이 특정 뉴런 또는 특정 조합에 너무 의존적이게 되는 것을 방지해주고, 매번 랜덤 선택으로 뉴런들을 사용하지 않으므로 서로 다른 신경망들을 앙상블하여 사용하는 것 같은 효과를 내어 과적합을 방지합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLxcV21-Enwo",
        "colab_type": "text"
      },
      "source": [
        "## 5.9 기울기 소실(Gradient Vanishing)과 폭주(Exploding)\n",
        "\n",
        "깊은 인공 신경망을 학습하다보면 역전파 과정에서 입력층으로 갈 수록 기울기(Gradient)가 점차적으로 작아지는 현상이 발생할 수 있습니다. 입력층에 가까운 층들에서 가중치들이 업데이트가 제대로 되지 않으면 결국 최적의 모델을 찾을 수 없게 됩니다. 이를 기울기 소실(Gradient Vanishing)이라고 합니다.\n",
        "\n",
        "반대의 경우도 있습니다. 기울기가 점차 커지더니 가중치들이 비정상적으로 큰 값이 되면서 결국 발산되기도 합니다. 이를 기울기 폭주(Gradient Exploding)이라고 하며, 뒤에서 배울 순환 신경망(Recurrent Neural Network, RNN)에서 발생할 수 있습니다.\n",
        "\n",
        "이번 챕터에서는 기울기 소실 또는 기울기 폭주를 막는 방법들에 대해서 다룹니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Zo23RW2EspD",
        "colab_type": "text"
      },
      "source": [
        "### 5.9.1 ReLU와 ReLU의 변형들\n",
        "\n",
        "\n",
        "앞에서 배운 내용을 간단히 복습해봅시다. 시그모이드 함수를 사용하면 입력의 절대값이 클 경우에 시그모이드 함수의 출력값이 0 또는 1에 수렴하면서 기울기가 0에 가까워집니다. 그래서 역전파 과정에서 전파 시킬 기울기가 점차 사라져서 입력층 방향으로 갈 수록 제대로 역전파가 되지 않는 기울기 소실 문제가 발생할 수 있습니다.\n",
        "\n",
        "기울기 소실을 완화하는 가장 간단한 방법은 은닉층의 활성화 함수로 시그모이드나 하이퍼볼릭탄젠트 함수 대신에 ReLU나 ReLU의 변형 함수와 같은 Leaky ReLU를 사용하는 것입니다.\n",
        "\n",
        "\n",
        "\n",
        "*   은닉층에서는 시그모이드 함수를 사용하지 마세요.\n",
        "\n",
        "*   Leaky ReLU를 사용하면 모든 입력값에 대해서 기울기가 0에 수렴하지 않아 죽은 ReLU 문제를 해결합니다.\n",
        "\n",
        "*   은닉층에서는 ReLU나 Leaky ReLU와 같은 ReLU 함수의 변형들을 사용하세요.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7aSzlXnnFJPx",
        "colab_type": "text"
      },
      "source": [
        "### 5.9.2 가중치 초기화(Weight initialization)\n",
        "\n",
        "같은 모델을 훈련시키더라도 가중치가 초기에 어떤 값을 가졌느냐에 따라서 모델의 훈련 결과가 달라지기도 합니다. 다시 말해 가중치 초기화만 적절히 해줘도 기울기 소실 문제과 같은 문제를 완화시킬 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTgz8R4HFQFZ",
        "colab_type": "text"
      },
      "source": [
        "1) 세이비어 초기화(Xavier Initialization)\n",
        "논문 : http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf\n",
        "\n",
        "2010년 세이비어 글로럿과 요슈아 벤지오는 가중치 초기화가 모델에 미치는 영향을 분석하여 새로운 초기화 방법을 제안했습니다. 이 초기화 방법은 제안한 사람의 이름을 따서 세이비어(Xavier Initialization) 초기화 또는 글로럿 초기화(Glorot Initialization)라고 합니다.\n",
        "\n",
        "이 방법은 균등 분포(Uniform Distribution) 또는 정규 분포(Normal distribution)로 초기화 할 때 두 가지 경우로 나뉘며, 이전 층의 뉴런 개수와 다음 층의 뉴런 개수를 가지고 식을 세웁니다. 이전 층의 뉴런의 개수를 $n_{in}$, 다음 층의 뉴런의 개수를 $n_{out}$이라고 해봅시다.\n",
        "\n",
        "글로럿과 벤지오의 논문에서는 균등 분포를 사용하여 가중치를 초기화할 경우 다음과 같은 균등 분포 범위를 사용하라고 합니다.\n",
        "\n",
        "$W \\sim Uniform(-\\sqrt{\\frac{6}{ {n}_{in} + {n}_{out} }}, +\\sqrt{\\frac{6}{ {n}_{in} + {n}_{out} }})$\n",
        "\n",
        "다시 말해 $\\sqrt{\\frac{6}{ {n}_{in} + {n}_{out} }}$를  $m$이라고 하였을 때, -$m$과 +$m$ 사이의 균등 분포를 의미합니다.\n",
        "\n",
        "정규 분포로 초기화할 경우에는 평균이 0이고, 표준 편차 σ가 다음을 만족하도록 합니다.\n",
        "\n",
        "$\\sigma=\\sqrt{\\frac { 2 }{ { n }_{ in }+{ n }_{ out } } }$\n",
        "\n",
        "세이비어 초기화는 여러 층의 기울기 분산 사이에 균형을 맞춰서 특정 층이 너무 주목을 받거나 다른 층이 뒤쳐지는 것을 막습니다. 그런데 세이비어 초기화는 시그모이드 함수나 하이퍼볼릭 탄젠트 함수와 같은 S자 형태인 활성화 함수와 함께 사용할 경우에는 좋은 성능을 보이지만, ReLU와 함께 사용할 경우에는 성능이 좋지 않습니다. ReLU 함수 또는 ReLU의 변형 함수들을 활성화 함수로 사용할 경우에는 다른 초기화 방법을 사용하는 것이 좋은데, 이를 He 초기화(He initialization)라고 합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWVp9DgyGfdI",
        "colab_type": "text"
      },
      "source": [
        "2) He 초기화(He initialization)\n",
        "\n",
        "논문 : https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/He_Delving_Deep_into_ICCV_2015_paper.pdf\n",
        "\n",
        "He 초기화(He initialization)는 세이비어 초기화와 유사하게 정규 분포와 균등 분포 두 가지 경우로 나뉩니다. 다만, He 초기화는 세이비어 초기화와 다르게 다음 층의 뉴런의 수를 반영하지 않습니다. 전과 같이 이전 층의 뉴런의 개수를 $n_{in}$이라고 해봅시다.\n",
        "\n",
        "He 초기화는 균등 분포로 초기화 할 경우에는 다음과 같은 균등 분포 범위를 가지도록 합니다.\n",
        "\n",
        "$W\\sim Uniform(- \\sqrt{\\frac { 6 }{ { n }_{ in } } } , \\space\\space + \\sqrt{\\frac { 6 }{ { n }_{ in } } } )$\n",
        "\n",
        "정규 분포로 초기화할 경우에는 표준 편차 σ가 다음을 만족하도록 합니다.\n",
        "\n",
        "$\\sigma=\\sqrt{\\frac { 2 }{ { n }_{ in } } }$\n",
        "\n",
        "\n",
        "\n",
        "*   시그모이드 함수나 하이퍼볼릭탄젠트 함수를 사용할 경우에는 세이비어 초기화 방법이 효율적입니다.\n",
        "\n",
        "*   ReLU 계열 함수를 사용할 경우에는 He 초기화 방법이 효율적입니다.\n",
        "\n",
        "*   ReLU + He 초기화 방법이 좀 더 보편적입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lzBF_ScHElk",
        "colab_type": "text"
      },
      "source": [
        "### 5.9.3 배치 정규화(Batch Normalization)\n",
        "\n",
        "ReLU 계열의 함수와 He 초기화를 사용하는 것만으로도 어느 정도 기울기 소실과 폭주를 완화시킬 수 있지만, 이 두 방법을 사용하더라도 훈련 중에 언제든 다시 발생할 수 있습니다. 기울기 소실이나 폭주를 예방하는 또 다른 방법은 배치 정규화(Batch Normalization)입니다. 배치 정규화는 인공 신경망의 각 층에 들어가는 입력을 평균과 분산으로 정규화하여 학습을 효율적으로 만듭니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUL-cq51HJv6",
        "colab_type": "text"
      },
      "source": [
        "1) 내부 공변량 변화(Internal Covariate Shift)\n",
        "\n",
        "배치 정규화를 이해하기 위해서는 내부 공변량 변화(Internal Covariate Shift)를 이해할 필요가 있습니다. 내부 공변량 변화란 학습 과정에서 층 별로 입력 데이터 분포가 달라지는 현상을 말합니다. 이전 층들의 학습에 의해 이전 층의 가중치 값이 바뀌게 되면, 현재 층에 전달되는 입력 데이터의 분포가 현재 층이 학습했던 시점의 분포와 차이가 발생합니다. 배치 정규화를 제안한 논문에서는 기울기 소실/폭주 등의 딥 러닝 모델의 불안전성이 층마다 입력의 분포가 달라지기 때문이라고 주장합니다.\n",
        "\n",
        "\n",
        "\n",
        "*   공변량 변화는 훈련 데이터의 분포와 테스트 데이터의 분포가 다른 경우를 의미합니다.\n",
        "\n",
        "*   내부 공변량 변화는 신경망 층 사이에서 발생하는 입력 데이터의 분포 변화를 의미합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cH30GnkEHSZS",
        "colab_type": "text"
      },
      "source": [
        "2) 배치 정규화(Batch Normalization)\n",
        "\n",
        "배치 정규화(Batch Normalization)는 표현 그대로 한 번에 들어오는 배치 단위로 정규화하는 것을 말합니다. 배치 정규화는 각 층에서 활성화 함수를 통과하기 전에 수행됩니다. 배치 정규화를 요약하면 다음과 같습니다. 입력에 대해 평균을 0으로 만들고, 정규화를 합니다. 그리고 정규화 된 데이터에 대해서 스케일과 시프트를 수행합니다. 이 때 두 개의 매개변수 γ와 β를 사용하는데, γ는 스케일을 위해 사용하고, β는 시프트를 하는 것에 사용하며 다음 레이어에 일정한 범위의 값들만 전달되게 합니다.\n",
        "\n",
        "배치 정규화의 수식은 다음과 같습니다. 아래에서 $BN$은 배치 정규화를 의미합니다.\n",
        "\n",
        "Input : 미니배치 $B = \\{{x}^{(1)}, {x}^{(2)}, ..., {x}^{(m)}\\}$\n",
        "\n",
        "Output : $y^{(i)} = BN_{\\gamma, \\beta}(x^{(i)})$\n",
        "\n",
        "$\\mu_{B}$ ← $\\frac{1}{m} \\sum_{i=1}^{m} x^{(i)}$ # 미니배치에 대한 표준편차\n",
        "\n",
        "$\\sigma ^{2}_{B}$ ← $\\frac{1}{m} \\sum_{i=1}^{m} (x^{(i)} - \\mu _{B})^{2}$ # 미니 배치에 대한 표준편차\n",
        "\n",
        "$\\hat{x}^{(i)}$ ← $\\frac{x^{(i)} - \\mu _{B}}{\\sqrt{σ^{2}_{B}+\\epsilon}}$ # 정규화\n",
        "\n",
        "$y^{(i)}$ ← $\\gamma \\hat{x}^{(i)} + \\beta = BN_{\\gamma, \\beta}(x^{(i)})$ # 스케일 조정과 시프트\n",
        "\n",
        "\n",
        "\n",
        "*   $m$ 은 미니 배치에 있는 샘플의 수\n",
        "*   $\\mu _{B}$는 미니 배치 $B$에 대한 평균\n",
        "*$\\sigma_{B}$는 미니 배치 $B$에 대한 평균\n",
        "*$\\hat{x}^{(i)}$은 평균이 0이고 정규화 된 입력 데이터\n",
        "*$\\epsilon$ 은 분모가 0이 되는 것을 막는 작은 수. 보편적으로 $10^{-5}$\n",
        "*$\\gamma$ 는 정규화 된 데이터에 대한 스케일 매개변수로 학습 대상\n",
        "*$\\beta$는 정규화 된 데이터에 대한 시프트 매개변수로 학습 대상\n",
        "* $y^{(i)}$는 스케일과 시프트를 통해 조정한 $BN$의 최종 결과\n",
        "\n",
        "배치 정규화는 학습 시 배치 단위의 평균과 분산들을 차례대로 받아 이동 평균과 이동 분산을 저장해놓았다가 테스트 할 때는 해당 배치의 평균과 분산을 구하지 않고 구해놓았던 평균과 분산으로 정규화를 합니다.\n",
        "\n",
        "*   배치 정규화를 사용하면 시그모이드 함수나 하이퍼볼릭탄젠트 함수를 사용하더라도 기울기 소실 문제가 크게 개선됩니다.\n",
        "\n",
        "*   가중치 초기화에 훨씬 덜 민감해집니다.\n",
        "\n",
        "*   훨씬 큰 학습률을 사용할 수 있어 학습 속도를 개선시킵니다.\n",
        "\n",
        "*   미니 배치마다 평균과 표준편차를 계산하므로 훈련 데이터에 일종의 잡음을 넣는 부수 효과로 과적합을 방지하는 효과도 냅니다. 하지만 부수적 효과이므로 드롭 아웃과 함께 사용하는 것이 좋습니다.\n",
        "\n",
        "*   배치 정규화는 모델을 복잡하게 하며, 추가 계산을 하는 것이므로 테스트 데이터에 대한 예측 시에 실행 시간이 느려집니다. 그래서 서비스 속도를 고려하는 관점에서는 배치 정규화가 꼭 필요한지 고민이 필요합니다.\n",
        "\n",
        "*   배치 정규화의 효과는 굉장하지만 내부 공변량 변화때문은 아니라는 논문도 있습니다. : https://arxiv.org/pdf/1805.11604.pdf\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJhmFgPGJ5It",
        "colab_type": "text"
      },
      "source": [
        "3) 배치 정규화의 한계\n",
        "\n",
        "배치 정규화는 뛰어난 방법이지만 몇 가지 한계가 존재합니다.\n",
        "\n",
        "1. 미니 배치 크기에 의존적이다.\n",
        "배치 정규화는 너무 작은 배치 크기에서는 잘 동작하지 않을 수 있습니다. 단적으로 배치 크기를 1로 하게되면 분산은 0이 됩니다. 작은 미니 배치에서는 배치 정규화의 효과가 극단적으로 작용되어 훈련에 악영향을 줄 수 있습니다. 배치 정규화를 적용할때는 작은 미니 배치보다는 크기가 어느정도 되는 미니 배치에서 하는 것이 좋습니다. 이처럼 배치 정규화는 배치 크기에 의존적인 면이 있습니다.\n",
        "\n",
        "2. RNN에 적용하기 어렵다.\n",
        "뒤에서 배우겠지만, RNN은 각 시점(time step)마다 다른 통계치를 가집니다. 이는 RNN에 배치 정규화를 적용하는 것을 어렵게 만듭니다. RNN에서 배치 정규화를 적용하기 위한 몇 가지 논문이 제시되어 있지만, 여기서는 이를 소개하는 대신 배치 크기에도 의존적이지 않으며, RNN에도 적용하는 것이 수월한 층 정규화(layer normalization)라는 방법을 소개하고자 합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13o2gqwHKRCI",
        "colab_type": "text"
      },
      "source": [
        "### 5.9.4 층 정규화(Layer Normalization)\n",
        "\n",
        "층 정규화를 이해하기에 앞서 배치 정규화를 시각화해보겠습니다. 다음은 $m$이 3이고, 특성의 수가 4일 때의 배치 정규화를 보여줍니다. 미니 배치란 동일한 특성(feature) 개수들을 가진 다수의 샘플들을 의미함을 상기합시다.\n",
        "\n",
        "![대체 텍스트](https://wikidocs.net/images/page/61375/%EB%B0%B0%EC%B9%98%EC%A0%95%EA%B7%9C%ED%99%94.PNG)\n",
        "\n",
        "반면, 층 정규화는 다음과 같습니다.\n",
        "\n",
        "![대체 텍스트](https://wikidocs.net/images/page/61375/%EC%B8%B5%EC%A0%95%EA%B7%9C%ED%99%94.PNG)\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "가중치 초기화 참고 자료 :\n",
        "http://nlp.jbnu.ac.kr/AI2019/slides/ch05-1.pdf\n",
        "\n",
        "https://reniew.github.io/13/\n",
        "https://calcifer1009-dev.tistory.com/11\n",
        "\n",
        "\n",
        "\n",
        "배치 정규화 인터넷 강의(한국어 자막) :\n",
        "https://www.youtube.com/watch?v=tNIpEZLv_eg\n",
        "\n",
        "https://www.youtube.com/watch?v=em6dfRxYkYU\n",
        "\n",
        "https://www.youtube.com/watch?v=nUUqwaxLnWs\n",
        "\n",
        "\n",
        "\n",
        "배치 정규화 참고자료 :\n",
        "https://light-tree.tistory.com/139\n",
        "\n",
        "https://sacko.tistory.com/44?category=632408\n",
        "\n",
        "http://funmv2013.blogspot.com/2016/09/batch-normalization.html\n",
        "\n",
        "https://excelsior-cjh.tistory.com/178\n",
        "\n",
        "https://www.youtube.com/watch?v=HCEr5f-LfVE&list=PLQ28Nx3M4JrhkqBVIXg-i5_CVVoS1UzAv&index=17"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ox3VltnrAMJj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}