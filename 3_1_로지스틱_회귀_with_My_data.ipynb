{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled4.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO3mtUDlqUmKu3B64Hx1g2a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Namsik-Yoon/pytorch_basic/blob/master/3_1_%EB%A1%9C%EC%A7%80%EC%8A%A4%ED%8B%B1_%ED%9A%8C%EA%B7%80_with_My_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxbhNiKAFkcp",
        "colab_type": "text"
      },
      "source": [
        "sklearn에서 제공하는 유방암 데이터를 바탕으로 로지스틱 회귀모델 학습"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2H7G1KdFvTq",
        "colab_type": "text"
      },
      "source": [
        "# Data Load"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5IJnH5hFr3k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "breast_cancer = load_breast_cancer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awhKhxzuGih6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "858b6d9d-09db-4d68-c79a-6a4aa3b56207"
      },
      "source": [
        "print(breast_cancer.DESCR)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".. _breast_cancer_dataset:\n",
            "\n",
            "Breast cancer wisconsin (diagnostic) dataset\n",
            "--------------------------------------------\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "    :Number of Instances: 569\n",
            "\n",
            "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
            "\n",
            "    :Attribute Information:\n",
            "        - radius (mean of distances from center to points on the perimeter)\n",
            "        - texture (standard deviation of gray-scale values)\n",
            "        - perimeter\n",
            "        - area\n",
            "        - smoothness (local variation in radius lengths)\n",
            "        - compactness (perimeter^2 / area - 1.0)\n",
            "        - concavity (severity of concave portions of the contour)\n",
            "        - concave points (number of concave portions of the contour)\n",
            "        - symmetry \n",
            "        - fractal dimension (\"coastline approximation\" - 1)\n",
            "\n",
            "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
            "        largest values) of these features were computed for each image,\n",
            "        resulting in 30 features.  For instance, field 3 is Mean Radius, field\n",
            "        13 is Radius SE, field 23 is Worst Radius.\n",
            "\n",
            "        - class:\n",
            "                - WDBC-Malignant\n",
            "                - WDBC-Benign\n",
            "\n",
            "    :Summary Statistics:\n",
            "\n",
            "    ===================================== ====== ======\n",
            "                                           Min    Max\n",
            "    ===================================== ====== ======\n",
            "    radius (mean):                        6.981  28.11\n",
            "    texture (mean):                       9.71   39.28\n",
            "    perimeter (mean):                     43.79  188.5\n",
            "    area (mean):                          143.5  2501.0\n",
            "    smoothness (mean):                    0.053  0.163\n",
            "    compactness (mean):                   0.019  0.345\n",
            "    concavity (mean):                     0.0    0.427\n",
            "    concave points (mean):                0.0    0.201\n",
            "    symmetry (mean):                      0.106  0.304\n",
            "    fractal dimension (mean):             0.05   0.097\n",
            "    radius (standard error):              0.112  2.873\n",
            "    texture (standard error):             0.36   4.885\n",
            "    perimeter (standard error):           0.757  21.98\n",
            "    area (standard error):                6.802  542.2\n",
            "    smoothness (standard error):          0.002  0.031\n",
            "    compactness (standard error):         0.002  0.135\n",
            "    concavity (standard error):           0.0    0.396\n",
            "    concave points (standard error):      0.0    0.053\n",
            "    symmetry (standard error):            0.008  0.079\n",
            "    fractal dimension (standard error):   0.001  0.03\n",
            "    radius (worst):                       7.93   36.04\n",
            "    texture (worst):                      12.02  49.54\n",
            "    perimeter (worst):                    50.41  251.2\n",
            "    area (worst):                         185.2  4254.0\n",
            "    smoothness (worst):                   0.071  0.223\n",
            "    compactness (worst):                  0.027  1.058\n",
            "    concavity (worst):                    0.0    1.252\n",
            "    concave points (worst):               0.0    0.291\n",
            "    symmetry (worst):                     0.156  0.664\n",
            "    fractal dimension (worst):            0.055  0.208\n",
            "    ===================================== ====== ======\n",
            "\n",
            "    :Missing Attribute Values: None\n",
            "\n",
            "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
            "\n",
            "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
            "\n",
            "    :Donor: Nick Street\n",
            "\n",
            "    :Date: November, 1995\n",
            "\n",
            "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
            "https://goo.gl/U2Uwz2\n",
            "\n",
            "Features are computed from a digitized image of a fine needle\n",
            "aspirate (FNA) of a breast mass.  They describe\n",
            "characteristics of the cell nuclei present in the image.\n",
            "\n",
            "Separating plane described above was obtained using\n",
            "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
            "Construction Via Linear Programming.\" Proceedings of the 4th\n",
            "Midwest Artificial Intelligence and Cognitive Science Society,\n",
            "pp. 97-101, 1992], a classification method which uses linear\n",
            "programming to construct a decision tree.  Relevant features\n",
            "were selected using an exhaustive search in the space of 1-4\n",
            "features and 1-3 separating planes.\n",
            "\n",
            "The actual linear program used to obtain the separating plane\n",
            "in the 3-dimensional space is that described in:\n",
            "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
            "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
            "Optimization Methods and Software 1, 1992, 23-34].\n",
            "\n",
            "This database is also available through the UW CS ftp server:\n",
            "\n",
            "ftp ftp.cs.wisc.edu\n",
            "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
            "\n",
            ".. topic:: References\n",
            "\n",
            "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
            "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
            "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
            "     San Jose, CA, 1993.\n",
            "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
            "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
            "     July-August 1995.\n",
            "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
            "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
            "     163-171.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2rLBCdbGEWp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        },
        "outputId": "94ac3f5c-e2c3-467c-83d0-f0bb4231ad5f"
      },
      "source": [
        "cancer_df = pd.DataFrame(data=breast_cancer['data'],columns=breast_cancer['feature_names'])\n",
        "cancer_df"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>radius error</th>\n",
              "      <th>texture error</th>\n",
              "      <th>perimeter error</th>\n",
              "      <th>area error</th>\n",
              "      <th>smoothness error</th>\n",
              "      <th>compactness error</th>\n",
              "      <th>concavity error</th>\n",
              "      <th>concave points error</th>\n",
              "      <th>symmetry error</th>\n",
              "      <th>fractal dimension error</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.380</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.16220</td>\n",
              "      <td>0.66560</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.990</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.12380</td>\n",
              "      <td>0.18660</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.570</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.14440</td>\n",
              "      <td>0.42450</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.910</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.20980</td>\n",
              "      <td>0.86630</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.540</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.13740</td>\n",
              "      <td>0.20500</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>21.56</td>\n",
              "      <td>22.39</td>\n",
              "      <td>142.00</td>\n",
              "      <td>1479.0</td>\n",
              "      <td>0.11100</td>\n",
              "      <td>0.11590</td>\n",
              "      <td>0.24390</td>\n",
              "      <td>0.13890</td>\n",
              "      <td>0.1726</td>\n",
              "      <td>0.05623</td>\n",
              "      <td>1.1760</td>\n",
              "      <td>1.2560</td>\n",
              "      <td>7.673</td>\n",
              "      <td>158.70</td>\n",
              "      <td>0.010300</td>\n",
              "      <td>0.02891</td>\n",
              "      <td>0.05198</td>\n",
              "      <td>0.02454</td>\n",
              "      <td>0.01114</td>\n",
              "      <td>0.004239</td>\n",
              "      <td>25.450</td>\n",
              "      <td>26.40</td>\n",
              "      <td>166.10</td>\n",
              "      <td>2027.0</td>\n",
              "      <td>0.14100</td>\n",
              "      <td>0.21130</td>\n",
              "      <td>0.4107</td>\n",
              "      <td>0.2216</td>\n",
              "      <td>0.2060</td>\n",
              "      <td>0.07115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>20.13</td>\n",
              "      <td>28.25</td>\n",
              "      <td>131.20</td>\n",
              "      <td>1261.0</td>\n",
              "      <td>0.09780</td>\n",
              "      <td>0.10340</td>\n",
              "      <td>0.14400</td>\n",
              "      <td>0.09791</td>\n",
              "      <td>0.1752</td>\n",
              "      <td>0.05533</td>\n",
              "      <td>0.7655</td>\n",
              "      <td>2.4630</td>\n",
              "      <td>5.203</td>\n",
              "      <td>99.04</td>\n",
              "      <td>0.005769</td>\n",
              "      <td>0.02423</td>\n",
              "      <td>0.03950</td>\n",
              "      <td>0.01678</td>\n",
              "      <td>0.01898</td>\n",
              "      <td>0.002498</td>\n",
              "      <td>23.690</td>\n",
              "      <td>38.25</td>\n",
              "      <td>155.00</td>\n",
              "      <td>1731.0</td>\n",
              "      <td>0.11660</td>\n",
              "      <td>0.19220</td>\n",
              "      <td>0.3215</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.2572</td>\n",
              "      <td>0.06637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>16.60</td>\n",
              "      <td>28.08</td>\n",
              "      <td>108.30</td>\n",
              "      <td>858.1</td>\n",
              "      <td>0.08455</td>\n",
              "      <td>0.10230</td>\n",
              "      <td>0.09251</td>\n",
              "      <td>0.05302</td>\n",
              "      <td>0.1590</td>\n",
              "      <td>0.05648</td>\n",
              "      <td>0.4564</td>\n",
              "      <td>1.0750</td>\n",
              "      <td>3.425</td>\n",
              "      <td>48.55</td>\n",
              "      <td>0.005903</td>\n",
              "      <td>0.03731</td>\n",
              "      <td>0.04730</td>\n",
              "      <td>0.01557</td>\n",
              "      <td>0.01318</td>\n",
              "      <td>0.003892</td>\n",
              "      <td>18.980</td>\n",
              "      <td>34.12</td>\n",
              "      <td>126.70</td>\n",
              "      <td>1124.0</td>\n",
              "      <td>0.11390</td>\n",
              "      <td>0.30940</td>\n",
              "      <td>0.3403</td>\n",
              "      <td>0.1418</td>\n",
              "      <td>0.2218</td>\n",
              "      <td>0.07820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>20.60</td>\n",
              "      <td>29.33</td>\n",
              "      <td>140.10</td>\n",
              "      <td>1265.0</td>\n",
              "      <td>0.11780</td>\n",
              "      <td>0.27700</td>\n",
              "      <td>0.35140</td>\n",
              "      <td>0.15200</td>\n",
              "      <td>0.2397</td>\n",
              "      <td>0.07016</td>\n",
              "      <td>0.7260</td>\n",
              "      <td>1.5950</td>\n",
              "      <td>5.772</td>\n",
              "      <td>86.22</td>\n",
              "      <td>0.006522</td>\n",
              "      <td>0.06158</td>\n",
              "      <td>0.07117</td>\n",
              "      <td>0.01664</td>\n",
              "      <td>0.02324</td>\n",
              "      <td>0.006185</td>\n",
              "      <td>25.740</td>\n",
              "      <td>39.42</td>\n",
              "      <td>184.60</td>\n",
              "      <td>1821.0</td>\n",
              "      <td>0.16500</td>\n",
              "      <td>0.86810</td>\n",
              "      <td>0.9387</td>\n",
              "      <td>0.2650</td>\n",
              "      <td>0.4087</td>\n",
              "      <td>0.12400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>7.76</td>\n",
              "      <td>24.54</td>\n",
              "      <td>47.92</td>\n",
              "      <td>181.0</td>\n",
              "      <td>0.05263</td>\n",
              "      <td>0.04362</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1587</td>\n",
              "      <td>0.05884</td>\n",
              "      <td>0.3857</td>\n",
              "      <td>1.4280</td>\n",
              "      <td>2.548</td>\n",
              "      <td>19.15</td>\n",
              "      <td>0.007189</td>\n",
              "      <td>0.00466</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.02676</td>\n",
              "      <td>0.002783</td>\n",
              "      <td>9.456</td>\n",
              "      <td>30.37</td>\n",
              "      <td>59.16</td>\n",
              "      <td>268.6</td>\n",
              "      <td>0.08996</td>\n",
              "      <td>0.06444</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.2871</td>\n",
              "      <td>0.07039</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows × 30 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     mean radius  mean texture  ...  worst symmetry  worst fractal dimension\n",
              "0          17.99         10.38  ...          0.4601                  0.11890\n",
              "1          20.57         17.77  ...          0.2750                  0.08902\n",
              "2          19.69         21.25  ...          0.3613                  0.08758\n",
              "3          11.42         20.38  ...          0.6638                  0.17300\n",
              "4          20.29         14.34  ...          0.2364                  0.07678\n",
              "..           ...           ...  ...             ...                      ...\n",
              "564        21.56         22.39  ...          0.2060                  0.07115\n",
              "565        20.13         28.25  ...          0.2572                  0.06637\n",
              "566        16.60         28.08  ...          0.2218                  0.07820\n",
              "567        20.60         29.33  ...          0.4087                  0.12400\n",
              "568         7.76         24.54  ...          0.2871                  0.07039\n",
              "\n",
              "[569 rows x 30 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oH7t18MaGmB4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        },
        "outputId": "c4c36294-b5d3-40a1-f732-e66e836c0a4a"
      },
      "source": [
        "data = cancer_df\n",
        "data = data.apply(\n",
        "    lambda x: (x - x.mean()) / x.std()\n",
        ")\n",
        "data['target'] = breast_cancer['target']\n",
        "data"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>radius error</th>\n",
              "      <th>texture error</th>\n",
              "      <th>perimeter error</th>\n",
              "      <th>area error</th>\n",
              "      <th>smoothness error</th>\n",
              "      <th>compactness error</th>\n",
              "      <th>concavity error</th>\n",
              "      <th>concave points error</th>\n",
              "      <th>symmetry error</th>\n",
              "      <th>fractal dimension error</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.096100</td>\n",
              "      <td>-2.071512</td>\n",
              "      <td>1.268817</td>\n",
              "      <td>0.983510</td>\n",
              "      <td>1.567087</td>\n",
              "      <td>3.280628</td>\n",
              "      <td>2.650542</td>\n",
              "      <td>2.530249</td>\n",
              "      <td>2.215566</td>\n",
              "      <td>2.253764</td>\n",
              "      <td>2.487545</td>\n",
              "      <td>-0.564768</td>\n",
              "      <td>2.830540</td>\n",
              "      <td>2.485391</td>\n",
              "      <td>-0.213814</td>\n",
              "      <td>1.315704</td>\n",
              "      <td>0.723390</td>\n",
              "      <td>0.660239</td>\n",
              "      <td>1.147747</td>\n",
              "      <td>0.906286</td>\n",
              "      <td>1.885031</td>\n",
              "      <td>-1.358098</td>\n",
              "      <td>2.301575</td>\n",
              "      <td>1.999478</td>\n",
              "      <td>1.306537</td>\n",
              "      <td>2.614365</td>\n",
              "      <td>2.107672</td>\n",
              "      <td>2.294058</td>\n",
              "      <td>2.748204</td>\n",
              "      <td>1.935312</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.828212</td>\n",
              "      <td>-0.353322</td>\n",
              "      <td>1.684473</td>\n",
              "      <td>1.907030</td>\n",
              "      <td>-0.826235</td>\n",
              "      <td>-0.486643</td>\n",
              "      <td>-0.023825</td>\n",
              "      <td>0.547662</td>\n",
              "      <td>0.001391</td>\n",
              "      <td>-0.867889</td>\n",
              "      <td>0.498816</td>\n",
              "      <td>-0.875473</td>\n",
              "      <td>0.263095</td>\n",
              "      <td>0.741749</td>\n",
              "      <td>-0.604819</td>\n",
              "      <td>-0.692317</td>\n",
              "      <td>-0.440393</td>\n",
              "      <td>0.259933</td>\n",
              "      <td>-0.804742</td>\n",
              "      <td>-0.099356</td>\n",
              "      <td>1.804340</td>\n",
              "      <td>-0.368879</td>\n",
              "      <td>1.533776</td>\n",
              "      <td>1.888827</td>\n",
              "      <td>-0.375282</td>\n",
              "      <td>-0.430066</td>\n",
              "      <td>-0.146620</td>\n",
              "      <td>1.086129</td>\n",
              "      <td>-0.243675</td>\n",
              "      <td>0.280943</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.578499</td>\n",
              "      <td>0.455786</td>\n",
              "      <td>1.565126</td>\n",
              "      <td>1.557513</td>\n",
              "      <td>0.941382</td>\n",
              "      <td>1.052000</td>\n",
              "      <td>1.362280</td>\n",
              "      <td>2.035440</td>\n",
              "      <td>0.938859</td>\n",
              "      <td>-0.397658</td>\n",
              "      <td>1.227596</td>\n",
              "      <td>-0.779398</td>\n",
              "      <td>0.850180</td>\n",
              "      <td>1.180298</td>\n",
              "      <td>-0.296744</td>\n",
              "      <td>0.814257</td>\n",
              "      <td>0.212889</td>\n",
              "      <td>1.423575</td>\n",
              "      <td>0.236827</td>\n",
              "      <td>0.293301</td>\n",
              "      <td>1.510541</td>\n",
              "      <td>-0.023953</td>\n",
              "      <td>1.346291</td>\n",
              "      <td>1.455004</td>\n",
              "      <td>0.526944</td>\n",
              "      <td>1.081980</td>\n",
              "      <td>0.854222</td>\n",
              "      <td>1.953282</td>\n",
              "      <td>1.151242</td>\n",
              "      <td>0.201214</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.768233</td>\n",
              "      <td>0.253509</td>\n",
              "      <td>-0.592166</td>\n",
              "      <td>-0.763792</td>\n",
              "      <td>3.280667</td>\n",
              "      <td>3.399917</td>\n",
              "      <td>1.914213</td>\n",
              "      <td>1.450431</td>\n",
              "      <td>2.864862</td>\n",
              "      <td>4.906602</td>\n",
              "      <td>0.326087</td>\n",
              "      <td>-0.110312</td>\n",
              "      <td>0.286341</td>\n",
              "      <td>-0.288125</td>\n",
              "      <td>0.689095</td>\n",
              "      <td>2.741868</td>\n",
              "      <td>0.818798</td>\n",
              "      <td>1.114027</td>\n",
              "      <td>4.728520</td>\n",
              "      <td>2.045711</td>\n",
              "      <td>-0.281217</td>\n",
              "      <td>0.133866</td>\n",
              "      <td>-0.249720</td>\n",
              "      <td>-0.549538</td>\n",
              "      <td>3.391291</td>\n",
              "      <td>3.889975</td>\n",
              "      <td>1.987839</td>\n",
              "      <td>2.173873</td>\n",
              "      <td>6.040726</td>\n",
              "      <td>4.930672</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.748758</td>\n",
              "      <td>-1.150804</td>\n",
              "      <td>1.775011</td>\n",
              "      <td>1.824624</td>\n",
              "      <td>0.280125</td>\n",
              "      <td>0.538866</td>\n",
              "      <td>1.369806</td>\n",
              "      <td>1.427237</td>\n",
              "      <td>-0.009552</td>\n",
              "      <td>-0.561956</td>\n",
              "      <td>1.269426</td>\n",
              "      <td>-0.789549</td>\n",
              "      <td>1.272070</td>\n",
              "      <td>1.189310</td>\n",
              "      <td>1.481763</td>\n",
              "      <td>-0.048477</td>\n",
              "      <td>0.827742</td>\n",
              "      <td>1.143199</td>\n",
              "      <td>-0.360775</td>\n",
              "      <td>0.498889</td>\n",
              "      <td>1.297434</td>\n",
              "      <td>-1.465481</td>\n",
              "      <td>1.337363</td>\n",
              "      <td>1.219651</td>\n",
              "      <td>0.220362</td>\n",
              "      <td>-0.313119</td>\n",
              "      <td>0.612640</td>\n",
              "      <td>0.728618</td>\n",
              "      <td>-0.867590</td>\n",
              "      <td>-0.396751</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>2.109139</td>\n",
              "      <td>0.720838</td>\n",
              "      <td>2.058974</td>\n",
              "      <td>2.341795</td>\n",
              "      <td>1.040926</td>\n",
              "      <td>0.218868</td>\n",
              "      <td>1.945573</td>\n",
              "      <td>2.318924</td>\n",
              "      <td>-0.312314</td>\n",
              "      <td>-0.930209</td>\n",
              "      <td>2.779634</td>\n",
              "      <td>0.070963</td>\n",
              "      <td>2.377491</td>\n",
              "      <td>2.601897</td>\n",
              "      <td>1.085429</td>\n",
              "      <td>0.191637</td>\n",
              "      <td>0.665416</td>\n",
              "      <td>2.065360</td>\n",
              "      <td>-1.137415</td>\n",
              "      <td>0.167832</td>\n",
              "      <td>1.899514</td>\n",
              "      <td>0.117596</td>\n",
              "      <td>1.751022</td>\n",
              "      <td>2.013529</td>\n",
              "      <td>0.378033</td>\n",
              "      <td>-0.273077</td>\n",
              "      <td>0.663928</td>\n",
              "      <td>1.627719</td>\n",
              "      <td>-1.358963</td>\n",
              "      <td>-0.708467</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>1.703356</td>\n",
              "      <td>2.083301</td>\n",
              "      <td>1.614511</td>\n",
              "      <td>1.722326</td>\n",
              "      <td>0.102368</td>\n",
              "      <td>-0.017817</td>\n",
              "      <td>0.692434</td>\n",
              "      <td>1.262558</td>\n",
              "      <td>-0.217473</td>\n",
              "      <td>-1.057681</td>\n",
              "      <td>1.299356</td>\n",
              "      <td>2.258951</td>\n",
              "      <td>1.155840</td>\n",
              "      <td>1.290429</td>\n",
              "      <td>-0.423637</td>\n",
              "      <td>-0.069697</td>\n",
              "      <td>0.251980</td>\n",
              "      <td>0.807720</td>\n",
              "      <td>-0.188995</td>\n",
              "      <td>-0.490124</td>\n",
              "      <td>1.535369</td>\n",
              "      <td>2.045599</td>\n",
              "      <td>1.420690</td>\n",
              "      <td>1.493644</td>\n",
              "      <td>-0.690623</td>\n",
              "      <td>-0.394473</td>\n",
              "      <td>0.236365</td>\n",
              "      <td>0.733182</td>\n",
              "      <td>-0.531387</td>\n",
              "      <td>-0.973122</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>0.701667</td>\n",
              "      <td>2.043775</td>\n",
              "      <td>0.672084</td>\n",
              "      <td>0.577445</td>\n",
              "      <td>-0.839745</td>\n",
              "      <td>-0.038646</td>\n",
              "      <td>0.046547</td>\n",
              "      <td>0.105684</td>\n",
              "      <td>-0.808406</td>\n",
              "      <td>-0.894800</td>\n",
              "      <td>0.184730</td>\n",
              "      <td>-0.257145</td>\n",
              "      <td>0.276450</td>\n",
              "      <td>0.180539</td>\n",
              "      <td>-0.379008</td>\n",
              "      <td>0.660696</td>\n",
              "      <td>0.510377</td>\n",
              "      <td>0.611619</td>\n",
              "      <td>-0.890632</td>\n",
              "      <td>0.036694</td>\n",
              "      <td>0.560868</td>\n",
              "      <td>1.373645</td>\n",
              "      <td>0.578492</td>\n",
              "      <td>0.427529</td>\n",
              "      <td>-0.808876</td>\n",
              "      <td>0.350427</td>\n",
              "      <td>0.326479</td>\n",
              "      <td>0.413705</td>\n",
              "      <td>-1.103578</td>\n",
              "      <td>-0.318129</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>1.836725</td>\n",
              "      <td>2.334403</td>\n",
              "      <td>1.980781</td>\n",
              "      <td>1.733693</td>\n",
              "      <td>1.524426</td>\n",
              "      <td>3.269267</td>\n",
              "      <td>3.294046</td>\n",
              "      <td>2.656528</td>\n",
              "      <td>2.135315</td>\n",
              "      <td>1.042778</td>\n",
              "      <td>1.156917</td>\n",
              "      <td>0.685485</td>\n",
              "      <td>1.437265</td>\n",
              "      <td>1.008615</td>\n",
              "      <td>-0.172848</td>\n",
              "      <td>2.015943</td>\n",
              "      <td>1.301140</td>\n",
              "      <td>0.785031</td>\n",
              "      <td>0.326346</td>\n",
              "      <td>0.903262</td>\n",
              "      <td>1.959515</td>\n",
              "      <td>2.235958</td>\n",
              "      <td>2.301575</td>\n",
              "      <td>1.651717</td>\n",
              "      <td>1.429169</td>\n",
              "      <td>3.901415</td>\n",
              "      <td>3.194794</td>\n",
              "      <td>2.287972</td>\n",
              "      <td>1.917396</td>\n",
              "      <td>2.217684</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>-1.806811</td>\n",
              "      <td>1.220718</td>\n",
              "      <td>-1.812793</td>\n",
              "      <td>-1.346604</td>\n",
              "      <td>-3.109349</td>\n",
              "      <td>-1.149741</td>\n",
              "      <td>-1.113893</td>\n",
              "      <td>-1.260710</td>\n",
              "      <td>-0.819349</td>\n",
              "      <td>-0.560539</td>\n",
              "      <td>-0.070217</td>\n",
              "      <td>0.382756</td>\n",
              "      <td>-0.157311</td>\n",
              "      <td>-0.465742</td>\n",
              "      <td>0.049299</td>\n",
              "      <td>-1.162493</td>\n",
              "      <td>-1.056571</td>\n",
              "      <td>-1.911765</td>\n",
              "      <td>0.752168</td>\n",
              "      <td>-0.382418</td>\n",
              "      <td>-1.409652</td>\n",
              "      <td>0.763518</td>\n",
              "      <td>-1.431475</td>\n",
              "      <td>-1.074867</td>\n",
              "      <td>-1.857384</td>\n",
              "      <td>-1.206491</td>\n",
              "      <td>-1.304683</td>\n",
              "      <td>-1.743529</td>\n",
              "      <td>-0.048096</td>\n",
              "      <td>-0.750546</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows × 31 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     mean radius  mean texture  ...  worst fractal dimension  target\n",
              "0       1.096100     -2.071512  ...                 1.935312       0\n",
              "1       1.828212     -0.353322  ...                 0.280943       0\n",
              "2       1.578499      0.455786  ...                 0.201214       0\n",
              "3      -0.768233      0.253509  ...                 4.930672       0\n",
              "4       1.748758     -1.150804  ...                -0.396751       0\n",
              "..           ...           ...  ...                      ...     ...\n",
              "564     2.109139      0.720838  ...                -0.708467       0\n",
              "565     1.703356      2.083301  ...                -0.973122       0\n",
              "566     0.701667      2.043775  ...                -0.318129       0\n",
              "567     1.836725      2.334403  ...                 2.217684       0\n",
              "568    -1.806811      1.220718  ...                -0.750546       1\n",
              "\n",
              "[569 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2FCKsXmG1ZK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "acd122c3-b53e-4cec-94d7-a355fad6ceaf"
      },
      "source": [
        "X,y = data.values[:,:-1],data.values[:,-1:]\n",
        "print(X.shape,y.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(569, 30) (569, 1)\n",
            "(569, 30) (569, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tj7_IFSgG_LP",
        "colab_type": "text"
      },
      "source": [
        "# Set Custom Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-PMlzjSG6oj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-VlszMLHB9p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self):\n",
        "        self.x_data = torch.tensor(X,dtype=torch.float)\n",
        "        self.y_data = torch.tensor(y,dtype=torch.float)\n",
        "    def __len__(self):\n",
        "        return len(self.x_data)\n",
        "\n",
        "    def __getitem__(self,idx):\n",
        "        x = self.x_data[idx]\n",
        "        y = self.y_data[idx]\n",
        "        return x,y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ja1xKvrRHDu5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = MyDataset()\n",
        "dataloader = DataLoader(dataset, batch_size=len(dataset), shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZoIBVcRHIyB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BinaryClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(30, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.sigmoid(self.linear(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8hHrM3BHfrZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = BinaryClassifier()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.05)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTLlS_NUHMGh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "07fe3647-9e4f-44df-a755-23243b03b548"
      },
      "source": [
        "nb_epochs = 1000\n",
        "for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    # H(x) 계산\n",
        "    hypothesis = model(x_train)\n",
        "\n",
        "    # cost 계산\n",
        "    cost = F.binary_cross_entropy(hypothesis, y_train)\n",
        "\n",
        "    # cost로 H(x) 개선\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # 20번마다 로그 출력\n",
        "    if epoch % 10 == 0:\n",
        "        prediction = hypothesis >= torch.FloatTensor([0.5]) # 예측값이 0.5를 넘으면 True로 간주\n",
        "        correct_prediction = prediction.float() == y_train # 실제값과 일치하는 경우만 True로 간주\n",
        "        accuracy = correct_prediction.sum().item() / len(correct_prediction) # 정확도를 계산\n",
        "        print('Epoch {:4d}/{} Cost: {:.6f} Accuracy {:2.2f}%'.format( # 각 에포크마다 정확도를 출력\n",
        "            epoch, nb_epochs, cost.item(), accuracy * 100,\n",
        "        ))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch    0/1000 Cost: 0.176482 Accuracy 95.78%\n",
            "Epoch   10/1000 Cost: 0.164015 Accuracy 95.78%\n",
            "Epoch   20/1000 Cost: 0.154353 Accuracy 96.13%\n",
            "Epoch   30/1000 Cost: 0.146595 Accuracy 96.31%\n",
            "Epoch   40/1000 Cost: 0.140195 Accuracy 96.66%\n",
            "Epoch   50/1000 Cost: 0.134805 Accuracy 96.66%\n",
            "Epoch   60/1000 Cost: 0.130185 Accuracy 96.66%\n",
            "Epoch   70/1000 Cost: 0.126172 Accuracy 96.66%\n",
            "Epoch   80/1000 Cost: 0.122644 Accuracy 96.84%\n",
            "Epoch   90/1000 Cost: 0.119513 Accuracy 96.84%\n",
            "Epoch  100/1000 Cost: 0.116709 Accuracy 96.84%\n",
            "Epoch  110/1000 Cost: 0.114181 Accuracy 96.84%\n",
            "Epoch  120/1000 Cost: 0.111886 Accuracy 96.84%\n",
            "Epoch  130/1000 Cost: 0.109792 Accuracy 97.19%\n",
            "Epoch  140/1000 Cost: 0.107870 Accuracy 97.19%\n",
            "Epoch  150/1000 Cost: 0.106099 Accuracy 97.19%\n",
            "Epoch  160/1000 Cost: 0.104461 Accuracy 97.19%\n",
            "Epoch  170/1000 Cost: 0.102940 Accuracy 97.19%\n",
            "Epoch  180/1000 Cost: 0.101522 Accuracy 97.54%\n",
            "Epoch  190/1000 Cost: 0.100196 Accuracy 97.54%\n",
            "Epoch  200/1000 Cost: 0.098954 Accuracy 97.72%\n",
            "Epoch  210/1000 Cost: 0.097787 Accuracy 97.72%\n",
            "Epoch  220/1000 Cost: 0.096687 Accuracy 97.89%\n",
            "Epoch  230/1000 Cost: 0.095649 Accuracy 97.89%\n",
            "Epoch  240/1000 Cost: 0.094667 Accuracy 98.07%\n",
            "Epoch  250/1000 Cost: 0.093736 Accuracy 98.07%\n",
            "Epoch  260/1000 Cost: 0.092853 Accuracy 98.07%\n",
            "Epoch  270/1000 Cost: 0.092012 Accuracy 98.07%\n",
            "Epoch  280/1000 Cost: 0.091211 Accuracy 98.07%\n",
            "Epoch  290/1000 Cost: 0.090447 Accuracy 98.07%\n",
            "Epoch  300/1000 Cost: 0.089716 Accuracy 98.24%\n",
            "Epoch  310/1000 Cost: 0.089018 Accuracy 98.24%\n",
            "Epoch  320/1000 Cost: 0.088348 Accuracy 98.24%\n",
            "Epoch  330/1000 Cost: 0.087707 Accuracy 98.24%\n",
            "Epoch  340/1000 Cost: 0.087090 Accuracy 98.24%\n",
            "Epoch  350/1000 Cost: 0.086498 Accuracy 98.24%\n",
            "Epoch  360/1000 Cost: 0.085928 Accuracy 98.24%\n",
            "Epoch  370/1000 Cost: 0.085379 Accuracy 98.24%\n",
            "Epoch  380/1000 Cost: 0.084850 Accuracy 98.24%\n",
            "Epoch  390/1000 Cost: 0.084339 Accuracy 98.24%\n",
            "Epoch  400/1000 Cost: 0.083846 Accuracy 98.24%\n",
            "Epoch  410/1000 Cost: 0.083370 Accuracy 98.24%\n",
            "Epoch  420/1000 Cost: 0.082909 Accuracy 98.24%\n",
            "Epoch  430/1000 Cost: 0.082463 Accuracy 98.24%\n",
            "Epoch  440/1000 Cost: 0.082031 Accuracy 98.24%\n",
            "Epoch  450/1000 Cost: 0.081612 Accuracy 98.24%\n",
            "Epoch  460/1000 Cost: 0.081206 Accuracy 98.24%\n",
            "Epoch  470/1000 Cost: 0.080812 Accuracy 98.24%\n",
            "Epoch  480/1000 Cost: 0.080429 Accuracy 98.24%\n",
            "Epoch  490/1000 Cost: 0.080057 Accuracy 98.42%\n",
            "Epoch  500/1000 Cost: 0.079696 Accuracy 98.42%\n",
            "Epoch  510/1000 Cost: 0.079344 Accuracy 98.42%\n",
            "Epoch  520/1000 Cost: 0.079002 Accuracy 98.42%\n",
            "Epoch  530/1000 Cost: 0.078668 Accuracy 98.42%\n",
            "Epoch  540/1000 Cost: 0.078344 Accuracy 98.42%\n",
            "Epoch  550/1000 Cost: 0.078027 Accuracy 98.42%\n",
            "Epoch  560/1000 Cost: 0.077719 Accuracy 98.42%\n",
            "Epoch  570/1000 Cost: 0.077418 Accuracy 98.42%\n",
            "Epoch  580/1000 Cost: 0.077124 Accuracy 98.42%\n",
            "Epoch  590/1000 Cost: 0.076837 Accuracy 98.42%\n",
            "Epoch  600/1000 Cost: 0.076557 Accuracy 98.42%\n",
            "Epoch  610/1000 Cost: 0.076283 Accuracy 98.42%\n",
            "Epoch  620/1000 Cost: 0.076016 Accuracy 98.42%\n",
            "Epoch  630/1000 Cost: 0.075754 Accuracy 98.42%\n",
            "Epoch  640/1000 Cost: 0.075498 Accuracy 98.42%\n",
            "Epoch  650/1000 Cost: 0.075248 Accuracy 98.59%\n",
            "Epoch  660/1000 Cost: 0.075003 Accuracy 98.59%\n",
            "Epoch  670/1000 Cost: 0.074763 Accuracy 98.59%\n",
            "Epoch  680/1000 Cost: 0.074528 Accuracy 98.59%\n",
            "Epoch  690/1000 Cost: 0.074297 Accuracy 98.59%\n",
            "Epoch  700/1000 Cost: 0.074072 Accuracy 98.59%\n",
            "Epoch  710/1000 Cost: 0.073851 Accuracy 98.59%\n",
            "Epoch  720/1000 Cost: 0.073634 Accuracy 98.59%\n",
            "Epoch  730/1000 Cost: 0.073421 Accuracy 98.59%\n",
            "Epoch  740/1000 Cost: 0.073212 Accuracy 98.59%\n",
            "Epoch  750/1000 Cost: 0.073008 Accuracy 98.59%\n",
            "Epoch  760/1000 Cost: 0.072807 Accuracy 98.59%\n",
            "Epoch  770/1000 Cost: 0.072609 Accuracy 98.59%\n",
            "Epoch  780/1000 Cost: 0.072415 Accuracy 98.59%\n",
            "Epoch  790/1000 Cost: 0.072225 Accuracy 98.59%\n",
            "Epoch  800/1000 Cost: 0.072038 Accuracy 98.59%\n",
            "Epoch  810/1000 Cost: 0.071854 Accuracy 98.59%\n",
            "Epoch  820/1000 Cost: 0.071673 Accuracy 98.59%\n",
            "Epoch  830/1000 Cost: 0.071496 Accuracy 98.59%\n",
            "Epoch  840/1000 Cost: 0.071321 Accuracy 98.59%\n",
            "Epoch  850/1000 Cost: 0.071150 Accuracy 98.59%\n",
            "Epoch  860/1000 Cost: 0.070981 Accuracy 98.59%\n",
            "Epoch  870/1000 Cost: 0.070814 Accuracy 98.59%\n",
            "Epoch  880/1000 Cost: 0.070651 Accuracy 98.59%\n",
            "Epoch  890/1000 Cost: 0.070490 Accuracy 98.59%\n",
            "Epoch  900/1000 Cost: 0.070331 Accuracy 98.59%\n",
            "Epoch  910/1000 Cost: 0.070175 Accuracy 98.59%\n",
            "Epoch  920/1000 Cost: 0.070021 Accuracy 98.59%\n",
            "Epoch  930/1000 Cost: 0.069870 Accuracy 98.59%\n",
            "Epoch  940/1000 Cost: 0.069721 Accuracy 98.59%\n",
            "Epoch  950/1000 Cost: 0.069574 Accuracy 98.59%\n",
            "Epoch  960/1000 Cost: 0.069429 Accuracy 98.59%\n",
            "Epoch  970/1000 Cost: 0.069287 Accuracy 98.59%\n",
            "Epoch  980/1000 Cost: 0.069146 Accuracy 98.59%\n",
            "Epoch  990/1000 Cost: 0.069007 Accuracy 98.59%\n",
            "Epoch 1000/1000 Cost: 0.068871 Accuracy 98.59%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Dw6hX9fHrnf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}