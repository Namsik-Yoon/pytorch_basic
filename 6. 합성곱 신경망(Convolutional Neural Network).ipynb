{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled9.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyP0CgSMIaH/XZ6XN0y3C62A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6b9eb6b4c5214cb4a4e5d64cb34ec882": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b7b59fd44394499d91a5b786ee50d981",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_eec4e0a84d0f43bca16e316387e8387f",
              "IPY_MODEL_efe8b168221e4ff68f72a5670db37be6"
            ]
          }
        },
        "b7b59fd44394499d91a5b786ee50d981": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "eec4e0a84d0f43bca16e316387e8387f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_af460e044aa44d3b86da9196b8133564",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d9aac06a5ac54673b01546ee5f393f0f"
          }
        },
        "efe8b168221e4ff68f72a5670db37be6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3a469ab9744242e9a932f77f9348ba8d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 9920512/? [00:19&lt;00:00, 750075.70it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_53feed322f444fc1bd0610fe34b93776"
          }
        },
        "af460e044aa44d3b86da9196b8133564": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d9aac06a5ac54673b01546ee5f393f0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3a469ab9744242e9a932f77f9348ba8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "53feed322f444fc1bd0610fe34b93776": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "df251af4123a412ebd0d748be8ddad8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_978f397169e449358c5b9d1e6b0fd09e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6e0dff7fa4c74d3fa1900671fa1de1a3",
              "IPY_MODEL_5572014e78c54ad9bc785d0b58ae39f7"
            ]
          }
        },
        "978f397169e449358c5b9d1e6b0fd09e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6e0dff7fa4c74d3fa1900671fa1de1a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2b6616361abc4bdc83f1f82d2df63940",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cfce6fbd486c4a7c9437a7cb847575a5"
          }
        },
        "5572014e78c54ad9bc785d0b58ae39f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bda478131aff4c29b916114ce8026f9e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 32768/? [00:06&lt;00:00, 5362.27it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4900858392e249ff9adbdbecb80b77c1"
          }
        },
        "2b6616361abc4bdc83f1f82d2df63940": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cfce6fbd486c4a7c9437a7cb847575a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bda478131aff4c29b916114ce8026f9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4900858392e249ff9adbdbecb80b77c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b1b627fc23204f09b052a49018644f4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4dfb35d344084bab8ca7abf660c72f1e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ccc378651d7043a39f641b20109e2df0",
              "IPY_MODEL_f123f77d6b49476eb48eb41260e9ed37"
            ]
          }
        },
        "4dfb35d344084bab8ca7abf660c72f1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ccc378651d7043a39f641b20109e2df0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_72eb1565c041494d934757331b2ca3cd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f02a8827c9e54c90a0eb47a39289e852"
          }
        },
        "f123f77d6b49476eb48eb41260e9ed37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ac9596e0392e40ae8077239171a8ba2f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1654784/? [00:05&lt;00:00, 285129.90it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7e0ffa2f441a47a492a49f6a70fc580c"
          }
        },
        "72eb1565c041494d934757331b2ca3cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f02a8827c9e54c90a0eb47a39289e852": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ac9596e0392e40ae8077239171a8ba2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7e0ffa2f441a47a492a49f6a70fc580c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bcabad4617ef47c08b1f5283e3ee44ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_59a08bca9b654327b2aab1b9fb65a967",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_85bef3e680904d8f86df02691a579f28",
              "IPY_MODEL_3d6449b736264d37a1ff61c80d8cc1ca"
            ]
          }
        },
        "59a08bca9b654327b2aab1b9fb65a967": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "85bef3e680904d8f86df02691a579f28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4396ff89768a4719aec89f89a189536c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_08836f2e15944214898a577f0f6bc137"
          }
        },
        "3d6449b736264d37a1ff61c80d8cc1ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_754bc74ee42a4f9a80f22023e21a321b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 8192/? [00:04&lt;00:00, 1813.01it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3ca08a7128a748ed8b271f84855692cd"
          }
        },
        "4396ff89768a4719aec89f89a189536c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "08836f2e15944214898a577f0f6bc137": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "754bc74ee42a4f9a80f22023e21a321b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3ca08a7128a748ed8b271f84855692cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Namsik-Yoon/pytorch_basic/blob/master/6.%20%ED%95%A9%EC%84%B1%EA%B3%B1%20%EC%8B%A0%EA%B2%BD%EB%A7%9D(Convolutional%20Neural%20Network).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QDo5WSDMPDQ"
      },
      "source": [
        "# 6. 합성곱 신경망(Convolutional Neural Network)\n",
        "\n",
        "이번 챕터에서는 주로 이미지, 비전 분야에서 사용되는 (하지만 자연어 처리에서도 일부 사용되는) 합성곱 신경망(Convolutional Neural Network)에 대해서 배웁니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lq4avwdMMbXe"
      },
      "source": [
        "## 6.1 합성곱과 풀링(Convolution and Pooling)\n",
        "\n",
        "합성곱 신경망(Convolutional Neural Network)은 이미지 처리에 탁월한 성능을 보이는 신경망입니다. 이번 챕터에서는 합성곱 신경망에 대해서 학습합니다.\n",
        "\n",
        "합성곱 신경망은 크게 합성곱층과(Convolution layer)와 풀링층(Pooling layer)으로 구성됩니다. 아래의 그림은 합성곱 신경망의 일반적인 예를 보여줍니다.\n",
        "\n",
        "![대체 텍스트](https://wikidocs.net/images/page/62306/convpooling.PNG)\n",
        "\n",
        "위의 그림에서 CONV는 합성곱 연산을 의미하고, 합성곱 연산의 결과가 활성화 함수 ReLU를 지납니다. 이 두 과정을 합성곱층이라고 합니다. 그 후에 POOL이라는 구간을 지나는데 이는 풀링 연산을 의미하며 풀링층이라고 합니다.\n",
        "\n",
        "이번 챕터에서는 합성곱 연산과 풀링 연산의 의미에 대해서 학습합니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXVD6YM_Mzg2"
      },
      "source": [
        "### 6.1.1 합성곱 신경망의 대두\n",
        "\n",
        "합성곱 신경망은 이미지 처리에 탁월한 성능을 보이는 신경망입니다. 이미지 처리를 하기 위해서 앞서 배운 다층 퍼셉트론을 사용할 수는 있지만 한계가 있었습니다. 예를 들어, 알파벳 손글씨를 분류하는 어떤 문제가 있다고 해봅시다. 아래의 그림은 알파벳 Y를 비교적 정자로 쓴 손글씨와 다소 휘갈겨 쓴 손글씨 두 개를 2차원 텐서인 행렬로 표현한 것입니다.\n",
        "\n",
        "![대체 텍스트](https://wikidocs.net/images/page/64066/conv0.png)\n",
        "\n",
        "사람이 보기에는 두 그림 모두 알파벳 Y로 손쉽게 판단이 가능하지만, 기계가 보기에는 각 픽셀마다 가진 값이 거의 상이하므로 완전히 다른 값을 가진 입력입니다. 그런데 이미지라는 것은 위와 같이 같은 대상이라도 휘어지거나, 이동되었거나, 방향이 뒤틀렸거나 등 다양한 변형이 존재합니다. 다층 퍼셉트론은 몇 가지 픽셀만 값이 달라져도 민감하게 예측에 영향을 받는다는 단점이 있습니다.\n",
        "\n",
        "좀 더 구체적으로 보겠습니다. 위 손글씨를 다층 퍼셉트론으로 분류한다고 하면, 이미지를 1차원 텐서인 벡터로 변환하고 다층 퍼셉트론의 입력층으로 사용해야 합니다. 두번째 손글씨를 다층 퍼셉트론으로 분류하기 위해서 벡터로 바꾸면 다음과 같습니다.\n",
        "\n",
        "![대체 텍스트](https://wikidocs.net/images/page/64066/conv1.png)\n",
        "\n",
        "1차원으로 변환된 결과는 사람이 보기에도 이게 원래 어떤 이미지였는지 알아보기가 어렵습니다. 이는 기계도 마찬가지 입니다. 위와 같이 결과는 변환 전에 가지고 있던 공간적인 구조(spatial structure) 정보가 유실된 상태입니다. 여기서 공간적인 구조 정보라는 것은 거리가 가까운 어떤 픽셀들끼리는 어떤 연관이 있고, 어떤 픽셀들끼리는 값이 비슷하거나 등을 포함하고 있습니다. 결국 이미지의 공간적인 구조 정보를 보존하면서 학습할 수 있는 방법이 필요해졌고, 이를 위해 사용하는 것이 합성곱 신경망입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLZJMnJ3NKiO"
      },
      "source": [
        "### 6.1.2 채널(Channel)\n",
        "\n",
        "이미지 처리의 기본적인 용어인 채널에 대해서 간단히 정의하겠습니다.\n",
        "\n",
        "기계는 글자나 이미지보다 숫자. 다시 말해, 텐서를 더 잘 처리할 수 있습니다. 이미지는 (높이, 너비, 채널)이라는 3차원 텐서입니다. 여기서 높이는 이미지의 세로 방향 픽셀 수, 너비는 이미지의 가로 방향 픽셀 수, 채널은 색 성분을 의미합니다. 흑백 이미지는 채널 수가 1이며, 각 픽셀은 0부터 255 사이의 값을 가집니다. 아래는 28 × 28 픽셀의 손글씨 데이터를 보여줍니다.\n",
        "\n",
        "![대체 텍스트](https://wikidocs.net/images/page/64066/conv2.png)\n",
        "\n",
        "위 손글씨 데이터는 흑백 이미지므로 채널 수가 1임을 고려하면 (28 × 28 × 1)의 크기를 가지는 3차원 텐서입니다. 그렇다면 흑백이 아니라 우리가 통상적으로 접하게 되는 컬러 이미지는 어떨까요? 컬러 이미지는 적색(Red), 녹색(Green), 청색(Blue) 채널 수가 3개입니다.\n",
        "\n",
        "![대체 텍스트](https://wikidocs.net/images/page/64066/conv3.png)\n",
        "\n",
        "하나의 픽셀은 세 가지 색깔, 삼원색의 조합으로 이루어집니다. 만약, 높이가 28, 너비가 28인 컬러 이미지가 있다면 이 이미지의 텐서는 (28 × 28 × 3)의 크기를 가지는 3차원 텐서입니다. 채널은 때로는 깊이(depth)라고도 합니다. 이 경우 이미지는 (높이, 너비, 깊이)라는 3차원 텐서로 표현된다고 말할 수 있을 겁니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nZGYku8NXhF"
      },
      "source": [
        "### 6.1.3 합성곱 연산(Convolution operation)\n",
        "\n",
        "합성곱층은 합성곱 연산을 통해서 이미지의 특징을 추출하는 역할을 합니다. 우선, 합성곱 연산에 대해서 이해해봅시다. 합성곱은 영어로 컨볼루션이라고도 불리는데, 커널(kernel) 또는 필터(filter)라는 n x m 크기의 행렬로 높이(height)x너비(width) 크기의 이미지를 처음부터 끝까지 겹치며 훑으면서 n x m크기의 겹쳐지는 부분의 각 이미지와 커널의 원소의 값을 곱해서 모두 더한 값을 출력으로 하는 것을 말합니다. 이때, 이미지의 가장 왼쪽 위부터 가장 오른쪽까지 순차적으로 훑습니다.\n",
        "\n",
        "*  커널(kernel)은 일반적으로 3 x 3 또는 5 x 5를 사용합니다.\n",
        "\n",
        "예를 통해 이해해봅시다. 아래는 3x3 크기의 커널로 5×5의 이미지 행렬에 합성곱 연산을 수행하는 과정을 보여줍니다. 한 번의 연산을 1 스텝(step)이라고 하였을 때, 합성곱 연산의 네번째 스텝까지 이미지와 식으로 표현해봤습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbFDdjrgN2_Z"
      },
      "source": [
        "1) 첫번째 스텝\n",
        "\n",
        "![대체 텍스트](https://wikidocs.net/images/page/64066/conv4.png)\n",
        "\n",
        "(1×1) + (2×0) + (3×1) + (2×1) + (1×0) + (0×1) + (3×0) + (0×1) + (1×0) = 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omUfpfDGOAMH"
      },
      "source": [
        "2) 두번째 스텝\n",
        "\n",
        "![대체 텍스트](https://wikidocs.net/images/page/64066/conv5.png)\n",
        "\n",
        "(2×1) + (3×0) + (4×1) + (1×1) + (0×0) + (1×1) + (0×0) + (1×1) + (1×0) = 9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMa1wOzvOIJk"
      },
      "source": [
        "3) 세번째 스텝\n",
        "\n",
        "![대체 텍스트](https://wikidocs.net/images/page/64066/conv6.png)\n",
        "\n",
        "(3×1) + (4×0) + (5×1) + (0×1) + (1×0) + (2×1) + (1×0) + (1×1) + (0×0) = 11"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STdZCNkQOM3t"
      },
      "source": [
        "4) 네번째 스텝\n",
        "\n",
        "![대체 텍스트](https://wikidocs.net/images/page/64066/conv7.png)\n",
        "\n",
        "(2×1) + (1×0) + (0×1) + (3×1) + (0×0) + (1×1) + (1×0) + (4×1) + (1×0) = 10\n",
        "\n",
        "위 연산을 총 9번의 스텝까지 마쳤다고 가정하였을 때, 최종 결과는 아래와 같습니다.\n",
        "\n",
        "![대체 텍스트](https://wikidocs.net/images/page/64066/conv8.png)\n",
        "\n",
        "위와 같이 입력으로부터 커널을 사용하여 합성곱 연산을 통해 나온 결과를 특성 맵(feature map)이라고 합니다.\n",
        "\n",
        "위의 예제에서는 커널의 크기가 3 × 3이었지만, 커널의 크기는 사용자가 정할 수 있습니다. 또한 커널의 이동 범위가 위의 예제에서는 한 칸이었지만, 이 또한 사용자가 정할 수 있습니다. 이러한 이동 범위를 스트라이드(stride)라고 합니다.\n",
        "\n",
        "아래의 예제는 스트라이드가 2일 경우에 5 × 5 이미지에 합성곱 연산을 수행하는 3 × 3 커널의 움직임을 보여줍니다. 최종적으로 2 × 2의 크기의 특성 맵을 얻습니다.\n",
        "\n",
        "![대체 텍스트](https://wikidocs.net/images/page/64066/conv9.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_WBJ3-9Oc0h"
      },
      "source": [
        "### 6.1.4 패딩(Padding)\n",
        "\n",
        "위의 예에서 5 × 5 이미지에 3 × 3의 커널로 합성곱 연산을 하였을 때, 스트라이드가 1일 경우에는 3 × 3의 특성 맵을 얻었습니다. 이와 같이 합성곱 연산의 결과로 얻은 특성 맵은 입력보다 크기가 작아진다는 특징이 있습니다. 만약, 합성곱 층을 여러개 쌓았다면 최종적으로 얻은 특성 맵은 초기 입력보다 매우 작아진 상태가 되버립니다. 합성곱 연산 이후에도 특성 맵의 크기가 입력의 크기와 동일하게 유지되도록 하고 싶다면 패딩(padding)을 사용하면 됩니다.\n",
        "\n",
        "![대체 텍스트](https://wikidocs.net/images/page/64066/conv10.png)\n",
        "\n",
        "패딩은 (합성곱 연산을 하기 전에) 입력의 가장자리에 지정된 개수의 폭만큼 행과 열을 추가해주는 것을 말합니다. 좀 더 쉽게 설명하면 지정된 개수의 폭만큼 테두리를 추가합니다. 주로 값을 0으로 채우는 제로 패딩(zero padding)을 사용합니다. 위의 그림은 5 × 5 이미지에 1폭짜리 제로 패딩을 사용하여 위, 아래에 하나의 행을 좌, 우에 하나의 열을 추가한 모습을 보여줍니다.\n",
        "\n",
        "커널은 주로 3 × 3 또는 5 × 5를 사용한다고 언급한 바 있습니다. 만약 스트라이드가 1이라고 하였을 때, 3 × 3 크기의 커널을 사용한다면 1폭짜리 제로 패딩을 사용하고, 5 × 5 크기의 커널을 사용한다면 2폭 짜리 제로 패딩을 사용하면 입력과 특성 맵의 크기를 보존할 수 있습니다. 예를 들어 5 × 5 크기의 이미지에 1폭짜리 제로 패딩을 하면 7 × 7 이미지가 되는데, 여기에 3 × 3의 커널을 사용하여 1 스트라이드로 합성곱을 한 후의 특성 맵은 기존의 입력 이미지의 크기와 같은 5 × 5가 됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gi5-8x84TceA"
      },
      "source": [
        "### 6.1.5 가중치와 편향\n",
        "\n",
        "합성곱 신경망에서의 가중치와 편향을 이해하기 위해서 우선 다층 퍼셉트론을 복습해보겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGdrMM2iTgGn"
      },
      "source": [
        "1) 합성곱 신경망의 가중치\n",
        "\n",
        "다층 퍼셉트론으로 3 × 3 이미지를 처리한다고 가정해보겠습니다. 우선 이미지를 1차원 텐서인 벡터로 만들면, 3 × 3 = 9가 되므로 입력층은 9개의 뉴론을 가집니다. 그리고 4개의 뉴론을 가지는 은닉층을 추가한다고 해보겠습니다. 이는 아래의 그림과 같습니다.\n",
        "\n",
        "![대체 텍스트](https://wikidocs.net/images/page/64066/conv11.png)\n",
        "\n",
        "위에서 각 연결선은 가중치를 의미하므로, 위의 그림에서는 9 × 4 = 36개의 가중치를 가집니다. 이제 비교를 위해 합성곱 신경망으로 3 × 3 이미지를 처리한다고 해보겠습니다. 2 × 2 커널을 사용하고, 스트라이드는 1로 합니다. (*는 합성곱 연산을 의미합니다.)\n",
        "\n",
        "![대체 텍스트](https://wikidocs.net/images/page/64066/conv12.png)\n",
        "\n",
        "사실 합성곱 신경망에서 가중치는 커널 행렬의 원소들입니다. 이를 인공 신경망의 형태로 표현한다면 다음과 같이 표현할 수 있습니다.\n",
        "\n",
        "![대체 텍스트](https://wikidocs.net/images/page/64066/conv13.png)\n",
        "\n",
        "최종적으로 특성 맵을 얻기 위해서는 동일한 커널로 이미지 전체를 훑으며 합성곱 연산을 진행합니다. 결국 이미지 전체를 훑으면서 사용되는 가중치는 $w_0, w_1, w_2, w_3$ 4개 뿐입니다. 그리고 각 합성곱 연산마다 이미지의 모든 픽셀을 사용하는 것이 아니라, 커널과 맵핑되는 픽셀만을 입력으로 사용하는 것을 볼 수 있습니다. 결국 합성곱 신경망은 다층 퍼셉트론을 사용할 때보다 훨씬 적은 수의 가중치를 사용하며 공간적 구조 정보를 보존한다는 특징이 있습니다.\n",
        "\n",
        "다층 퍼셉트론의 은닉층에서는 가중치 연산 후에 비선형성을 추가하기 위해서 활성화 함수를 통과시켰습니다. 합성곱 신경망의 은닉층에서도 마찬가지입니다. 합성곱 연산을 통해 얻은 특성 맵은 다층 퍼셉트론때와 마찬가지로 비선형성 추가를 위해서 활성화 함수를 지나게 됩니다. 이때 렐루 함수나 렐루 함수의 변형들이 주로 사용됩니다. 은닉층에서 렐루 함수가 주로 사용되는 이유는 앞서 활성화 함수 챕터에서 다뤘습니다. 이와 같이 합성곱 연산을 통해서 특성 맵을 얻고, 활성화 함수를 지나는 연산을 하는 합성곱 신경망의 은닉층을 합성곱 신경망에서는 합성곱 층(convolution layer)이라고 합니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iokbajl2T3XO"
      },
      "source": [
        "2) 합성곱 신경망의 편향\n",
        "\n",
        "![대체 텍스트](https://wikidocs.net/images/page/64066/conv14.png)\n",
        "\n",
        "합성곱 신경망에도 편향(bias)를 당연히 추가할 수 있습니다. 만약, 편향을 사용한다면 커널을 적용한 뒤에 더해집니다. 편향은 하나의 값만 존재하며, 커널이 적용된 결과의 모든 원소에 더해집니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUCbdYS1UAxY"
      },
      "source": [
        "### 6.1.6 특성 맵의 크기 계산 방법\n",
        "\n",
        "입력의 크기와 커널의 크기, 그리고 스트라이드의 값만 알면 합성곱 연산의 결과인 특성 맵의 크기를 계산할 수 있습니다.\n",
        "\n",
        "\n",
        "\n",
        "*   $I_{h}$ : 입력의 높이\n",
        "\n",
        "*   $I_{w}$ : 입력의 너비\n",
        "\n",
        "*   $K_{h}$ : 커널의 높이\n",
        "\n",
        "*   $K_{w}$ : 커널의 높이\n",
        "\n",
        "*   $S$ : 스트라이드\n",
        "\n",
        "*   $O_{h}$ : 특성 맵의 높이\n",
        "\n",
        "*   $O_{w}$ : 특성 맵의 너비\n",
        "\n",
        "이에 따라 특성 맵의 높이와 너비는 다음과 같습니다.\n",
        "\n",
        "$O_{h} = floor(\\frac{I_{h} - K_{h}}{S}+1)$\n",
        "\n",
        "$O_{w} = floor(\\frac{I_{w} - K_{w}}{S}+1)$\n",
        "\n",
        "여기서 $floor$ 함수는 소수점 발생 시 소수점 이하를 버리는 역할을 합니다. 예를 들어 위의 첫번째 예제의 경우 5 × 5 크기의 이미지에 3 × 3 커널을 사용하고 스트라이드 1로 합성곱 연산을 했습니다. 이 경우 특성 맵의 크기는 (5 - 3 + 1 ) × (5 - 3 + 1) = 3 × 3임을 알 수 있습니다. 이는 또한 총 9번의 스텝이 필요함을 의미하기도 합니다.\n",
        "\n",
        "패딩의 폭을 P라고 하고, 패딩까지 고려한 식은 다음과 같습니다.\n",
        "\n",
        "$O_{h} = floor(\\frac{I_{h} - K_{h} + 2P}{S}+1)$\n",
        "\n",
        "$O_{w} = floor(\\frac{I_{w} - K_{w} + 2P}{S}+1)$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-AOC8x5U8vd"
      },
      "source": [
        "### 6.1.7 다수의 채널을 가질 경우의 합성곱 연산(3차원 텐서의 합성곱 연산)\n",
        "\n",
        "지금까지는 채널(channel) 또는 깊이(depth)를 고려하지 않고, 2차원 텐서를 가정하고 설명했습니다. 하지만 실제로 합성곱 연산의 입력은 '다수의 채널을 가진' 이미지 또는 이전 연산의 결과로 나온 특성 맵일 수 있습니다. 만약, 다수의 채널을 가진 입력 데이터를 가지고 합성곱 연산을 한다고 하면 커널의 채널 수도 입력의 채널 수만큼 존재해야 합니다. 다시 말해 입력 데이터의 채널 수와 커널의 채널 수는 같아야 합니다. 채널 수가 같으므로 합성곱 연산을 채널마다 수행합니다. 그리고 그 결과를 모두 더하여 최종 특성 맵을 얻습니다.\n",
        "\n",
        "![대체 텍스트](https://wikidocs.net/images/page/64066/conv15.png)\n",
        "\n",
        "위 그림은 3개의 채널을 가진 입력 데이터와 3개의 채널을 가진 커널의 합성곱 연산을 보여줍니다. 커널의 각 채널끼리의 크기는 같아야 합니다. 각 채널 간 합성곱 연산을 마치고, 그 결과를 모두 더해서 하나의 채널을 가지는 특성 맵을 만듭니다. 주의할 점은 위의 연산에서 사용되는 커널은 3개의 커널이 아니라 3개의 채널을 가진 1개의 커널이라는 점입니다.\n",
        "\n",
        "위 그림은 높이 3, 너비 3, 채널 3의 입력이 높이 2, 너비 2, 채널 3의 커널과 합성곱 연산을 하여 높이 2, 너비 2, 채널 1의 특성 맵을 얻는다는 의미입니다. 합성곱 연산의 결과로 얻은 특성 맵의 채널 차원은 RGB 채널 등과 같은 컬러의 의미를 담고 있지는 않습니다.\n",
        "\n",
        "이제 이 연산에서 각 차원을 변수로 두고 좀 더 일반화시켜보겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCAy2ea_VFy7"
      },
      "source": [
        "### 6.1.8 3차원 텐서의 합성곱 연산\n",
        "\n",
        "일반화를 위해 사용하는 각 변수가 의미하는 바는 다음과 같습니다.\n",
        "\n",
        "*   $I_{h}$ : 입력의 높이\n",
        "\n",
        "*   $I_{w}$ : 입력의 너비\n",
        "\n",
        "*   $K_{h}$ : 커널의 높이\n",
        "\n",
        "*   $K_{w}$ : 커널의 높이\n",
        "\n",
        "*   $O_{h}$ : 특성 맵의 높이\n",
        "\n",
        "*   $O_{w}$ : 특성 맵의 너비\n",
        "\n",
        "*   $C_{i}$ : 입력 데이터의 채널\n",
        "\n",
        "다음은 3차원 텐서의 합성곱 연산을 보여줍니다.\n",
        "\n",
        "![대체 텍스트](https://wikidocs.net/images/page/64066/conv16_final.png)\n",
        "\n",
        "높이 $I_h$, 너비 $I_w$, 채널 $C_i$의 입력 데이터는 동일한 채널 수 $C_i$를 가지는 높이 $K_h$, 너비 $K_w$의 커널과 합성곱 연산을 하여 높이 $O_h$, 너비 $O_w$, 채널 1의 특성 맵을 얻습니다. 그런데 하나의 입력에 여러 개의 커널을 사용하는 합성곱 연산을 할 수도 있습니다.\n",
        "\n",
        "합성곱 연산에서 다수의 커널을 사용할 경우, 특성 맵의 크기가 어떻게 바뀌는지 봅시다. 다음은 $C_o$를 합성곱 연산에 사용하는 커널의 수라고 하였을 때의 합성곱 연산 과정을 보여줍니다.\n",
        "\n",
        "![대체 텍스트](https://wikidocs.net/images/page/64066/conv17_final_final.PNG)\n",
        "\n",
        "합성곱 연산에서 다수의 커널을 사용할 경우, 사용한 커널 수는 합성곱 연산의 결과로 나오는 특성 맵의 채널 수가 됩니다.\n",
        "\n",
        "이를 이해했다면 커널의 크기와 입력 데이터의 채널 수 $C_i$와 특성 맵(출력 데이터)의 채널 수 $C_o$가 주어졌을 때, 가중치 매개변수의 총 개수를 구할 수 있습니다. 가중치는 커널의 원소들이므로 하나의 커널의 하나의 채널은 $K_h$ × $K_w$개의 매개변수를 가지고 있습니다. 그런데 합성곱 연산을 하려면 커널은 입력 데이터의 채널 수와 동일한 채널 수를 가져야 합니다. 이에 따라 하나의 커널이 가지는 매개변수의 수는 $K_h$ × $K_w$ × $C_i$입니다. 그런데 이러한 커널이 총 $C_o$개가 있어야 하므로 가중치 매개변수의 총 수는 다음과 같습니다.\n",
        "\n",
        "가중치 매개변수의 총 수 : $K_h$  × $K_w$ × $C_i$ × $C_o$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50XGb9DSXI0B"
      },
      "source": [
        "### 6.1.9 풀링(Pooling)\n",
        "\n",
        "일반적으로 합성곱 층(합성곱 연산 + 활성화 함수) 다음에는 풀링 층을 추가하는 것이 일반적입니다. 풀링 층에서는 특성 맵을 다운샘플링하여 특성 맵의 크기를 줄이는 풀링 연산이 이루어집니다. 풀링 연산에는 일반적으로 최대 풀링(max pooling)과 평균 풀링(average pooling)이 사용됩니다. 우선 최대 풀링을 통해서 풀링 연산을 이해해봅시다.\n",
        "\n",
        "![대체 텍스트](https://wikidocs.net/images/page/62306/maxpooling.PNG)\n",
        "\n",
        "풀링 연산에서도 합성곱 연산과 마찬가지로 커널과 스트라이드의 개념을 가집니다. 위의 그림은 스트라이드가 2일 때, 2 x 2 크기 커널로 맥스 풀링 연산을 했을 때 특성맵이 절반의 크기로 다운샘플링되는 것을 보여줍니다. 맥스 풀링은 커널과 겹치는 영역 안에서 최대값을 추출하는 방식으로 다운샘플링합니다.\n",
        "\n",
        "다른 풀링 기법인 평균 풀링은 최대값을 추출하는 것이 아니라 평균값을 추출하는 연산이 됩니다. 풀링 연산은 커널과 스트라이드 개념이 존재한다는 점에서 합성곱 연산과 유사하지만, 합성곱 연산과의 차이점은 학습해야 할 가중치가 없으며 연산 후에 채널 수가 변하지 않는다는 점입니다.\n",
        "\n",
        "풀링을 사용하면, 특성 맵의 크기가 줄어드므로 특성 맵의 가중치의 개수를 줄여줍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bHDlluAXVt7"
      },
      "source": [
        "## 6.2 CNN으로 MNIST 분류하기\n",
        "\n",
        "이번 챕터에서는 CNN으로 MNIST를 분류해보겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCLView2XZ3A"
      },
      "source": [
        "### 6.2.1 모델 이해하기\n",
        "\n",
        "우리가 만들 모델의 아키텍처를 이해해봅시다. 합성곱 신경망은 출처에 따라서 합성곱 층을 부르는 단위가 조금 다릅니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZZZZB2DXijx"
      },
      "source": [
        "1) 첫번째 표기 방법\n",
        "\n",
        "합성곱(nn.Cov2d) + 활성화 함수(nn.ReLU)를 하나의 합성곱 층으로 보고, 맥스풀링(nn.MaxPoold2d)은 풀링 층으로 별도로 명명합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xx2AnF03Xvu_"
      },
      "source": [
        "2) 두번째 표기 방법\n",
        "\n",
        "합성곱(nn.Conv2d) + 활성화 함수(nn.ReLU) + 맥스풀링(nn.MaxPoold2d)을 하나의 합성곱 층으로 봅니다.\n",
        "\n",
        "다시 말해 풀링도 하나의 층으로 보느냐, 안 보느냐의 문제인데 누가 옳고 틀리냐의 문제는 아니므로, 이번 챕터에서는 편의를 위해 맥스풀링까지도 포함해서 하나의 합성곱 층으로 판단하고 정리해보겠습니다. 다시 말해 두번째 표기 방법을 택하겠습니다.\n",
        "\n",
        "모델의 아키텍처는 총 3개의 층으로 구성됩니다.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "# 1번 레이어 : 합성곱층(Convolutional layer)\n",
        "합성곱(in_channel = 1, out_channel = 32, kernel_size=3, stride=1, padding=1) + 활성화 함수 ReLU\n",
        "맥스풀링(kernel_size=2, stride=2))\n",
        "\n",
        "# 2번 레이어 : 합성곱층(Convolutional layer)\n",
        "합성곱(in_channel = 32, out_channel = 64, kernel_size=3, stride=1, padding=1) + 활성화 함수 ReLU\n",
        "맥스풀링(kernel_size=2, stride=2))\n",
        "\n",
        "# 3번 레이어 : 전결합층(Fully-Connected layer)\n",
        "특성맵을 펼친다. # batch_size × 64 × 7 × 7 → batch_size × 3136\n",
        "전결합층(뉴런 10개) + 활성화 함수 Softmax\n",
        "```\n",
        "\n",
        "이를 직접 구현해보며 이해해봅시다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sc6XDAgMYDL_"
      },
      "source": [
        "### 6.2.2 모델 구현하기\n",
        "\n",
        "위의 3개의 층을 직접 구현해보겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hhhrf201YGlk"
      },
      "source": [
        "1) 필요한 도구 임포트와 입력의 정의\n",
        "\n",
        "필요한 도구들을 임포트합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SM6L1FV4MaqF"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmD5jWD4YLDF"
      },
      "source": [
        "임의의 텐서를 만듭니다. 텐서의 크기는 1 × 1 × 28 × 28입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4o59aP_dYKnd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "25eb32be-9e02-4d3d-8207-2877f61f81d9"
      },
      "source": [
        "# 배치 크기 × 채널 × 높이(height) × 너비(widht)의 크기의 텐서를 선언\n",
        "inputs = torch.Tensor(1, 1, 28, 28)\n",
        "print('텐서의 크기 : {}'.format(inputs.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "텐서의 크기 : torch.Size([1, 1, 28, 28])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_f9MCMLYN0T"
      },
      "source": [
        "2) 합성곱층과 풀링 선언하기\n",
        "\n",
        "이제 첫번째 합성곱 층을 구현해봅시다. 1채널 짜리를 입력받아서 32채널을 뽑아내는데 커널 사이즈는 3이고 패딩은 1입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPNz4sSyYNaj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "167ef906-3437-461b-b260-a9844a92be9a"
      },
      "source": [
        "conv1 = nn.Conv2d(1, 32, 3, padding=1)\n",
        "print(conv1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLRtT24EYYPx"
      },
      "source": [
        "이제 두번째 합성곱 층을 구현해봅시다. 32채널 짜리를 입력받아서 64채널을 뽑아내는데 커널 사이즈는 3이고 패딩은 1입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RI8aWX6NYSCE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c129e4f3-59fe-4cae-aa9b-e3687ceeba03"
      },
      "source": [
        "conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "print(conv2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yrTlS1xYanq"
      },
      "source": [
        "이제 맥스풀링을 구현해봅시다. 정수 하나를 인자로 넣으면 커널 사이즈와 스트라이드가 둘 다 해당값으로 지정됩니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GTx__xuYZu0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a69ea34d-0383-4ade-ff3c-4d6313657c68"
      },
      "source": [
        "pool = nn.MaxPool2d(2)\n",
        "print(pool)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CnXepu-YfG4"
      },
      "source": [
        "3) 구현체를 연결하여 모델 만들기\n",
        "\n",
        "지금까지는 선언만한 것이고 아직 이들을 연결시키지는 않았습니다. 이들을 연결시켜서 모델을 완성시켜보겠습니다. 우선 입력을 첫번째 합성곱층을 통과시키고 합성곱층을 통과시킨 후의 텐서의 크기를 보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3E83GigYc-T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "90312b42-a4d0-4a69-fc0c-b257c99ee8aa"
      },
      "source": [
        "out = conv1(inputs)\n",
        "print(out.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 32, 28, 28])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcUbmOI-Ylg9"
      },
      "source": [
        "32채널의 28너비 28높이의 텐서가 되었습니다. 32가 나온 이유는 conv1의 out_channel로 32를 지정해주었기 때문입니다. 또한, 28너비 28높이가 된 이유는 패딩을 1폭으로 하고 3 × 3 커널을 사용하면 크기가 보존되기 때문입니다. 이제 이를 맥스풀링을 통과시키고 맥스풀링을 통과한 후의 텐서의 크기를 보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5cDFUWOYjU2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fc413409-734a-4e7a-abc4-a35b6afdf6a7"
      },
      "source": [
        "out = pool(out)\n",
        "print(out.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 32, 14, 14])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbZuXpL6YoQY"
      },
      "source": [
        "32채널의 14너비 14높이의 텐서가 되었습니다. 이제 이를 다시 두번째 합성곱층에 통과시키고 통과한 후의 텐서의 크기를 보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTb7nLJFYm9p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ed872815-da98-45f6-e508-8ff86cd2e436"
      },
      "source": [
        "out = conv2(out)\n",
        "print(out.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 64, 14, 14])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MevEsVD9Yrpo"
      },
      "source": [
        "64채널의 14너비 14높이의 텐서가 되었습니다. 64가 나온 이유는 conv2의 out_channel로 64를 지정해주었기 때문입니다. 또한, 14너비 14높이가 된 이유는 패딩을 1폭으로 하고 3 × 3 커널을 사용하면 크기가 보존되기 때문입니다. 이제 이를 맥스풀링을 통과시키고 맥스풀링을 통과한 후의 텐서의 크기를 보겠습니다. 이제 이를 맥스풀링을 통과시키고 맥스풀링을 통과한 후의 텐서의 크기를 보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gJsIt3LYqFm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "271573ab-70f2-44a9-936f-adcd4e1ca0c8"
      },
      "source": [
        "out = pool(out)\n",
        "print(out.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 64, 7, 7])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUfJrzf3YuNP"
      },
      "source": [
        "이제 이 텐서를 펼치는 작업을 할 겁니다. 그런데 펼치기에 앞서 텐서의 n번째 차원을 접근하게 해주는 .size(n)에 대해서 배워보겠습니다. 현재 out의 크기는 1 × 64 × 7 × 7입니다. out의 첫번째 차원이 몇인지 출력해보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Ox20AJkYs62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "668c0f81-3eb0-4293-8a33-1aeb87a0dec3"
      },
      "source": [
        "out.size(0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFLq38m8Y06E"
      },
      "source": [
        "out의 첫번째 차원은 1입니다. 두번째 차원이 몇인지 출력해보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_wwrWoWYvar",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e560799c-bfc4-48d0-f793-e2bc735219e5"
      },
      "source": [
        "out.size(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nu_R1f7OY4Px"
      },
      "source": [
        "out의 두번째 차원은 64입니다. 세번째 차원이 몇인지 출력해보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZELzQ7ehY2ge",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d155e929-bcab-4e33-ef0a-1b7344372eaf"
      },
      "source": [
        "out.size(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PObOIDeSY7hz"
      },
      "source": [
        "마찬가지로 out의 네번째 차원을 출력해보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnQCWFENY5qc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7a102eb3-41d4-436c-8092-a6447168f844"
      },
      "source": [
        "out.size(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXNxQA6CY-PT"
      },
      "source": [
        "이제 이를 가지고 .view()를 사용하여 텐서를 펼치는 작업을 해보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvROxzoRY9I9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d4412c65-d719-4610-eb7d-5356f4bbbd9a"
      },
      "source": [
        "# 첫번째 차원인 배치 차원은 그대로 두고 나머지는 펼쳐라\n",
        "out = out.view(out.size(0), -1) \n",
        "print(out.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 3136])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0sjdXtFZZCw2"
      },
      "source": [
        "배치 차원을 제외하고 모두 하나의 차원으로 통합된 것을 볼 수 있습니다. 이제 이에 대해서 전결합층(Fully-Connteced layer)를 통과시켜보겠습니다. 출력층으로 10개의 뉴런을 배치하여 10개 차원의 텐서로 변환합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmnSnDmDY_oL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "96534fc2-7925-4a3b-ec83-e44b5d0914de"
      },
      "source": [
        "fc = nn.Linear(3136, 10) # input_dim = 3,136, output_dim = 10\n",
        "out = fc(out)\n",
        "print(out.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZZ87fIjZF91"
      },
      "source": [
        "### 6.2.3 CNN으로 MNIST 분류하기\n",
        "\n",
        "우선 필요한 도구들을 임포트합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emURm3fDZEOM"
      },
      "source": [
        "import torch\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.init"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lArVyQJ9ZLI2"
      },
      "source": [
        "만약 GPU를 사용 가능하다면 device 값이 cuda가 되고, 아니라면 cpu가 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yh0q-wdxZJmk"
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# 랜덤 시드 고정\n",
        "torch.manual_seed(777)\n",
        "\n",
        "# GPU 사용 가능일 경우 랜덤 시드 고정\n",
        "if device == 'cuda':\n",
        "    torch.cuda.manual_seed_all(777)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60YPkVCwZOF3"
      },
      "source": [
        "학습에 사용할 파라미터를 설정합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJK6fuIvZM3y"
      },
      "source": [
        "learning_rate = 0.001\n",
        "training_epochs = 15\n",
        "batch_size = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-G6VM8VZQx8"
      },
      "source": [
        "데이터로더를 사용하여 데이터를 다루기 위해서 데이터셋을 정의해줍니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55nlv0qkZPrz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325,
          "referenced_widgets": [
            "6b9eb6b4c5214cb4a4e5d64cb34ec882",
            "b7b59fd44394499d91a5b786ee50d981",
            "eec4e0a84d0f43bca16e316387e8387f",
            "efe8b168221e4ff68f72a5670db37be6",
            "af460e044aa44d3b86da9196b8133564",
            "d9aac06a5ac54673b01546ee5f393f0f",
            "3a469ab9744242e9a932f77f9348ba8d",
            "53feed322f444fc1bd0610fe34b93776",
            "df251af4123a412ebd0d748be8ddad8f",
            "978f397169e449358c5b9d1e6b0fd09e",
            "6e0dff7fa4c74d3fa1900671fa1de1a3",
            "5572014e78c54ad9bc785d0b58ae39f7",
            "2b6616361abc4bdc83f1f82d2df63940",
            "cfce6fbd486c4a7c9437a7cb847575a5",
            "bda478131aff4c29b916114ce8026f9e",
            "4900858392e249ff9adbdbecb80b77c1",
            "b1b627fc23204f09b052a49018644f4d",
            "4dfb35d344084bab8ca7abf660c72f1e",
            "ccc378651d7043a39f641b20109e2df0",
            "f123f77d6b49476eb48eb41260e9ed37",
            "72eb1565c041494d934757331b2ca3cd",
            "f02a8827c9e54c90a0eb47a39289e852",
            "ac9596e0392e40ae8077239171a8ba2f",
            "7e0ffa2f441a47a492a49f6a70fc580c",
            "bcabad4617ef47c08b1f5283e3ee44ae",
            "59a08bca9b654327b2aab1b9fb65a967",
            "85bef3e680904d8f86df02691a579f28",
            "3d6449b736264d37a1ff61c80d8cc1ca",
            "4396ff89768a4719aec89f89a189536c",
            "08836f2e15944214898a577f0f6bc137",
            "754bc74ee42a4f9a80f22023e21a321b",
            "3ca08a7128a748ed8b271f84855692cd"
          ]
        },
        "outputId": "00babee6-650a-4d35-f1d8-422de8679886"
      },
      "source": [
        "mnist_train = dsets.MNIST(root='MNIST_data/', # 다운로드 경로 지정\n",
        "                          train=True, # True를 지정하면 훈련 데이터로 다운로드\n",
        "                          transform=transforms.ToTensor(), # 텐서로 변환\n",
        "                          download=True)\n",
        "\n",
        "mnist_test = dsets.MNIST(root='MNIST_data/', # 다운로드 경로 지정\n",
        "                         train=False, # False를 지정하면 테스트 데이터로 다운로드\n",
        "                         transform=transforms.ToTensor(), # 텐서로 변환\n",
        "                         download=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6b9eb6b4c5214cb4a4e5d64cb34ec882",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz to MNIST_data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "df251af4123a412ebd0d748be8ddad8f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b1b627fc23204f09b052a49018644f4d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz to MNIST_data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bcabad4617ef47c08b1f5283e3ee44ae",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9pIdG54ZTwF"
      },
      "source": [
        "데이터로더를 사용하여 배치 크기를 지정해줍니다. 만약 데이터셋과 데이터로더가 기억이 안 난다면 '미니 배치와 데이터 로드' 챕터를 꼭 복습하세요."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCAQlM2-ZSJQ"
      },
      "source": [
        "data_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=True,\n",
        "                                          drop_last=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OiwLCQvtZYon"
      },
      "source": [
        "이제 클래스로 모델을 설계합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkRBXAV_ZWK6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "b8577120-4df3-43c2-b68c-b0a8450279d5"
      },
      "source": [
        "class CNN(torch.nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        # 첫번째층\n",
        "        # ImgIn shape=(?, 28, 28, 1)\n",
        "        #    Conv     -> (?, 32, 28, 28)\n",
        "        #    Pool     -> (?, 32, 14, 14)\n",
        "        self.layer1 = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "\n",
        "        # 두번째층\n",
        "        # ImgIn shape=(?, 32, 14, 14)\n",
        "        #    Conv      ->(?, 64, 14, 14)\n",
        "        #    Pool      ->(?, 64, 7, 7)\n",
        "        self.layer2 = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "\n",
        "        # 전결합층 7x7x64 inputs -> 10 outputs\n",
        "        self.fc = torch.nn.Linear(7 * 7 * 64, 10, bias=True)\n",
        "\n",
        "        # 전결합층 한정으로 가중치 초기화\n",
        "        torch.nn.init.xavier_uniform_(self.fc.weight)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = out.view(out.size(0), -1)   # 전결합층을 위해서 Flatten\n",
        "        out = self.fc(out)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LM9_bxn1Zc4l"
      },
      "source": [
        "모델을 정의합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqEuCBRpZZBo"
      },
      "source": [
        "# CNN 모델 정의\n",
        "model = CNN().to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6qoPadHZfUe"
      },
      "source": [
        "비용 함수와 옵티마이저를 정의합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIOK8jzkZeSN"
      },
      "source": [
        "criterion = torch.nn.CrossEntropyLoss().to(device)    # 비용 함수에 소프트맥스 함수 포함되어져 있음.\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvsNsHtXZoHY"
      },
      "source": [
        "총 배치의 수를 출력해보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_frLOZiBZimk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c03fa1f8-8ef3-44e4-9194-4c1cb5bc0dd4"
      },
      "source": [
        "total_batch = len(data_loader)\n",
        "print('총 배치의 수 : {}'.format(total_batch))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "총 배치의 수 : 600\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEal_UdlZq6D"
      },
      "source": [
        "총 배치의 수는 600입니다. 그런데 배치 크기를 100으로 했으므로 결국 훈련 데이터는 총 60,000개란 의미입니다. 이제 모델을 훈련시켜보겠습니다. (시간이 꽤 오래 걸립니다.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fpEtRMMZpe1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "ce5ad9ef-80f5-4712-f6ad-7511b3a58794"
      },
      "source": [
        "for epoch in range(training_epochs):\n",
        "    avg_cost = 0\n",
        "\n",
        "    for X, Y in data_loader: # 미니 배치 단위로 꺼내온다. X는 미니 배치, Y느 ㄴ레이블.\n",
        "        # image is already size of (28x28), no reshape\n",
        "        # label is not one-hot encoded\n",
        "        X = X.to(device)\n",
        "        Y = Y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        hypothesis = model(X)\n",
        "        cost = criterion(hypothesis, Y)\n",
        "        cost.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        avg_cost += cost / total_batch\n",
        "\n",
        "    print('[Epoch: {:>4}] cost = {:>.9}'.format(epoch + 1, avg_cost))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Epoch:    1] cost = 0.223998249\n",
            "[Epoch:    2] cost = 0.0621480942\n",
            "[Epoch:    3] cost = 0.0448664278\n",
            "[Epoch:    4] cost = 0.035497617\n",
            "[Epoch:    5] cost = 0.0290347487\n",
            "[Epoch:    6] cost = 0.0248380173\n",
            "[Epoch:    7] cost = 0.0206937008\n",
            "[Epoch:    8] cost = 0.0180317909\n",
            "[Epoch:    9] cost = 0.0151582453\n",
            "[Epoch:   10] cost = 0.0124741569\n",
            "[Epoch:   11] cost = 0.0103889583\n",
            "[Epoch:   12] cost = 0.0100173047\n",
            "[Epoch:   13] cost = 0.00808507297\n",
            "[Epoch:   14] cost = 0.00730823725\n",
            "[Epoch:   15] cost = 0.00602955278\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whx78-lVZxoc"
      },
      "source": [
        "이제 테스트를 해보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1z2az_fkZswf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "a18c4e95-52f4-4ce5-cf91-ac0ed195405d"
      },
      "source": [
        "# 학습을 진행하지 않을 것이므로 torch.no_grad()\n",
        "with torch.no_grad():\n",
        "    X_test = mnist_test.test_data.view(len(mnist_test), 1, 28, 28).float().to(device)\n",
        "    Y_test = mnist_test.test_labels.to(device)\n",
        "\n",
        "    prediction = model(X_test)\n",
        "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
        "    accuracy = correct_prediction.float().mean()\n",
        "    print('Accuracy:', accuracy.item())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9882999658584595\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:60: UserWarning: test_data has been renamed data\n",
            "  warnings.warn(\"test_data has been renamed data\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:50: UserWarning: test_labels has been renamed targets\n",
            "  warnings.warn(\"test_labels has been renamed targets\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGrFKf5aZ1GF"
      },
      "source": [
        "98%의 정확도를 얻습니다. 다음 챕터에서는 층을 더 쌓아보겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylRxBY3saGl1"
      },
      "source": [
        "## 6.3 깊은 CNN으로 MNIST 분류하기\n",
        "\n",
        "이번 챕터에서는 앞서 배운 CNN에 층을 더 추가하여 MNIST를 분류해보겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TuuisoV_aMJh"
      },
      "source": [
        "### 6.3.1 모델 이해하기\n",
        "\n",
        "우리가 만들 모델의 아키텍처를 이해해봅시다. 모델의 아키텍처는 총 5개의 층으로 구성됩니다. 앞서 배운 챕터에서 1번 레이어와 2번 레이어는 동일하되, 새로운 합성곱층과 전결합층을 추가했습니다.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "# 1번 레이어 : 합성곱층(Convolutional layer)\n",
        "합성곱(in_channel = 1, out_channel = 32, kernel_size=3, stride=1, padding=1) + 활성화 함수 ReLU\n",
        "맥스풀링(kernel_size=2, stride=2))\n",
        "\n",
        "# 2번 레이어 : 합성곱층(Convolutional layer)\n",
        "합성곱(in_channel = 32, out_channel = 64, kernel_size=3, stride=1, padding=1) + 활성화 함수 ReLU\n",
        "맥스풀링(kernel_size=2, stride=2))\n",
        "\n",
        "# 3번 레이어 : 합성곱층(Convolutional layer)\n",
        "합성곱(in_channel = 64, out_channel = 128, kernel_size=3, stride=1, padding=1) + 활성화 함수 ReLU\n",
        "맥스풀링(kernel_size=2, stride=2, padding=1))\n",
        "\n",
        "# 4번 레이어 : 전결합층(Fully-Connected layer)\n",
        "특성맵을 펼친다. # batch_size  × 128 × 4 × 4 → batch_size × 2048\n",
        "전결합층(뉴런 625개) + 활성화 함수 ReLU\n",
        "\n",
        "# 5번 레이어 : 전결합층(Fully-Connected layer)\n",
        "전결합층(뉴런 10개) + 활성화 함수 Softmax\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7St1II40aVbd"
      },
      "source": [
        "### 6.3.2 깊은 CNN으로 MNIST 분류하기\n",
        "\n",
        "사실 이번 챕터의 코드는 이전 챕터에서 층이 조금 더 추가되는 것 말고는 동일합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btCUlV3eZzeM"
      },
      "source": [
        "import torch\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.init"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfdLLkdzahCd"
      },
      "source": [
        "만약 GPU를 사용 가능하다면 device 값이 cuda가 되고, 아니라면 cpu가 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgWTyn6xafoF"
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# 랜덤 시드 고정\n",
        "torch.manual_seed(777)\n",
        "\n",
        "# GPU 사용 가능일 경우 랜덤 시드 고정\n",
        "if device == 'cuda':\n",
        "    torch.cuda.manual_seed_all(777)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NkplvEEajuu"
      },
      "source": [
        "학습에 사용할 파라미터를 설정합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xb604pMwailH"
      },
      "source": [
        "learning_rate = 0.001\n",
        "training_epochs = 15\n",
        "batch_size = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25LNMX1_amdP"
      },
      "source": [
        "데이터로더를 사용하여 데이터를 다루기 위해서 데이터셋을 정의해줍니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cH83iNRMalSs"
      },
      "source": [
        "mnist_train = dsets.MNIST(root='MNIST_data/', # 다운로드 경로 지정\n",
        "                          train=True, # True를 지정하면 훈련 데이터로 다운로드\n",
        "                          transform=transforms.ToTensor(), # 텐서로 변환\n",
        "                          download=True)\n",
        "\n",
        "mnist_test = dsets.MNIST(root='MNIST_data/', # 다운로드 경로 지정\n",
        "                         train=False, # False를 지정하면 테스트 데이터로 다운로드\n",
        "                         transform=transforms.ToTensor(), # 텐서로 변환\n",
        "                         download=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_03vv_3lapxJ"
      },
      "source": [
        "데이터로더를 사용하여 배치 크기를 지정해줍니다. 만약 데이터셋과 데이터로더가 기억이 안 난다면 '미니 배치와 데이터 로드' 챕터를 꼭 복습하세요."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x16P4dk9aoDE"
      },
      "source": [
        "data_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=True,\n",
        "                                          drop_last=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ZkfRwMXatZZ"
      },
      "source": [
        "이제 클래스로 모델을 설계합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XduoNa8arjb"
      },
      "source": [
        "class CNN(torch.nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.keep_prob = 0.5\n",
        "        # L1 ImgIn shape=(?, 1, 28, 28)\n",
        "        #    Conv     -> (?, 32, 28, 28)\n",
        "        #    Pool     -> (?, 32, 14, 14)\n",
        "        self.layer1 = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        # L2 ImgIn shape=(?, 32, 14, 14)\n",
        "        #    Conv      ->(?, 64, 14, 14)\n",
        "        #    Pool      ->(?, 64, 7, 7)\n",
        "        self.layer2 = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        # L3 ImgIn shape=(?, 64, 7, 7)\n",
        "        #    Conv      ->(?, 128, 7, 7)\n",
        "        #    Pool      ->(?, 128, 4, 4)\n",
        "        self.layer3 = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=1))\n",
        "\n",
        "        # L4 FC 4x4x128 inputs -> 625 outputs\n",
        "        self.fc1 = torch.nn.Linear(4 * 4 * 128, 625, bias=True)\n",
        "        torch.nn.init.xavier_uniform_(self.fc1.weight)\n",
        "        self.layer4 = torch.nn.Sequential(\n",
        "            self.fc1,\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Dropout(p=1 - self.keep_prob))\n",
        "        # L5 Final FC 625 inputs -> 10 outputs\n",
        "        self.fc2 = torch.nn.Linear(625, 10, bias=True)\n",
        "        torch.nn.init.xavier_uniform_(self.fc2.weight)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = out.view(out.size(0), -1)   # Flatten them for FC\n",
        "        out = self.layer4(out)\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFIVxZrGaw8D"
      },
      "source": [
        "모델을 정의합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9F4yVzRfavXm"
      },
      "source": [
        "# CNN 모델 정의\n",
        "model = CNN().to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmVLO0ZNa0cE"
      },
      "source": [
        "비용 함수와 옵티마이저를 정의합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cczQPY7NazQ8"
      },
      "source": [
        "criterion = torch.nn.CrossEntropyLoss().to(device)    # 비용 함수에 소프트맥스 함수 포함되어져 있음.\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4hlEZ1ha2_9"
      },
      "source": [
        "총 배치의 수를 출력해보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBxqv6Zea169",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "08b1ea59-c34e-4d7b-a1e5-4729de9470f5"
      },
      "source": [
        "total_batch = len(data_loader)\n",
        "print('총 배치의 수 : {}'.format(total_batch))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "총 배치의 수 : 600\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIw7dHOYa52i"
      },
      "source": [
        "총 배치의 수는 600입니다. 그런데 배치 크기를 100으로 했으므로 결국 훈련 데이터는 총 60,000개란 의미입니다. 이제 모델을 훈련시켜보겠습니다. (시간이 꽤 오래 걸립니다.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfRya8Ioa4hw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "73d98d7d-4a95-483a-e1ef-bfcd0e56619b"
      },
      "source": [
        "for epoch in range(training_epochs):\n",
        "    avg_cost = 0\n",
        "\n",
        "    for X, Y in data_loader: # 미니 배치 단위로 꺼내온다. X는 미니 배치, Y느 ㄴ레이블.\n",
        "        # image is already size of (28x28), no reshape\n",
        "        # label is not one-hot encoded\n",
        "        X = X.to(device)\n",
        "        Y = Y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        hypothesis = model(X)\n",
        "        cost = criterion(hypothesis, Y)\n",
        "        cost.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        avg_cost += cost / total_batch\n",
        "\n",
        "    print('[Epoch: {:>4}] cost = {:>.9}'.format(epoch + 1, avg_cost))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Epoch:    1] cost = 0.188890502\n",
            "[Epoch:    2] cost = 0.0516052097\n",
            "[Epoch:    3] cost = 0.0381604284\n",
            "[Epoch:    4] cost = 0.0296325386\n",
            "[Epoch:    5] cost = 0.0232051183\n",
            "[Epoch:    6] cost = 0.0188576579\n",
            "[Epoch:    7] cost = 0.016843183\n",
            "[Epoch:    8] cost = 0.0157588534\n",
            "[Epoch:    9] cost = 0.013913529\n",
            "[Epoch:   10] cost = 0.0113126049\n",
            "[Epoch:   11] cost = 0.010036381\n",
            "[Epoch:   12] cost = 0.0101416381\n",
            "[Epoch:   13] cost = 0.00922845118\n",
            "[Epoch:   14] cost = 0.00916809682\n",
            "[Epoch:   15] cost = 0.00737075135\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vsy0Pq6Qa9Xi"
      },
      "source": [
        "이제 테스트를 해보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBQG4iTwa7sr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "998fc3b5-b907-4284-dc36-128e23211bf5"
      },
      "source": [
        "# 학습을 진행하지 않을 것이므로 torch.no_grad()\n",
        "with torch.no_grad():\n",
        "    X_test = mnist_test.test_data.view(len(mnist_test), 1, 28, 28).float().to(device)\n",
        "    Y_test = mnist_test.test_labels.to(device)\n",
        "\n",
        "    prediction = model(X_test)\n",
        "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
        "    accuracy = correct_prediction.float().mean()\n",
        "    print('Accuracy:', accuracy.item())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9810999631881714\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:60: UserWarning: test_data has been renamed data\n",
            "  warnings.warn(\"test_data has been renamed data\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:50: UserWarning: test_labels has been renamed targets\n",
            "  warnings.warn(\"test_labels has been renamed targets\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xH52WvTlbARk"
      },
      "source": [
        "층을 더 깊게 쌓았는데 오히려 정확도가 줄어드는 것을 볼 수 있습니다. 결국 층을 깊게 쌓는 것도 중요하지만, 꼭 깊게 쌓는 것이 정확도를 올려주지는 않으며 효율적으로 쌓는 것도 중요하다는 의미입니다."
      ]
    }
  ]
}