{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled27.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNMZ+/YfPkOUkqFEbdszPpy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Namsik-Yoon/pytorch_basic/blob/master/7_1_%EC%9E%90%EC%97%B0%EC%96%B4%20%EC%B2%98%EB%A6%AC%EC%9D%98%20%EC%A0%84%EC%B2%98%EB%A6%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xPH35LoKyZi",
        "colab_type": "text"
      },
      "source": [
        "# text 데이터 전처리 실습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zv1EErIHKzR4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install wget\n",
        "import wget"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLzT-8kcgkil",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git\n",
        "%cd Mecab-ko-for-Google-Colab\n",
        "!bash install_mecab-ko_on_colab190912.sh"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuFn_cVgupjz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fd0b2985-fec5-4fe9-8f96-eca86a3a5d2a"
      },
      "source": [
        "wget.download('https://www.dropbox.com/s/vbbnve5znm0bjiq/Joker_script.txt?dl=1')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Joker_script.txt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgVxEYRBFhNI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dd69f91b-ce26-4e07-dcd5-dc3a6d965981"
      },
      "source": [
        "input_file = open('Joker_script.txt','r')\n",
        "lines = input_file.readlines()\n",
        "lines[:100]"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['JOKER\\n',\n",
              " '\\n',\n",
              " '                          AN ORIGIN\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '                         Written by\\n',\n",
              " '\\n',\n",
              " '                 Todd Phillips & Scott Silver\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '                                                  13 April 2018 \\n',\n",
              " '\\n',\n",
              " '  This story takes place in its own universe. It has no\\n',\n",
              " '  connection to any of the DC films that have come before it.\\n',\n",
              " '\\n',\n",
              " '  We see it as a classic Warner Bros. movie. Gritty, intimate\\n',\n",
              " '  and oddly funny, the characters live in the real world and\\n',\n",
              " '  the stakes are personal.\\n',\n",
              " '\\n',\n",
              " '  Although it is never mentioned in the film, this story takes\\n',\n",
              " '  place in the past.\\n',\n",
              " '\\n',\n",
              " \"  Let's call it 1981.\\n\",\n",
              " '\\n',\n",
              " \"  It's a troubled time. The crime rate in Gotham is at record\\n\",\n",
              " '  highs. A garbage strike has crippled the city for the past\\n',\n",
              " '  six weeks. And the divide between the \"haves\" and the \"have-\\n',\n",
              " '  nots\" is palpable. Dreams are beyond reach, slipping into\\n',\n",
              " '  delusions.\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '                                                      OVER BLACK:\\n',\n",
              " '\\n',\n",
              " '    HEAR LAUGHTER.\\n',\n",
              " '\\n',\n",
              " '    The sound of a man totally cracking up.\\n',\n",
              " '\\n',\n",
              " '                                                        FADE IN:\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '1   INT. DEPT. OF HEALTH, OFFICE - MORNING                          1\\n',\n",
              " '\\n',\n",
              " \"    CLOSE ON JOKER (30's), tears in his eyes from laughing so\\n\",\n",
              " \"    hard. He's trying to get it under control. His greasy, black\\n\",\n",
              " \"    hair is matted down. He's wearing an old, faded red hooded\\n\",\n",
              " '    zip-up sweatshirt, a threadbare gray scarf, thin from years\\n',\n",
              " '    of use, hangs loosely around his neck.\\n',\n",
              " '\\n',\n",
              " '    WE NOTICE TWO FADED OLD SCARS cut at the corners of his\\n',\n",
              " '    mouth. Almost forming a smile.\\n',\n",
              " '\\n',\n",
              " \"    He's sitting across from an overworked SOCIAL WORKER (50's),\\n\",\n",
              " '    African American. Her office is cramped and run-down in a\\n',\n",
              " '    cramped and run-down building. Stacks of folders piled high\\n',\n",
              " '    in front of her.\\n',\n",
              " '\\n',\n",
              " '    She just sits behind her desk, waiting for his laughing fit\\n',\n",
              " \"    to end, she's been through this before. Finally it subsides.\\n\",\n",
              " '\\n',\n",
              " \"    Joker takes a deep breath, pauses to see if it's over.\\n\",\n",
              " '\\n',\n",
              " '    Beat.\\n',\n",
              " '\\n',\n",
              " '                        JOKER\\n',\n",
              " '              --is it just me, or is it getting\\n',\n",
              " '              crazier out there?\\n',\n",
              " '\\n',\n",
              " \"    Despite the laughter, there's real pain in his eyes.\\n\",\n",
              " \"    Something broken in him. Looks like he hasn't slept in days.\\n\",\n",
              " '\\n',\n",
              " '                         SOCIAL WORKER\\n',\n",
              " \"              It's certainly tense. People are\\n\",\n",
              " \"              upset, they're struggling. Looking\\n\",\n",
              " '              for work. The garbage strike seems\\n',\n",
              " \"              like it's been going on forever.\\n\",\n",
              " '              These are tough times.\\n',\n",
              " '                  (then)\\n',\n",
              " \"              How 'bout you. How's the job? Still\\n\",\n",
              " '              enjoying it?\\n',\n",
              " '\\n',\n",
              " '                          JOKER\\n',\n",
              " \"              Yeah, I   mean, it's different each\\n\",\n",
              " \"              day, so   I really like that. I don't\\n\",\n",
              " '              think I   could ever work in an\\n',\n",
              " '              office.   Behind a desk.\\n',\n",
              " '                          (MORE)\\n',\n",
              " '                                                         2.\\n',\n",
              " '\\n',\n",
              " \"                     JOKER (CONT'D)\\n\",\n",
              " '              (beat)\\n',\n",
              " '          No offense.\\n',\n",
              " '\\n',\n",
              " \"She smiles. Writes something down. Looks at the clock, she's\\n\",\n",
              " 'running late for her next appointment.\\n',\n",
              " '\\n']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGpLzvT3usuB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "\n",
        "temp_sentence = ''\n",
        "raw_sentence = ''\n",
        "\n",
        "for line in lines:\n",
        "    line = re.sub('[^a-zA-Z0-9.]',' ',line.lower())\n",
        "    raw_sentence+=line"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ErnF641Cpd2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "outputId": "01ee5a11-50ff-43ef-9187-db0c40bfe906"
      },
      "source": [
        "splited_sentence = raw_sentence.split('.')\n",
        "splited_sentence[:20]"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['joker                            an origin                              written by                   todd phillips   scott silver                                                       13 april 2018     this story takes place in its own universe',\n",
              " ' it has no   connection to any of the dc films that have come before it',\n",
              " '    we see it as a classic warner bros',\n",
              " ' movie',\n",
              " ' gritty  intimate   and oddly funny  the characters live in the real world and   the stakes are personal',\n",
              " '    although it is never mentioned in the film  this story takes   place in the past',\n",
              " '    let s call it 1981',\n",
              " '    it s a troubled time',\n",
              " ' the crime rate in gotham is at record   highs',\n",
              " ' a garbage strike has crippled the city for the past   six weeks',\n",
              " ' and the divide between the  haves  and the  have    nots  is palpable',\n",
              " ' dreams are beyond reach  slipping into   delusions',\n",
              " '                                                          over black       hear laughter',\n",
              " '      the sound of a man totally cracking up',\n",
              " '                                                          fade in    1   int',\n",
              " ' dept',\n",
              " ' of health  office   morning                          1      close on joker  30 s   tears in his eyes from laughing so     hard',\n",
              " ' he s trying to get it under control',\n",
              " ' his greasy  black     hair is matted down',\n",
              " ' he s wearing an old  faded red hooded     zip up sweatshirt  a threadbare gray scarf  thin from years     of use  hangs loosely around his neck']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxIK40MUH6nB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cleansed_splited_sentence = []\n",
        "for sentence in splited_sentence:\n",
        "    temp_sentence = ''\n",
        "    words = sentence.split(' ')\n",
        "    for word in words:\n",
        "        if word !='':\n",
        "            temp_sentence+=word+' '\n",
        "    if temp_sentence[:-1] == '':continue\n",
        "    cleansed_splited_sentence.append(temp_sentence[:-1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oI_vc-jUGrPu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "d007782c-2476-40a6-faef-1a24208ae043"
      },
      "source": [
        "cleansed_splited_sentence[:10]"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['joker an origin written by todd phillips scott silver 13 april 2018 this story takes place in its own universe',\n",
              " 'it has no connection to any of the dc films that have come before it',\n",
              " 'we see it as a classic warner bros',\n",
              " 'movie',\n",
              " 'gritty intimate and oddly funny the characters live in the real world and the stakes are personal',\n",
              " 'although it is never mentioned in the film this story takes place in the past',\n",
              " 'let s call it 1981',\n",
              " 'it s a troubled time',\n",
              " 'the crime rate in gotham is at record highs',\n",
              " 'a garbage strike has crippled the city for the past six weeks']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gr9hfKYSz4WZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "40a3749e-1e3f-4d96-f86b-61a55c970095"
      },
      "source": [
        "splited_word = []\n",
        "for sentence in cleansed_splited_sentence:\n",
        "    words = sentence.split(' ')\n",
        "    splited_word+=words\n",
        "        \n",
        "splited_word[:10]"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['joker',\n",
              " 'an',\n",
              " 'origin',\n",
              " 'written',\n",
              " 'by',\n",
              " 'todd',\n",
              " 'phillips',\n",
              " 'scott',\n",
              " 'silver',\n",
              " '13']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "naCOjW6n977P",
        "colab_type": "text"
      },
      "source": [
        "[영어 불용어](https://wikidocs.net/22530)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jydd3O1WzkrI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c3ccac8a-cc01-4655-f4f5-c278b7e02d6a"
      },
      "source": [
        "from nltk.corpus import stopwords \n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import FreqDist\n",
        "import numpy as np\n",
        "\n",
        "stop_words = set(stopwords.words('english')) \n",
        "stopwords.words('english')[:10]"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnw7NDO3zt5K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result = []\n",
        "for word in splited_word:\n",
        "    if word not in stop_words:\n",
        "        result.append(word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51XSjv0a-eDo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "6637f2a4-a7e5-4b28-fe65-b9e91662e2c8"
      },
      "source": [
        "result[:10]"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['joker',\n",
              " 'origin',\n",
              " 'written',\n",
              " 'todd',\n",
              " 'phillips',\n",
              " 'scott',\n",
              " 'silver',\n",
              " '13',\n",
              " 'april',\n",
              " '2018']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZJQPGBh-uPj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4c2a5df7-0fce-4e2c-a8e9-373e22d78858"
      },
      "source": [
        "vocab = FreqDist(np.hstack(result))\n",
        "print('단어 집합의 크기 : {}'.format(len(vocab)))"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "단어 집합의 크기 : 2989\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j64E0fK7-y0A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6c33ee08-35df-46fd-b908-bbe060524b3a"
      },
      "source": [
        "vocab['happy']"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGX3cdX2-0-2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a0e2ba46-ac10-4f96-811b-3bf986fee389"
      },
      "source": [
        "vocab_size = 1000\n",
        "# 상위 vocab_size개의 단어만 보존\n",
        "vocab = vocab.most_common(vocab_size)\n",
        "print('단어 집합의 크기 : {}'.format(len(vocab)))"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "단어 집합의 크기 : 1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fowZscFDB8Ko",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TU9vuQfLM_w",
        "colab_type": "text"
      },
      "source": [
        "# 네이버 영화 댓글 웹크롤링(조커)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHZedMgcLRr_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwbjq2gFLbWz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a4043699-7b9f-4139-d859-c3cf1529f646"
      },
      "source": [
        "test_url = \"https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=167613&type=after&page=1\"\n",
        "resp = requests.get(test_url)\n",
        "html = BeautifulSoup(resp.content, 'html.parser')\n",
        "html"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "<!DOCTYPE html>\n",
              "\n",
              "<html lang=\"ko\">\n",
              "<head>\n",
              "<meta charset=\"utf-8\"/>\n",
              "<meta content=\"IE=edge\" http-equiv=\"X-UA-Compatible\"/>\n",
              "<title>네이버 영화</title>\n",
              "<link href=\"https://ssl.pstatic.net/static/m/movie/icons/naver_movie_favicon.ico\" rel=\"shortcut icon\" type=\"image/x-icon\"/>\n",
              "<link href=\"/css/common.css?20200515103320\" rel=\"stylesheet\" type=\"text/css\">\n",
              "<link href=\"/css/movie_tablet.css?20200515103320\" rel=\"stylesheet\" type=\"text/css\"/>\n",
              "<link href=\"/css/movie_end.css?20200515103320\" rel=\"stylesheet\" type=\"text/css\"/>\n",
              "<script src=\"/js/deploy/movie.all.js?20200515103320\" type=\"text/javascript\"></script>\n",
              "</link></head>\n",
              "<body>\n",
              "<!-- content -->\n",
              "<input id=\"movieCode\" name=\"movieCode\" type=\"hidden\" value=\"167613\"/>\n",
              "<input id=\"onlyActualPointYn\" name=\"onlyActualPointYn\" type=\"hidden\" value=\"N\"/>\n",
              "<input id=\"includeSpoilerYn\" name=\"includeSpoilerYn\" type=\"hidden\" value=\"N\"/>\n",
              "<input id=\"order\" name=\"order\" type=\"hidden\" value=\"sympathyScore\"/>\n",
              "<input id=\"page\" name=\"page\" type=\"hidden\" value=\"1\"/>\n",
              "<div class=\"ifr_area basic_ifr\">\n",
              "<div class=\"input_netizen \">\n",
              "<!-- [D] 관람객 평점 작성 완료 -->\n",
              "<div class=\"ly_viewer\" id=\"actualPointWriteExecuteLayer\" style=\"display:none\">\n",
              "<h4>관람객 평점 작성 완료 안내</h4>\n",
              "<p>관람객 평점이 등록되었습니다.<br/><em>네이버페이 포인트 500원</em>이 적립되었습니다.<br/><em>7일 이후</em> 확인 가능합니다.</p>\n",
              "<p>(평점 삭제시, 적립된 포인트는 회수됩니다.)</p>\n",
              "<div class=\"btn\">\n",
              "<a class=\"ok\" href=\"#\" id=\"actualPointWriteExecuteLayerOkButton\">확인</a>\n",
              "<a class=\"close\" href=\"#\" id=\"actualPointWriteExecuteLayerCloseButton\" title=\"닫기\">관람객 평점 작성 완료 안내 레이어 닫기</a>\n",
              "</div>\n",
              "</div>\n",
              "<!-- //관람객 평점 작성 완료 -->\n",
              "<!-- [D] 관람객 평점 작성 완료2 -->\n",
              "<div class=\"ly_viewer\" id=\"pointWriteExecuteLayer\" style=\"display:none\">\n",
              "<h4>관람객 평점 작성 완료 안내</h4>\n",
              "<p class=\"msg1\">관람객 평점이 등록되었습니다.</p>\n",
              "<div class=\"btn\">\n",
              "<a class=\"ok\" href=\"#\" id=\"pointWriteExecuteLayerOkButton\">확인</a>\n",
              "<a class=\"close\" href=\"#\" id=\"pointWriteExecuteLayerCloseButton\" title=\"닫기\">관람객 평점 작성 완료 안내 레이어 닫기</a>\n",
              "</div>\n",
              "</div>\n",
              "<!-- //관람객 평점 작성 완료2 -->\n",
              "<div class=\"score_total\">\n",
              "<strong class=\"total\">관람객 평점 <em>30,004</em>건<button class=\"btn_review\" id=\"open-form-btn\">내 평점 등록</button></strong>\n",
              "</div>\n",
              "<div class=\"top_behavior\" id=\"orderCheckbox\">\n",
              "<ul class=\"sorting_list\">\n",
              "<li class=\"on\"><a href=\"#\" onclick=\"parent.clickcr(this, 'ara.bysym', '', '', event); dislplayOrder('sympathyScore');\">공감순</a></li>\n",
              "<li><a href=\"#\" onclick=\"parent.clickcr(this, 'ara.byrct', '', '', event); dislplayOrder('newest');\">최신순</a></li>\n",
              "<li><a href=\"#\" onclick=\"parent.clickcr(this, 'ara.high', '', '', event); dislplayOrder('highest');\">평점 높은 순</a></li>\n",
              "<li><a href=\"#\" onclick=\"parent.clickcr(this, 'ara.low', '', '', event); dislplayOrder('lowest');\">평점 낮은 순</a></li>\n",
              "</ul>\n",
              "<ul class=\"quarter_mode\">\n",
              "<li>\n",
              "<input class=\"blind \" id=\"spoilerYnCheckBox\" name=\"spilerViewer\" onclick=\"parent.clickcr(this,'','','',event); return false;\" title=\"스포일러 보기\" type=\"checkbox\"/>\n",
              "<label class=\"label_viewer\" for=\"spoilerYnCheckBox\" id=\"spoilerYnLable\">스포일러 보기</label>\n",
              "</li>\n",
              "<li>\n",
              "<input class=\"blind \" id=\"actualYnCheckBox\" name=\"viewer\" onclick=\"parent.clickcr(this,'ura.mgs','','',event); return false;\" title=\"관람객 평점만 보기\" type=\"checkbox\"/>\n",
              "<label class=\"label_viewer\" for=\"actualYnCheckBox\" id=\"actualYnLable\">관람객 평점만 보기</label>\n",
              "<a class=\"help _actualPointHelp\" href=\"#\" id=\"actualPointHelpButton\" title=\"도움말\">관람객 평점만 보기 도움말</a>\n",
              "<div class=\"ly_help _actualPointHelp\" id=\"actualPointHelp\" style=\"display:none\">\n",
              "<h5>관람객평점만 보기 안내 레이어</h5>\n",
              "<div class=\"ly_cont _actualPointHelp\">\n",
              "<p>네이버 영화에서 예매하신 고객님들이<br/> 영화 관람 후 등록해주신 평점입니다.</p>\n",
              "</div>\n",
              "<button class=\"btn_close _actualPointHelp\" id=\"actualPointHelpCloseButton\" title=\"닫기\" type=\"button\"><span class=\"blind\">관람객 평점만 보기 안내 레이어 닫기</span></button>\n",
              "<span class=\"arr _actualPointHelp\"></span>\n",
              "</div>\n",
              "</li>\n",
              "</ul>\n",
              "</div>\n",
              "<div class=\"score_result\">\n",
              "<ul>\n",
              "<li>\n",
              "<div class=\"star_score\">\n",
              "<span class=\"st_off\"><span class=\"st_on\" style=\"width:100.0%\"></span></span><em>10</em>\n",
              "</div>\n",
              "<div class=\"score_reple\">\n",
              "<p>\n",
              "<!-- 스포일러 컨텐츠로 처리되는지 여부 -->\n",
              "<span id=\"_filtered_ment_0\">\n",
              "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
              "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
              "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
              "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t착하게 사는것은 높은 계단을 오르는것과 같지만 포기하고 내려갈때는 너무나도 빠르고 즐겁다. \n",
              "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
              "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
              "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
              "\t\t\t\t\t\t\t\t\t\t\t\t\t</span>\n",
              "</p>\n",
              "<dl>\n",
              "<dt>\n",
              "<em>\n",
              "<a href=\"#\" onclick=\"javascript:showPointListByNid(16219865, 'after');parent.clickcr(this, 'ara.uid', '', '', event); return false;\" target=\"_top\">\n",
              "<span>버블껌(roac****)</span>\n",
              "</a>\n",
              "</em>\n",
              "<em>2019.10.02 12:54</em>\n",
              "</dt>\n",
              "<dd>\n",
              "<a class=\"go_report2\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.report', '', '', event); common.report('false','roac****', 'iiCVFSlTLdR62UUS6c/98OoxQSoOdzFoljx3vFpinBk=', '착하게 사는것은 높은 계단을 오르는것과 같지만 포기하고 내려갈때는 너무나도 빠르고 즐겁다. ', '16219865', 'point_after', false);return false;\"><em>신고</em></a>\n",
              "</dd>\n",
              "</dl>\n",
              "</div>\n",
              "<div class=\"btn_area\">\n",
              "<a class=\"_sympathyButton\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.sym', '', '', event);\">\n",
              "<span class=\"ico_up\"></span>\n",
              "<span class=\"blind\">공감</span>\n",
              "<strong class=\"sympathy_16219865\">24194</strong>\n",
              "</a>\n",
              "<a class=\"_notSympathyButton\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.opp', '', '', event);\">\n",
              "<span class=\"ico_down\"></span>\n",
              "<span class=\"blind\">비공감</span>\n",
              "<strong class=\"notSympathy_16219865\">1023</strong>\n",
              "</a>\n",
              "</div>\n",
              "</li>\n",
              "<li>\n",
              "<div class=\"star_score\">\n",
              "<span class=\"st_off\"><span class=\"st_on\" style=\"width:100.0%\"></span></span><em>10</em>\n",
              "</div>\n",
              "<div class=\"score_reple\">\n",
              "<p>\n",
              "<!-- 스포일러 컨텐츠로 처리되는지 여부 -->\n",
              "<span id=\"_filtered_ment_1\">\n",
              "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
              "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
              "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
              "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t하여간 역대 조커들은 너무 완벽해. 시저 로메로, 잭니콜슨, 로저 스톤버너, 히스레저, 박명수, 호아킨 피닉스.. \n",
              "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
              "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
              "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
              "\t\t\t\t\t\t\t\t\t\t\t\t\t</span>\n",
              "</p>\n",
              "<dl>\n",
              "<dt>\n",
              "<em>\n",
              "<a href=\"#\" onclick=\"javascript:showPointListByNid(16218948, 'after');parent.clickcr(this, 'ara.uid', '', '', event); return false;\" target=\"_top\">\n",
              "<span>꼬망스(jang****)</span>\n",
              "</a>\n",
              "</em>\n",
              "<em>2019.10.02 10:27</em>\n",
              "</dt>\n",
              "<dd>\n",
              "<a class=\"go_report2\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.report', '', '', event); common.report('false','jang****', 'ZBv6QEtk8Mb7DCFcSKoUFVI5vGd9TYObXrOeq5PcgcE=', '하여간 역대 조커들은 너무 완벽해. 시저 로메로, 잭니콜슨, 로저 스톤버너, 히스레저, 박명수, 호아킨 피닉스.. ', '16218948', 'point_after', false);return false;\"><em>신고</em></a>\n",
              "</dd>\n",
              "</dl>\n",
              "</div>\n",
              "<div class=\"btn_area\">\n",
              "<a class=\"_sympathyButton\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.sym', '', '', event);\">\n",
              "<span class=\"ico_up\"></span>\n",
              "<span class=\"blind\">공감</span>\n",
              "<strong class=\"sympathy_16218948\">14027</strong>\n",
              "</a>\n",
              "<a class=\"_notSympathyButton\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.opp', '', '', event);\">\n",
              "<span class=\"ico_down\"></span>\n",
              "<span class=\"blind\">비공감</span>\n",
              "<strong class=\"notSympathy_16218948\">1592</strong>\n",
              "</a>\n",
              "</div>\n",
              "</li>\n",
              "<li>\n",
              "<div class=\"star_score\">\n",
              "<span class=\"st_off\"><span class=\"st_on\" style=\"width:100.0%\"></span></span><em>10</em>\n",
              "</div>\n",
              "<div class=\"score_reple\">\n",
              "<p>\n",
              "<!-- 스포일러 컨텐츠로 처리되는지 여부 -->\n",
              "<span id=\"_filtered_ment_2\">\n",
              "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
              "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
              "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
              "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t명작들만 골라서 번역하는 박지훈이야말로 이시대의 조커 아닐까? \n",
              "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
              "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
              "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
              "\t\t\t\t\t\t\t\t\t\t\t\t\t</span>\n",
              "</p>\n",
              "<dl>\n",
              "<dt>\n",
              "<em>\n",
              "<a href=\"#\" onclick=\"javascript:showPointListByNid(16219400, 'after');parent.clickcr(this, 'ara.uid', '', '', event); return false;\" target=\"_top\">\n",
              "<span>김민수(msms****)</span>\n",
              "</a>\n",
              "</em>\n",
              "<em>2019.10.02 11:51</em>\n",
              "</dt>\n",
              "<dd>\n",
              "<a class=\"go_report2\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.report', '', '', event); common.report('false','msms****', 'RuTroT3bQ/ZqhEmTLw0r/mP7S2Qvso+Odosju4TtA5Y=', '명작들만 골라서 번역하는 박지훈이야말로 이시대의 조커 아닐까? ', '16219400', 'point_after', false);return false;\"><em>신고</em></a>\n",
              "</dd>\n",
              "</dl>\n",
              "</div>\n",
              "<div class=\"btn_area\">\n",
              "<a class=\"_sympathyButton\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.sym', '', '', event);\">\n",
              "<span class=\"ico_up\"></span>\n",
              "<span class=\"blind\">공감</span>\n",
              "<strong class=\"sympathy_16219400\">12257</strong>\n",
              "</a>\n",
              "<a class=\"_notSympathyButton\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.opp', '', '', event);\">\n",
              "<span class=\"ico_down\"></span>\n",
              "<span class=\"blind\">비공감</span>\n",
              "<strong class=\"notSympathy_16219400\">747</strong>\n",
              "</a>\n",
              "</div>\n",
              "</li>\n",
              "<li>\n",
              "<div class=\"star_score\">\n",
              "<span class=\"st_off\"><span class=\"st_on\" style=\"width:100.0%\"></span></span><em>10</em>\n",
              "</div>\n",
              "<div class=\"score_reple\">\n",
              "<p>\n",
              "<!-- 스포일러 컨텐츠로 처리되는지 여부 -->\n",
              "<span id=\"_filtered_ment_3\">\n",
              "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
              "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
              "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
              "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t마블은 10년간 공들여 만든 \"타노스\"로 관객을 열광시키고 DC는 10년간 똥을 싸도 \"조커\" 하나로 다시 부활한다. \n",
              "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
              "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
              "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
              "\t\t\t\t\t\t\t\t\t\t\t\t\t</span>\n",
              "</p>\n",
              "<dl>\n",
              "<dt>\n",
              "<em>\n",
              "<a href=\"#\" onclick=\"javascript:showPointListByNid(16220473, 'after');parent.clickcr(this, 'ara.uid', '', '', event); return false;\" target=\"_top\">\n",
              "<span>엿먹어(cheo****)</span>\n",
              "</a>\n",
              "</em>\n",
              "<em>2019.10.02 14:23</em>\n",
              "</dt>\n",
              "<dd>\n",
              "<a class=\"go_report2\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.report', '', '', event); common.report('false','cheo****', 'oF7yBb6zHjLUQ1UK5VDZKn8N1awWh4OoXXnub13j5I8=', '마블은 10년간 공들여 만든 &quot;타노스&quot;로 관객을 열광시키고 DC는 10년간 똥을 싸도 &quot;조커&quot; 하나로 다시 부활한다. ', '16220473', 'point_after', false);return false;\"><em>신고</em></a>\n",
              "</dd>\n",
              "</dl>\n",
              "</div>\n",
              "<div class=\"btn_area\">\n",
              "<a class=\"_sympathyButton\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.sym', '', '', event);\">\n",
              "<span class=\"ico_up\"></span>\n",
              "<span class=\"blind\">공감</span>\n",
              "<strong class=\"sympathy_16220473\">9788</strong>\n",
              "</a>\n",
              "<a class=\"_notSympathyButton\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.opp', '', '', event);\">\n",
              "<span class=\"ico_down\"></span>\n",
              "<span class=\"blind\">비공감</span>\n",
              "<strong class=\"notSympathy_16220473\">552</strong>\n",
              "</a>\n",
              "</div>\n",
              "</li>\n",
              "<li>\n",
              "<div class=\"star_score\">\n",
              "<span class=\"st_off\"><span class=\"st_on\" style=\"width:100.0%\"></span></span><em>10</em>\n",
              "</div>\n",
              "<div class=\"score_reple\">\n",
              "<p>\n",
              "<!-- 스포일러 컨텐츠로 처리되는지 여부 -->\n",
              "<span id=\"_filtered_ment_4\">\n",
              "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
              "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
              "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
              "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t조커 분장 후 계단씬 지린다.. \n",
              "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
              "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
              "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
              "\t\t\t\t\t\t\t\t\t\t\t\t\t</span>\n",
              "</p>\n",
              "<dl>\n",
              "<dt>\n",
              "<em>\n",
              "<a href=\"#\" onclick=\"javascript:showPointListByNid(16218705, 'after');parent.clickcr(this, 'ara.uid', '', '', event); return false;\" target=\"_top\">\n",
              "<span>포동잉(epod****)</span>\n",
              "</a>\n",
              "</em>\n",
              "<em>2019.10.02 09:02</em>\n",
              "</dt>\n",
              "<dd>\n",
              "<a class=\"go_report2\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.report', '', '', event); common.report('false','epod****', 'yiPxnAvPj9vyLx4E1PVXbLZp/HmaAnrpvq6WMlIK9PE=', '조커 분장 후 계단씬 지린다.. ', '16218705', 'point_after', false);return false;\"><em>신고</em></a>\n",
              "</dd>\n",
              "</dl>\n",
              "</div>\n",
              "<div class=\"btn_area\">\n",
              "<a class=\"_sympathyButton\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.sym', '', '', event);\">\n",
              "<span class=\"ico_up\"></span>\n",
              "<span class=\"blind\">공감</span>\n",
              "<strong class=\"sympathy_16218705\">9655</strong>\n",
              "</a>\n",
              "<a class=\"_notSympathyButton\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.opp', '', '', event);\">\n",
              "<span class=\"ico_down\"></span>\n",
              "<span class=\"blind\">비공감</span>\n",
              "<strong class=\"notSympathy_16218705\">467</strong>\n",
              "</a>\n",
              "</div>\n",
              "</li>\n",
              "<li>\n",
              "<div class=\"star_score\">\n",
              "<span class=\"st_off\"><span class=\"st_on\" style=\"width:100.0%\"></span></span><em>10</em>\n",
              "</div>\n",
              "<div class=\"score_reple\">\n",
              "<p>\n",
              "<!-- 스포일러 컨텐츠로 처리되는지 여부 -->\n",
              "<span id=\"_filtered_ment_5\">\n",
              "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
              "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
              "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
              "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t작은 친구의 이마에 입맞춤하던, 그리고 닿을 수 없는 잠금을 풀며 사과하던, 그가 아서였던 마지막 순간. \n",
              "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
              "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
              "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
              "\t\t\t\t\t\t\t\t\t\t\t\t\t</span>\n",
              "</p>\n",
              "<dl>\n",
              "<dt>\n",
              "<em>\n",
              "<a href=\"#\" onclick=\"javascript:showPointListByNid(16223872, 'after');parent.clickcr(this, 'ara.uid', '', '', event); return false;\" target=\"_top\">\n",
              "<span>지끼(peac****)</span>\n",
              "</a>\n",
              "</em>\n",
              "<em>2019.10.02 23:23</em>\n",
              "</dt>\n",
              "<dd>\n",
              "<a class=\"go_report2\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.report', '', '', event); common.report('false','peac****', 'J7AYnL6wEatQioFSCaYtcWW4FpuTJYJRD4OM1Q8jj6s=', '작은 친구의 이마에 입맞춤하던, 그리고 닿을 수 없는 잠금을 풀며 사과하던, 그가 아서였던 마지막 순간. ', '16223872', 'point_after', false);return false;\"><em>신고</em></a>\n",
              "</dd>\n",
              "</dl>\n",
              "</div>\n",
              "<div class=\"btn_area\">\n",
              "<a class=\"_sympathyButton\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.sym', '', '', event);\">\n",
              "<span class=\"ico_up\"></span>\n",
              "<span class=\"blind\">공감</span>\n",
              "<strong class=\"sympathy_16223872\">9462</strong>\n",
              "</a>\n",
              "<a class=\"_notSympathyButton\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.opp', '', '', event);\">\n",
              "<span class=\"ico_down\"></span>\n",
              "<span class=\"blind\">비공감</span>\n",
              "<strong class=\"notSympathy_16223872\">302</strong>\n",
              "</a>\n",
              "</div>\n",
              "</li>\n",
              "<li>\n",
              "<div class=\"star_score\">\n",
              "<span class=\"st_off\"><span class=\"st_on\" style=\"width:100.0%\"></span></span><em>10</em>\n",
              "</div>\n",
              "<div class=\"score_reple\">\n",
              "<p>\n",
              "<!-- 스포일러 컨텐츠로 처리되는지 여부 -->\n",
              "<span id=\"_filtered_ment_6\">\n",
              "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
              "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
              "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
              "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t나락에 떨어진 불행한 인간의 손을 아무도 잡아주지 않을 때 그 손을 잡아준건 광기였다 \n",
              "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
              "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
              "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
              "\t\t\t\t\t\t\t\t\t\t\t\t\t</span>\n",
              "</p>\n",
              "<dl>\n",
              "<dt>\n",
              "<em>\n",
              "<a href=\"#\" onclick=\"javascript:showPointListByNid(16219493, 'after');parent.clickcr(this, 'ara.uid', '', '', event); return false;\" target=\"_top\">\n",
              "<span>양갱기(yhg6****)</span>\n",
              "</a>\n",
              "</em>\n",
              "<em>2019.10.02 12:07</em>\n",
              "</dt>\n",
              "<dd>\n",
              "<a class=\"go_report2\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.report', '', '', event); common.report('false','yhg6****', 'O9uqCjpjz3Wz9trM+yu0NMY4I10Cpfh5aUbSmkbGYkk=', '나락에 떨어진 불행한 인간의 손을 아무도 잡아주지 않을 때 그 손을 잡아준건 광기였다 ', '16219493', 'point_after', false);return false;\"><em>신고</em></a>\n",
              "</dd>\n",
              "</dl>\n",
              "</div>\n",
              "<div class=\"btn_area\">\n",
              "<a class=\"_sympathyButton\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.sym', '', '', event);\">\n",
              "<span class=\"ico_up\"></span>\n",
              "<span class=\"blind\">공감</span>\n",
              "<strong class=\"sympathy_16219493\">8341</strong>\n",
              "</a>\n",
              "<a class=\"_notSympathyButton\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.opp', '', '', event);\">\n",
              "<span class=\"ico_down\"></span>\n",
              "<span class=\"blind\">비공감</span>\n",
              "<strong class=\"notSympathy_16219493\">333</strong>\n",
              "</a>\n",
              "</div>\n",
              "</li>\n",
              "<li>\n",
              "<div class=\"star_score\">\n",
              "<span class=\"st_off\"><span class=\"st_on\" style=\"width:80.0%\"></span></span><em>8</em>\n",
              "</div>\n",
              "<div class=\"score_reple\">\n",
              "<p>\n",
              "<!-- 스포일러 컨텐츠로 처리되는지 여부 -->\n",
              "<span id=\"_filtered_ment_7\">\n",
              "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
              "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
              "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
              "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t봉오동전투에6점을주고 조커에5점을주는 김현수평론가는 누구인가... \n",
              "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
              "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
              "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
              "\t\t\t\t\t\t\t\t\t\t\t\t\t</span>\n",
              "</p>\n",
              "<dl>\n",
              "<dt>\n",
              "<em>\n",
              "<a href=\"#\" onclick=\"javascript:showPointListByNid(16220413, 'after');parent.clickcr(this, 'ara.uid', '', '', event); return false;\" target=\"_top\">\n",
              "<span>이새솔(toth****)</span>\n",
              "</a>\n",
              "</em>\n",
              "<em>2019.10.02 14:15</em>\n",
              "</dt>\n",
              "<dd>\n",
              "<a class=\"go_report2\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.report', '', '', event); common.report('false','toth****', 'B/+HgCjTS8jmLLsYqwbXF6hCgJ+7YZZE04avUQgmrb4=', '봉오동전투에6점을주고 조커에5점을주는 김현수평론가는 누구인가... ', '16220413', 'point_after', false);return false;\"><em>신고</em></a>\n",
              "</dd>\n",
              "</dl>\n",
              "</div>\n",
              "<div class=\"btn_area\">\n",
              "<a class=\"_sympathyButton\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.sym', '', '', event);\">\n",
              "<span class=\"ico_up\"></span>\n",
              "<span class=\"blind\">공감</span>\n",
              "<strong class=\"sympathy_16220413\">7950</strong>\n",
              "</a>\n",
              "<a class=\"_notSympathyButton\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.opp', '', '', event);\">\n",
              "<span class=\"ico_down\"></span>\n",
              "<span class=\"blind\">비공감</span>\n",
              "<strong class=\"notSympathy_16220413\">579</strong>\n",
              "</a>\n",
              "</div>\n",
              "</li>\n",
              "<li>\n",
              "<div class=\"star_score\">\n",
              "<span class=\"st_off\"><span class=\"st_on\" style=\"width:100.0%\"></span></span><em>10</em>\n",
              "</div>\n",
              "<div class=\"score_reple\">\n",
              "<p>\n",
              "<!-- 스포일러 컨텐츠로 처리되는지 여부 -->\n",
              "<span id=\"_filtered_ment_8\">\n",
              "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
              "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
              "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
              "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t연기 스토리도 오지는데 장면마다 깔리는 음악들이 압권임 진짜 \n",
              "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
              "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
              "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
              "\t\t\t\t\t\t\t\t\t\t\t\t\t</span>\n",
              "</p>\n",
              "<dl>\n",
              "<dt>\n",
              "<em>\n",
              "<a href=\"#\" onclick=\"javascript:showPointListByNid(16219060, 'after');parent.clickcr(this, 'ara.uid', '', '', event); return false;\" target=\"_top\">\n",
              "<span>Barca 10(sezy****)</span>\n",
              "</a>\n",
              "</em>\n",
              "<em>2019.10.02 10:56</em>\n",
              "</dt>\n",
              "<dd>\n",
              "<a class=\"go_report2\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.report', '', '', event); common.report('false','sezy****', 'AkmgRm5q0Wrd/Nfxf0e9i3ZCl68r96BHrkeU3QuDXvE=', '연기 스토리도 오지는데 장면마다 깔리는 음악들이 압권임 진짜 ', '16219060', 'point_after', false);return false;\"><em>신고</em></a>\n",
              "</dd>\n",
              "</dl>\n",
              "</div>\n",
              "<div class=\"btn_area\">\n",
              "<a class=\"_sympathyButton\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.sym', '', '', event);\">\n",
              "<span class=\"ico_up\"></span>\n",
              "<span class=\"blind\">공감</span>\n",
              "<strong class=\"sympathy_16219060\">7325</strong>\n",
              "</a>\n",
              "<a class=\"_notSympathyButton\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.opp', '', '', event);\">\n",
              "<span class=\"ico_down\"></span>\n",
              "<span class=\"blind\">비공감</span>\n",
              "<strong class=\"notSympathy_16219060\">253</strong>\n",
              "</a>\n",
              "</div>\n",
              "</li>\n",
              "<li class=\"last\">\n",
              "<div class=\"star_score\">\n",
              "<span class=\"st_off\"><span class=\"st_on\" style=\"width:90.0%\"></span></span><em>9</em>\n",
              "</div>\n",
              "<div class=\"score_reple\">\n",
              "<p>\n",
              "<!-- 스포일러 컨텐츠로 처리되는지 여부 -->\n",
              "<span id=\"_filtered_ment_9\">\n",
              "<span class=\"_unfold_ment\" id=\"_unfold_ment9\">\n",
              "<a data-src=\"이게 19세가 아니라니 영등위 제정신인가? 마지막에 나도 모르게 조커를 따라 웃고있더라. 정신적으로 엄청 위험한 영화임.그리고 번역오류는 없다 하는데 정작 중요한 편지읽는장면에서 핵심단어를 맘대로 빼놓고 지 맘대로 요약해놓으면 어떻게 하냐.그래도 이게 조커의 탄생배경 설명중엔 가장 최고가 아닐까 싶다. DC는 진작 이렇게 했어야... 어설프게 마블따라하지 말자 좀 \" href=\"javascript:void(0);\" onclick=\"unfoldPointMent(this);\">\n",
              "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t이게 19세가 아니라니 영등위 제정신인가? 마지막에 나도 모르게 조커를 따라 웃고있더라. 정신적으로 엄청 위험한 영화임.그리고 번역오류는 없다 하는데 정작 중요한 편지읽는장면에서 핵심단어를 맘대로 빼놓고 지 맘대로 ...\n",
              "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t</a>\n",
              "</span>\n",
              "</span>\n",
              "</p>\n",
              "<dl>\n",
              "<dt>\n",
              "<em>\n",
              "<a href=\"#\" onclick=\"javascript:showPointListByNid(16219477, 'after');parent.clickcr(this, 'ara.uid', '', '', event); return false;\" target=\"_top\">\n",
              "<span>jjj2****</span>\n",
              "</a>\n",
              "</em>\n",
              "<em>2019.10.02 12:05</em>\n",
              "</dt>\n",
              "<dd>\n",
              "<a class=\"go_report2\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.report', '', '', event); common.report('false','jjj2****', 'e3vhT3FDCqC1H8GGRpCjtg1p5/45shMfAXWWJ/3l+ck=', '이게 19세가 아니라니 영등위 제정신인가? 마지막에 나도 모르게 조커를 따라 웃고있더라. 정신적으로 엄청 위험한 영화임.그리고 번역오류는 없다 하는데 정작 중요한 편지읽는장면에서 핵심단어를 맘대로 빼놓고 지 맘대로 요약해놓으면 어떻게 하냐.그래도 이게 조커의 탄생배경 설명중엔 가장 최고가 아닐까 싶다. DC는 진작 이렇게 했어야... 어설프게 마블따라하지 말자 좀 ', '16219477', 'point_after', false);return false;\"><em>신고</em></a>\n",
              "</dd>\n",
              "</dl>\n",
              "</div>\n",
              "<div class=\"btn_area\">\n",
              "<a class=\"_sympathyButton\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.sym', '', '', event);\">\n",
              "<span class=\"ico_up\"></span>\n",
              "<span class=\"blind\">공감</span>\n",
              "<strong class=\"sympathy_16219477\">7207</strong>\n",
              "</a>\n",
              "<a class=\"_notSympathyButton\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.opp', '', '', event);\">\n",
              "<span class=\"ico_down\"></span>\n",
              "<span class=\"blind\">비공감</span>\n",
              "<strong class=\"notSympathy_16219477\">821</strong>\n",
              "</a>\n",
              "</div>\n",
              "</li>\n",
              "</ul>\n",
              "</div>\n",
              "<div class=\"paging\">\n",
              "<div>\n",
              "<a href=\"/movie/bi/mi/pointWriteFormList.nhn?code=167613&amp;type=after&amp;page=1\" id=\"pagerTagAnchor1\" onclick=\"parent.clickcr(this, 'ara.page', '', '', event);\"><span class=\"on\">1</span></a>\n",
              "<a href=\"/movie/bi/mi/pointWriteFormList.nhn?code=167613&amp;type=after&amp;page=2\" id=\"pagerTagAnchor2\" onclick=\"parent.clickcr(this, 'ara.page', '', '', event);\"><span>2</span></a>\n",
              "<a href=\"/movie/bi/mi/pointWriteFormList.nhn?code=167613&amp;type=after&amp;page=3\" id=\"pagerTagAnchor3\" onclick=\"parent.clickcr(this, 'ara.page', '', '', event);\"><span>3</span></a>\n",
              "<a href=\"/movie/bi/mi/pointWriteFormList.nhn?code=167613&amp;type=after&amp;page=4\" id=\"pagerTagAnchor4\" onclick=\"parent.clickcr(this, 'ara.page', '', '', event);\"><span>4</span></a>\n",
              "<a href=\"/movie/bi/mi/pointWriteFormList.nhn?code=167613&amp;type=after&amp;page=5\" id=\"pagerTagAnchor5\" onclick=\"parent.clickcr(this, 'ara.page', '', '', event);\"><span>5</span></a>\n",
              "<a href=\"/movie/bi/mi/pointWriteFormList.nhn?code=167613&amp;type=after&amp;page=6\" id=\"pagerTagAnchor6\" onclick=\"parent.clickcr(this, 'ara.page', '', '', event);\"><span>6</span></a>\n",
              "<a href=\"/movie/bi/mi/pointWriteFormList.nhn?code=167613&amp;type=after&amp;page=7\" id=\"pagerTagAnchor7\" onclick=\"parent.clickcr(this, 'ara.page', '', '', event);\"><span>7</span></a>\n",
              "<a href=\"/movie/bi/mi/pointWriteFormList.nhn?code=167613&amp;type=after&amp;page=8\" id=\"pagerTagAnchor8\" onclick=\"parent.clickcr(this, 'ara.page', '', '', event);\"><span>8</span></a>\n",
              "<a href=\"/movie/bi/mi/pointWriteFormList.nhn?code=167613&amp;type=after&amp;page=9\" id=\"pagerTagAnchor9\" onclick=\"parent.clickcr(this, 'ara.page', '', '', event);\"><span>9</span></a>\n",
              "<a href=\"/movie/bi/mi/pointWriteFormList.nhn?code=167613&amp;type=after&amp;page=10\" id=\"pagerTagAnchor10\" onclick=\"parent.clickcr(this, 'ara.page', '', '', event);\"><span>10</span></a>\n",
              "<a class=\"pg_next\" href=\"/movie/bi/mi/pointWriteFormList.nhn?code=167613&amp;type=after&amp;page=2\" id=\"pagerTagAnchor2\" onclick=\"parent.clickcr(this, 'ara.page', '', '', event);\" title=\"다음\"><em>다음</em></a>\n",
              "</div>\n",
              "</div>\n",
              "</div>\n",
              "</div>\n",
              "<!-- //content -->\n",
              "<form accept-charset=\"euc-kr\" id=\"reportForm\" method=\"POST\" name=\"reportForm1\"></form>\n",
              "<script type=\"text/javascript\">\n",
              "\n",
              "\n",
              "if (false == false && \"after\" == \"after\" && false) {\n",
              "\tif (true && false) {\n",
              "\t\tjindo.$Element(\"pointWriteExecuteLayer\").show();\n",
              "\t} else if (false && true) {\n",
              "\t\tjindo.$Element(\"actualPointWriteExecuteLayer\").show();\n",
              "\t}\n",
              "}\n",
              "\n",
              "var oElActualPointWriteExecuteLayer = jindo.$Element(\"actualPointWriteExecuteLayer\");\n",
              "\n",
              "if (oElActualPointWriteExecuteLayer != null && oElActualPointWriteExecuteLayer != \"undefined\") {\n",
              "\n",
              "\t\n",
              "\tjindo.$Element(\"actualPointWriteExecuteLayerOkButton\").attach(\"click\", function(e){\n",
              "\t\te.stop(jindo.$Event.CANCEL_DEFAULT);\n",
              "\t\tjindo.$Element(\"actualPointWriteExecuteLayer\").hide();\n",
              "\t\trefreshPage();\n",
              "\t});\n",
              "\t\n",
              "\t\n",
              "\t\n",
              "\tjindo.$Element(\"actualPointWriteExecuteLayerCloseButton\").attach(\"click\", function(e){\n",
              "\t\te.stop(jindo.$Event.CANCEL_DEFAULT);\n",
              "\t\tjindo.$Element(\"actualPointWriteExecuteLayer\").hide();\n",
              "\t\trefreshPage();\n",
              "\t});\n",
              "\t\n",
              "}\n",
              "\n",
              "var oElPointWriteExecuteLayer = jindo.$Element(\"pointWriteExecuteLayer\");\n",
              "\n",
              "if (oElPointWriteExecuteLayer != null && oElPointWriteExecuteLayer != \"undefined\") {\n",
              "\t\n",
              "\tjindo.$Element(\"pointWriteExecuteLayerOkButton\").attach(\"click\", function(e){\n",
              "\t\te.stop(jindo.$Event.CANCEL_DEFAULT);\n",
              "\t\tjindo.$Element(\"pointWriteExecuteLayer\").hide();\n",
              "\t\trefreshPage();\n",
              "\t});\n",
              "\t\n",
              "\t\n",
              "\t\n",
              "\tjindo.$Element(\"pointWriteExecuteLayerCloseButton\").attach(\"click\", function(e){\n",
              "\t\te.stop(jindo.$Event.CANCEL_DEFAULT);\n",
              "\t\tjindo.$Element(\"pointWriteExecuteLayer\").hide();\n",
              "\t\trefreshPage();\n",
              "\t});\n",
              "\t\n",
              "}\n",
              "\n",
              "jindo.$Fn(function () {\n",
              "\n",
              "  function checkboxHandlerFactory(isActualYn, isLabel) {\n",
              "    return function() {\n",
              "      var actualYnChecked = jindo.$(\"actualYnCheckBox\").checked;\n",
              "      var spoilerYnChecked = jindo.$(\"spoilerYnCheckBox\").checked;\n",
              "\n",
              "      // convert\n",
              "      actualYnChecked = (isActualYn && isLabel)? !actualYnChecked : actualYnChecked;\n",
              "      spoilerYnChecked = (!isActualYn && isLabel)? !spoilerYnChecked : spoilerYnChecked;\n",
              "\n",
              "      location.href = \"/movie/bi/mi/pointWriteFormList.nhn?code=167613&type=after&onlyActualPointYn=\" + (actualYnChecked? \"Y\" : \"N\")  + \"&onlySpoilerPointYn=\" + (spoilerYnChecked? \"Y\" : \"N\") + \"&order=sympathyScore\";\n",
              "    };\n",
              "  }\n",
              "\n",
              "\t\n",
              "\tif (jindo.$(\"actualYnCheckBox\") != null) {\n",
              "\t\tjindo.$Fn(checkboxHandlerFactory(true, false), this).attach(jindo.$(\"actualYnCheckBox\"), 'click');\n",
              "\t}\n",
              "\n",
              "\tif (jindo.$(\"actualYnLable\") != null) {\n",
              "\t    jindo.$Fn(checkboxHandlerFactory(true, true), this).attach(jindo.$(\"actualYnLable\"), 'click');\n",
              "\t}\n",
              "\n",
              "\t\n",
              "    if (jindo.$(\"spoilerYnCheckBox\") != null) {\n",
              "    jindo.$Fn(checkboxHandlerFactory(false, false), this).attach(jindo.$(\"spoilerYnCheckBox\"), 'click');\n",
              "  }\n",
              "\n",
              "  if (jindo.$(\"spoilerYnLable\") != null) {\n",
              "    jindo.$Fn(checkboxHandlerFactory(false, true), this).attach(jindo.$(\"spoilerYnLable\"), 'click');\n",
              "  }\n",
              "\t\n",
              "\t\n",
              "\tif (jindo.$Element(\"actualPointHelp\") != null && jindo.$Element(\"actualPointHelp\") != \"undefined\") {\n",
              "\t\tactualPointHelpLayerToggle = function() {\n",
              "\t\t\tsetTimeout( function() {\n",
              "\t\t\t\tif (document.activeElement != null) {\n",
              "\t\t\t\t\tvar focusedEl = jindo.$Element(document.activeElement);\n",
              "\t\t\t\t\tif (focusedEl != null) {\n",
              "\t\t\t\t\t\tif ( !focusedEl.hasClass(\"_actualPointHelp\") ) {\n",
              "\t\t\t\t\t\t\t jindo.$Element(\"actualPointHelp\").hide();\n",
              "\t\t\t\t\t\t}\n",
              "\t\t\t\t\t}\n",
              "\t\t\t\t}\n",
              "\t\t\t}, 100);\n",
              "\t\t};\n",
              "\n",
              "\t\tnew jindo.LayerManager(\"actualPointHelp\", {\n",
              "\t\t\tsCheckEvent : \"click\",\n",
              "\t\t\tnHideDelay : 0\n",
              "\t\t}).link(jindo.$(\"actualPointHelp\"), jindo.$(\"actualPointHelpButton\"));\n",
              "\n",
              "\t\tjindo.$Element(\"actualPointHelpButton\").attach(\"click\", function(e){\n",
              "\t\t\te.stop(jindo.$Event.CANCEL_DEFAULT);\n",
              "\t\t\tjindo.$Element(\"actualPointHelp\").toggle();\n",
              "\t\t});\n",
              "\n",
              "\t\tjindo.$Element(\"actualPointHelpCloseButton\").attach(\"click\", function(e){\n",
              "\t\t\te.stop(jindo.$Event.CANCEL_DEFAULT);\n",
              "\t\t\tjindo.$Element(\"actualPointHelp\").toggle();\n",
              "\t\t});\n",
              "\n",
              "\t\t\n",
              "\t\tvar waelActualPointHelp = jindo.$ElementList('._actualPointHelp');\n",
              "\n",
              "\t\tjindo.$A(waelActualPointHelp.$value()).forEach(function(value, index, array) {\n",
              "\t\t\tjindo.$Fn(actualPointHelpLayerToggle, this).attach(value, \"blur\");\n",
              "\t\t});\n",
              "\t}\n",
              "\n",
              "\tparent.setParamForPointAfterList('N', 'sympathyScore', '1');\n",
              "\tparent.resizePointAfterListIframe(0);\n",
              "\n",
              "\t// 최소 높이 270px 지정\n",
              "\tvar frameHeight = eval(jindo.$Document().scrollSize().height);\n",
              "\n",
              "\tparent.resizePointAfterListIframe(frameHeight);\n",
              "\tparent.isPointAfterListLoad = true;\n",
              "\t\n",
              "\t\n",
              "\t\n",
              "\n",
              "  var isCheckPointExist = false;\n",
              "  // TODO: fix below condition\n",
              "  if (false) {\n",
              "    if(jindo.$Element(\"open-form-btn\")) {\n",
              "\t\tjindo.$Element(\"open-form-btn\").attach(\"click\", function(e) {\n",
              "\t\t  \t\n",
              "\t\t  \t\n",
              "\t\t\t\n",
              "\t\t  if (true && false && isCheckPointExist == false) {\n",
              "\t\t\tparent.point.checkPointAfterExistAndMileageSubscriptionType();\n",
              "\t\t  }\n",
              "\t\t  isCheckPointExist = true;\n",
              "\t\t  parent.openPointWriteForm();\n",
              "\t\t});\n",
              "    }\n",
              "  } else {\n",
              "    if (jindo.$Element(\"open-form-btn\")) {\n",
              "\t\tjindo.$Element(\"open-form-btn\").attach(\"click\", function (e) {\n",
              "\t\t  common.checkLogin(false);\n",
              "\t\t});\n",
              "    }\n",
              "  }\n",
              "\n",
              "  var isHide = true;\n",
              "\n",
              "  if(jindo.$Element(\"eval-edit\")) {\n",
              "    jindo.$Element(\"eval-edit\").attach(\"click\", function() {\n",
              "\t\t  var edit = jindo.$Element(\"ly-edit\");\n",
              "\t  \tisHide ? edit.show() : edit.hide();\n",
              "      \tisHide = !isHide;\n",
              "    })\n",
              "  }\n",
              "  parent.resizePointAfterListIframeOnLoad();\n",
              "}, this).attach(this, 'load');\n",
              "\n",
              "var point = {\n",
              "\t\tcheckLoginWithMessage : function(login, loginMessage, notLoginMessage) {\n",
              "\t\t\tif(login == false){\n",
              "\t\t\t\tif(confirm(message)){\n",
              "\t\t\t\t\ttop.location.href=\"https://nid.naver.com/nidlogin.login?mode=form&url=\"+encodeURIComponent(top.location.href);\n",
              "\t\t\t\t}\n",
              "\t\t\t\treturn false;\n",
              "\t\t\t}\n",
              "\t\t\treturn true;\n",
              "\t\t},\n",
              "\n",
              "\t\t\n",
              "\t\tcheckAlreadyPointAfterExist : function (nid) {\n",
              "\t\t\tvar existPointType = \"pointBefore\";\n",
              "\t\t\t\n",
              "\t\t\tif (false == false) {\n",
              "\t\t\t\tvar oAjax = new jindo.$Ajax(\"/api/internal/point/pointAfterExistJson.nhn\", {\n",
              "\t\t\t    \tonload : function (oRes) {\n",
              "\t\t\t    \t\tvar resultCode = oRes.json().resultCode;\n",
              "\t\t\t    \t\t\n",
              "\t\t\t    \t\tif (resultCode == \"error\") {\t\t\t\t\t\t\t// 서버 오류\n",
              "\t\t\t    \t\t\talert(\"오류가 발생했습니다. 잠시 후 다시 시도해주세요.\");\n",
              "\t\t\t    \t\t\treturn false;\n",
              "\t\t\t    \t\t} else {\n",
              "\t\t\t    \t\t\texistPointType = oRes.json().existPointType;\n",
              "\t\t\t    \t\t\tpoint.del(existPointType, nid);\n",
              "\t\t\t    \t\t}\n",
              "\t\t\t    \t},\n",
              "\t\t\t\t\ttimeout : 5,\n",
              "\t\t\t    \tonerror : function (oRes) {\n",
              "\t\t\t    \t\talert(\"오류가 발생했습니다. 잠시 후 다시 시도해주세요.\");\n",
              "\t\t\t    \t\treturn false;\n",
              "\t\t\t    \t},\n",
              "\t\t\t    \tontimeout : function (oRes) {\n",
              "\t\t\t    \t\talert(\"처리가 지연되고 있습니다. 다시 시도해주세요.\");\n",
              "\t\t\t    \t\treturn false;\n",
              "\t\t\t    \t}\n",
              "\t\t\t    });\n",
              "\t\t\t    \n",
              "\t\t\t    oAjax.request({\n",
              "\t\t\t    \t\"movieCode\" : \"167613\",\n",
              "\t\t\t    \t\"isActualPoint\" : \"false\"\n",
              "\t\t\t    });\n",
              "\t\t\t} else {\n",
              "\t\t\t\tpoint.del(existPointType, nid);\n",
              "\t\t\t}\n",
              "\t\t},\n",
              "\n",
              "\t\tdel : function (existPointType, nid) {\n",
              "\t\t\tif (existPointType == \"actualPoint\") {\n",
              "\t\t\t\tif (confirm(\"관람객 평점 삭제시, 평점 작성으로 적립된 포인트는 회수됩니다. 평점을 삭제할까요?\") == false) {\n",
              "\t\t\t\t\treturn false;\n",
              "\t\t\t\t}\n",
              "\t\t\t} else {\n",
              "\t\t\t\tif (confirm(\"본인 삭제 시 복구할 수 없습니다.\\n평점을 삭제하시겠습니까?\") == false) {\n",
              "\t\t\t\t\treturn false;\n",
              "\t\t\t\t}\n",
              "\t\t\t}\n",
              "\t\t\t\n",
              "\t\t\tvar ajaxDeleteUrl = \"/api/internal/point/pointBeforeDelete.nhn\";\n",
              "\t\t\tif (\"after\" == \"after\") {\n",
              "\t\t\t\tajaxDeleteUrl = \"/api/internal/point/pointAfterDelete.nhn\";\n",
              "\t\t\t}\n",
              "\t\t\t\n",
              "\t\t\tvar ajax = new jindo.$Ajax(ajaxDeleteUrl, { \n",
              "\t\t\t\tmethod : \"POST\",\n",
              "\t\t\t\tasync : false,\n",
              "\t\t\t\tonload : this.delCallback\n",
              "\t\t\t});\n",
              "\t\t\tajax.header(\"ajax\", \"true\");\n",
              "\t\t\tajax.request({\n",
              "\t\t\t\t\"nid\":nid\n",
              "\t\t\t});\n",
              "\t\t},\n",
              "\t\t\n",
              "\t\tdelCallback : function(req) {\n",
              "\t\t\tvar returnValue = req.text();\n",
              "\t\t\t\n",
              "\t\t\tif(returnValue != \"success\"){\n",
              "\t\t\t\talert(returnValue);\n",
              "\t\t\t\treturn false;\n",
              "\t\t\t}\n",
              "\t\t\t\n",
              "\t\t\ttop.location.href = '/movie/bi/mi/point.nhn?code=167613#pointAfterTab';\n",
              "\t\t\ttop.location.reload(true);\n",
              "\t\t}\n",
              "};\n",
              "\n",
              "function dislplayOrder(order) {\n",
              "\tvar url = \"/movie/bi/mi/pointWriteFormList.nhn?code=167613&type=after\";\n",
              "\t\n",
              "\tvar onlyActualPointYnValue = jindo.$(\"onlyActualPointYn\").value;\n",
              "  \tvar includeSpoilerYnValue = jindo.$(\"includeSpoilerYn\").value;\n",
              "\n",
              "\tif (onlyActualPointYnValue != \"\") {\n",
              "\t\turl = url + \"&onlyActualPointYn=\" + onlyActualPointYnValue;\n",
              "\t}\n",
              "\n",
              "\tif (includeSpoilerYnValue != \"\") {\n",
              "      url = url + \"&onlySpoilerPointYn=\" + includeSpoilerYnValue;\n",
              "    }\n",
              "\t\n",
              "\turl = url + \"&order=\" + order;\n",
              "\t\n",
              "\tlocation.href = document.location.protocol + \"//\" + document.domain + url;\n",
              "}\n",
              "\n",
              "function showPointListByNid(nid, target){\n",
              "\tif (target == 'after') {\n",
              "\t\ttop.location.href = top.location.protocol + \"//\" + top.location.hostname + \"/movie/point/af/list.nhn?st=nickname&target=after&sword=\"+nid;\n",
              "\t} else {\n",
              "\t\ttop.location.href = top.location.protocol + \"//\" + top.location.hostname + \"/movie/point/af/list.nhn?st=nickname_before&target=before&sword=\"+nid;\n",
              "\t}\n",
              "}\n",
              "\n",
              "function refreshPage() {\n",
              "\t \n",
              "\ttop.location.href = '/movie/bi/mi/point.nhn?code=167613#pointAfterTab';\n",
              "}\n",
              "\n",
              "// 스포일러 감상평 내용 보기\n",
              "function showMovieReview(rvwIdx) {\n",
              "    jindo.$Element('_text_spo_' + rvwIdx).css('display', 'none');\n",
              "    jindo.$Element('_filtered_ment_' + rvwIdx).css('display', 'block');\n",
              "    parent.resizePointAfterListIframeOnLoad();\n",
              "}\n",
              "\n",
              "// 감상평 펼쳐보기\n",
              "function unfoldPointMent(obj) {\n",
              "    var fullMent = jindo.$Element(obj).attr(\"data-src\");\n",
              "    jindo.$Element(obj).parent().html(fullMent);\n",
              "    parent.resizePointAfterListIframeOnLoad();\n",
              "}\n",
              "\n",
              "\n",
              "</script>\n",
              "<script type=\"text/javascript\">\n",
              "\tvar sympathy = new Sympathy(\"167613\", \"after\");\n",
              "</script>\n",
              "<script type=\"text/javascript\">\n",
              "            jindo.$Fn(function() {\n",
              "                try{ lcs_do(); } catch(e){}\n",
              "            }).attach(window, \"pageshow\");\n",
              "\t\t</script>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJKe-O9sLc4z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 811
        },
        "outputId": "f9099da7-5ca7-4e48-a17f-363f824dcad5"
      },
      "source": [
        "score_result = html.find('div', {'class': 'score_result'})\n",
        "lis = score_result.findAll('li')\n",
        "lis[0]"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<li>\n",
              "<div class=\"star_score\">\n",
              "<span class=\"st_off\"><span class=\"st_on\" style=\"width:100.0%\"></span></span><em>10</em>\n",
              "</div>\n",
              "<div class=\"score_reple\">\n",
              "<p>\n",
              "<!-- 스포일러 컨텐츠로 처리되는지 여부 -->\n",
              "<span id=\"_filtered_ment_0\">\n",
              "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
              "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
              "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
              "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t착하게 사는것은 높은 계단을 오르는것과 같지만 포기하고 내려갈때는 너무나도 빠르고 즐겁다. \n",
              "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
              "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
              "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
              "\t\t\t\t\t\t\t\t\t\t\t\t\t</span>\n",
              "</p>\n",
              "<dl>\n",
              "<dt>\n",
              "<em>\n",
              "<a href=\"#\" onclick=\"javascript:showPointListByNid(16219865, 'after');parent.clickcr(this, 'ara.uid', '', '', event); return false;\" target=\"_top\">\n",
              "<span>버블껌(roac****)</span>\n",
              "</a>\n",
              "</em>\n",
              "<em>2019.10.02 12:54</em>\n",
              "</dt>\n",
              "<dd>\n",
              "<a class=\"go_report2\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.report', '', '', event); common.report('false','roac****', 'iiCVFSlTLdR62UUS6c/98OoxQSoOdzFoljx3vFpinBk=', '착하게 사는것은 높은 계단을 오르는것과 같지만 포기하고 내려갈때는 너무나도 빠르고 즐겁다. ', '16219865', 'point_after', false);return false;\"><em>신고</em></a>\n",
              "</dd>\n",
              "</dl>\n",
              "</div>\n",
              "<div class=\"btn_area\">\n",
              "<a class=\"_sympathyButton\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.sym', '', '', event);\">\n",
              "<span class=\"ico_up\"></span>\n",
              "<span class=\"blind\">공감</span>\n",
              "<strong class=\"sympathy_16219865\">24194</strong>\n",
              "</a>\n",
              "<a class=\"_notSympathyButton\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.opp', '', '', event);\">\n",
              "<span class=\"ico_down\"></span>\n",
              "<span class=\"blind\">비공감</span>\n",
              "<strong class=\"notSympathy_16219865\">1023</strong>\n",
              "</a>\n",
              "</div>\n",
              "</li>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haP4Yp71MEgd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f09b3945-4393-4b52-fefa-58de93f62c25"
      },
      "source": [
        "review_text = lis[0].find('p').getText()\n",
        "review_text.strip()"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'착하게 사는것은 높은 계단을 오르는것과 같지만 포기하고 내려갈때는 너무나도 빠르고 즐겁다.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKRhqlhHM47t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "df5a3f81-9ec0-44f8-c84b-06bf834016e4"
      },
      "source": [
        "score = lis[0].find('em').getText()\n",
        "score"
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'10'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hN7ECBgaOPx1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "outputId": "909a23c1-d69f-4b13-8dc9-c049544fe63a"
      },
      "source": [
        "for lis_ in lis:\n",
        "    comment = lis_.find('p').getText().strip()\n",
        "    score = lis_.find('em').getText()\n",
        "    print(comment,score)\n"
      ],
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "착하게 사는것은 높은 계단을 오르는것과 같지만 포기하고 내려갈때는 너무나도 빠르고 즐겁다. 10\n",
            "하여간 역대 조커들은 너무 완벽해. 시저 로메로, 잭니콜슨, 로저 스톤버너, 히스레저, 박명수, 호아킨 피닉스.. 10\n",
            "명작들만 골라서 번역하는 박지훈이야말로 이시대의 조커 아닐까? 10\n",
            "마블은 10년간 공들여 만든 \"타노스\"로 관객을 열광시키고 DC는 10년간 똥을 싸도 \"조커\" 하나로 다시 부활한다. 10\n",
            "조커 분장 후 계단씬 지린다.. 10\n",
            "작은 친구의 이마에 입맞춤하던, 그리고 닿을 수 없는 잠금을 풀며 사과하던, 그가 아서였던 마지막 순간. 10\n",
            "나락에 떨어진 불행한 인간의 손을 아무도 잡아주지 않을 때 그 손을 잡아준건 광기였다 10\n",
            "봉오동전투에6점을주고 조커에5점을주는 김현수평론가는 누구인가... 8\n",
            "연기 스토리도 오지는데 장면마다 깔리는 음악들이 압권임 진짜 10\n",
            "이게 19세가 아니라니 영등위 제정신인가? 마지막에 나도 모르게 조커를 따라 웃고있더라. 정신적으로 엄청 위험한 영화임.그리고 번역오류는 없다 하는데 정작 중요한 편지읽는장면에서 핵심단어를 맘대로 빼놓고 지 맘대로 ... 9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUz_UszhPv0q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 47
        },
        "outputId": "bff342b0-a7df-446a-d8dd-cc58d4eaeb7a"
      },
      "source": [
        "import time\n",
        "import pandas as pd\n",
        "score_df = pd.DataFrame(columns=['comment','score'])\n",
        "score_df"
      ],
      "execution_count": 286,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [comment, score]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 286
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mA6qHD_O6W9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c5408c43-d679-4535-e61b-3eecb19d468d"
      },
      "source": [
        "page_num = 1\n",
        "index = 0\n",
        "while True:\n",
        "    url = \"https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=167613&type=after&page=\"+f'{page_num}'\n",
        "    resp = requests.get(url)\n",
        "    html = BeautifulSoup(resp.content, 'html.parser')\n",
        "    score_result = html.find('div', {'class': 'score_result'})\n",
        "    lis = score_result.findAll('li')\n",
        "    for lis_ in lis:\n",
        "        comment = lis_.find('p').getText().strip().replace(\"\\n\",\"\").replace('\\t','').replace('\\r','')\n",
        "        comment = comment.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
        "        comment = comment.replace(\"관람객\",\"\")\n",
        "        comment = comment.replace(\"스포일러가 포함된 감상평입니다.\",\"\")\n",
        "        comment = comment.replace(\"감상평 보기\",\"\")\n",
        "        score = lis_.find('em').getText()\n",
        "        if ('관람객' in comment) or ('관람객' in score):continue\n",
        "        score_df.loc[index] = [comment,score]\n",
        "        if index%300==0:\n",
        "            print(f'{index}의 리뷰를 탐색함')\n",
        "            print(comment,score)\n",
        "            print('-------------------'*3)\n",
        "        index+=1\n",
        "        \n",
        "    page_num+=1\n",
        "    if index>30000:break"
      ],
      "execution_count": 287,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0의 리뷰를 탐색함\n",
            "착하게 사는것은 높은 계단을 오르는것과 같지만 포기하고 내려갈때는 너무나도 빠르고 즐겁다. 10\n",
            "---------------------------------------------------------\n",
            "300의 리뷰를 탐색함\n",
            "오늘부터 조커는 호아킨피닉스다 10\n",
            "---------------------------------------------------------\n",
            "600의 리뷰를 탐색함\n",
            "이게 왜 평점이 이렇게 높은지 이해 불가....영화 끝남과 동시에 웅성웅성 나와 같은 사람이 많았음.... 영화보다가 나간 커플도 있음....이해 할 내용이 아예 없음. 결론은 그냥 정신이상자 조커. 돈보다 내 시간... 1\n",
            "---------------------------------------------------------\n",
            "900의 리뷰를 탐색함\n",
            "주인공은웃지만 관객들은 웃을수없었던 영화 10\n",
            "---------------------------------------------------------\n",
            "1200의 리뷰를 탐색함\n",
            "난 왜 이 명작을 영화관에서 보지 않았나2019 제일 후회되는 일이다 10\n",
            "---------------------------------------------------------\n",
            "1500의 리뷰를 탐색함\n",
            "심해로 들어가는 DC를 머리채 잡고 끌어 올렸다 10\n",
            "---------------------------------------------------------\n",
            "1800의 리뷰를 탐색함\n",
            "그니까 새기덜아 애들 괴롭히지 말고 사이좋게 잘지내란 말야 새기덜아 10\n",
            "---------------------------------------------------------\n",
            "2100의 리뷰를 탐색함\n",
            "호아킨 피닉스의 연기가 모든 걸 완성시킨 느낌. 막판 몰입감에, 오랜만에 흠뻑 젖었다. 10\n",
            "---------------------------------------------------------\n",
            "2400의 리뷰를 탐색함\n",
            "사실 영화내에서 가장 악한 인물이 조커인데 관객들은 조커에 공감하게 된다. 이 영화가 무서운 이유다. 9\n",
            "---------------------------------------------------------\n",
            "2700의 리뷰를 탐색함\n",
            "명작중에 명작임 꼭봐야댐 10\n",
            "---------------------------------------------------------\n",
            "3000의 리뷰를 탐색함\n",
            "재미있게 잘 봤습니다. 10\n",
            "---------------------------------------------------------\n",
            "3300의 리뷰를 탐색함\n",
            "모든게 완벽함. 이영화 보기전 신세계,아바타 등이 내생 최고의 영화였는데 조커로 바뀌었음. 10\n",
            "---------------------------------------------------------\n",
            "3600의 리뷰를 탐색함\n",
            "호아킨 연기 미쳤다... 연기 진짜 도랏다... 그냥 상식밖의 연기력임.. 아몰라 호아킨대박... 이제 조커는 호아킨.. 10\n",
            "---------------------------------------------------------\n",
            "3900의 리뷰를 탐색함\n",
            "주인공이 정말로 연기를 잘한다고 느낌 진짜 광기에 서려있는 예측하지 못할 법한 행동들을 하는... 진짜 노래에 맞춰 추는 춤 하나하나가 이 배우가 느끼는 세세한 감정이 느껴졌음 영상미도 엄청나지만 이 배우의 연기 하... 10\n",
            "---------------------------------------------------------\n",
            "4200의 리뷰를 탐색함\n",
            "연기 영상미 합이 너무 오졌어요.. 여운이 가시질않네요.. 10\n",
            "---------------------------------------------------------\n",
            "4500의 리뷰를 탐색함\n",
            "다른건 잘 모르겠는데 조커 연기 하나는 기가막힌다 10\n",
            "---------------------------------------------------------\n",
            "4800의 리뷰를 탐색함\n",
            "아.. 진짜 최고다.. 10\n",
            "---------------------------------------------------------\n",
            "5100의 리뷰를 탐색함\n",
            "살면서 영화 평점을 달러 로그인한 일이 한번도 없었는데, 오늘 보고오고 처음으로 달았음.. 리뷰어들이 사회에 해롭다는 평가가 가장 궁금해서 직접 보고오니 필터링이나 정신적으로 몰려있는 사람들에게는 이 조커라는 영화가... 10\n",
            "---------------------------------------------------------\n",
            "5400의 리뷰를 탐색함\n",
            "이런 작품은 어디서  또 만들수 있을까? 7\n",
            "---------------------------------------------------------\n",
            "5700의 리뷰를 탐색함\n",
            "호아킨 연기 미쳤음....백퍼 아카데미주연상!!! 10\n",
            "---------------------------------------------------------\n",
            "6000의 리뷰를 탐색함\n",
            "2019 역대급 영화.... 10\n",
            "---------------------------------------------------------\n",
            "6300의 리뷰를 탐색함\n",
            "그래 가끔 나도 이유 없이 웃음이 나와. 총소리가 매우 시원시원하고 흥칫뿡이다. 10\n",
            "---------------------------------------------------------\n",
            "6600의 리뷰를 탐색함\n",
            "호아킨 연기로 인생영화 등극했음 10\n",
            "---------------------------------------------------------\n",
            "6900의 리뷰를 탐색함\n",
            "진짜 조커가 나타났다. 보는내내 이생각이 들었다. 진짜 조커다!!! 10\n",
            "---------------------------------------------------------\n",
            "7200의 리뷰를 탐색함\n",
            "사람과 사회가 만들어낸 악마..누가 악마일까 9\n",
            "---------------------------------------------------------\n",
            "7500의 리뷰를 탐색함\n",
            "전과는 다르게, 춤을 추며 본 모습을 찾은 것 같은 조커의 계단 내려오는 장면은 잊을 수가 없다. 분장 후에 담배를 물고 폭동이 일어나던 거리를 그저 걷기만 해도 감탄이 나오는 조커, 미워할 수 없는 악당. That... 10\n",
            "---------------------------------------------------------\n",
            "7800의 리뷰를 탐색함\n",
            "내 인생 최고의 영화였다. 연출과 연기, 특히 음악까지 모든 조화가 완벽했다. 10\n",
            "---------------------------------------------------------\n",
            "8100의 리뷰를 탐색함\n",
            "첨부터 연기에 압도당해서 조커시점으로 보다보나 나중에는 나도 조커가 이해되고 조커가 될 것 같았음 비극적인상황에서의 기괴한 웃음이랑 춤은 너무 모순적이어서 더 비극적이게 보임 암튼 혼자보지 마세요 정신이상해짐 10\n",
            "---------------------------------------------------------\n",
            "8400의 리뷰를 탐색함\n",
            "영화는 쩔지만 청소년 관람불가가 아니라는게 말이 안 된다.에일리언 커버넌트때도 느꼈는데 영통위가 폭력묘사에 너무 너그러운 듯 하다. 모방위험도는 폭력묘사가 성적묘사보다 높다고 들었는데, 어째 등급을 반대로 주는 경향... 5\n",
            "---------------------------------------------------------\n",
            "8700의 리뷰를 탐색함\n",
            "평생 히스테저를 뛰어넘을 조커는 없을 줄 알았는데... 10\n",
            "---------------------------------------------------------\n",
            "9000의 리뷰를 탐색함\n",
            "처음부터 끝까지 우울의 구렁텅이로 사람을 밀러 넣네 10\n",
            "---------------------------------------------------------\n",
            "9300의 리뷰를 탐색함\n",
            "피닉스의 물오른 연기에 감탄하면서 봤지만.. 영화가 끝나고 난뒤 기분이 좋지는 않은영화... 10\n",
            "---------------------------------------------------------\n",
            "9600의 리뷰를 탐색함\n",
            "19세로 해야할것같습니다 잔인성을 떠나서 가치관에 영향을 줄수도 있다는 꼰대같은생각이 들긴 하지만 이러나 저러나 완벽한 영화였슴 +다음날 방해받지않고 또보려고 스위트로가서 술빨며봄 10\n",
            "---------------------------------------------------------\n",
            "9900의 리뷰를 탐색함\n",
            "연기가좋아 10\n",
            "---------------------------------------------------------\n",
            "10200의 리뷰를 탐색함\n",
            "조금 루즈하고 심오하지만 연기가 너무멋있어요 10\n",
            "---------------------------------------------------------\n",
            "10500의 리뷰를 탐색함\n",
            "올해 최고의 영화 스토리와 연기는 말해 입아프고 적절하게 깔리는 브금이 인상적 10\n",
            "---------------------------------------------------------\n",
            "10800의 리뷰를 탐색함\n",
            "목소리 잃은 자들의 외침이 잘못된 방식으로 드러났다고는 생각하나, 씁쓸하게도 공감되고 납득이되는 방식이었다 10\n",
            "---------------------------------------------------------\n",
            "11100의 리뷰를 탐색함\n",
            "히스레저 조커가 최대한 현실적으로 보이려고 연출했다면 호아킨의 조커는 현실 그 차체. 분노에 찬 사람이 광대분장을 했을 뿐. 어떤 만화적인 요소가 없었다. 한가지 항의하자면 이건 19금으로 해야한다. 10\n",
            "---------------------------------------------------------\n",
            "11400의 리뷰를 탐색함\n",
            "자막빼고 모두 완벽했다 10\n",
            "---------------------------------------------------------\n",
            "11700의 리뷰를 탐색함\n",
            "깊은 감동을 받았네요. 10\n",
            "---------------------------------------------------------\n",
            "12000의 리뷰를 탐색함\n",
            "너무 설득력있어서 무서운 영화. 10\n",
            "---------------------------------------------------------\n",
            "12300의 리뷰를 탐색함\n",
            "안경 들고 와서 쓰고 봐야했어 또 봐야지 10\n",
            "---------------------------------------------------------\n",
            "12600의 리뷰를 탐색함\n",
            "60년생 해피.... 10\n",
            "---------------------------------------------------------\n",
            "12900의 리뷰를 탐색함\n",
            "Perfect movie 10\n",
            "---------------------------------------------------------\n",
            "13200의 리뷰를 탐색함\n",
            "영상각도 진짜 미쳤...배경음악도 진짜 ..ㅋ보고 나오자마자 머리가 띵... 여운이 정말 길게 남는영화 DC특유의 어두운분위기도 오랜만에 제대로나옴 10\n",
            "---------------------------------------------------------\n",
            "13500의 리뷰를 탐색함\n",
            "무엇을 상상하든 그 이상의 것을 보게될것이다. 10\n",
            "---------------------------------------------------------\n",
            "13800의 리뷰를 탐색함\n",
            "올해의 영화급이다ㅋㅋㅋㅋ문좀열어줄래?이거랑 닥터와의 키스 엄마죽인거 기억에남는다ㅋ 10\n",
            "---------------------------------------------------------\n",
            "14100의 리뷰를 탐색함\n",
            "조커연기쩐다우울함의 극치금연할것 8\n",
            "---------------------------------------------------------\n",
            "14400의 리뷰를 탐색함\n",
            "누구나 조커가 될 수 있는 세상 10\n",
            "---------------------------------------------------------\n",
            "14700의 리뷰를 탐색함\n",
            "호아킨 피닉스, 음악... 10\n",
            "---------------------------------------------------------\n",
            "15000의 리뷰를 탐색함\n",
            "우리가 만든 빌런. 우리 속의 빌런.다크함에 압도당했다. 9\n",
            "---------------------------------------------------------\n",
            "15300의 리뷰를 탐색함\n",
            "진짜 이시대의 최고의 악당솔직히 타노스 그 이상이다 10\n",
            "---------------------------------------------------------\n",
            "15600의 리뷰를 탐색함\n",
            "착한 사람 이미지에서 광기까지 변한 삶을 잘 표현한 조커네요... 8\n",
            "---------------------------------------------------------\n",
            "15900의 리뷰를 탐색함\n",
            "만약 이세계관이어서 배트맨 리부트하고 그다음편에 배트맨과 노련해진 조커가 맞붙는 스토리로 만들면 세편모두 길이 남을 역작이 될거라고 확신한다 10\n",
            "---------------------------------------------------------\n",
            "16200의 리뷰를 탐색함\n",
            "연기 한번더보고싶은영화 10\n",
            "---------------------------------------------------------\n",
            "16500의 리뷰를 탐색함\n",
            "DC가 정말로 살아날 수 있을거라고 감히 기대하지는 못했다. 그런데, 오늘밤 이후로는.. 그 희망을 절대로 버리지 못할것이다. 8\n",
            "---------------------------------------------------------\n",
            "16800의 리뷰를 탐색함\n",
            "철학이 아쉽다 그래도 근래 중 최고다 8\n",
            "---------------------------------------------------------\n",
            "17100의 리뷰를 탐색함\n",
            "최고임 몸짓 하나라도 현대무용 보는것 같음 10\n",
            "---------------------------------------------------------\n",
            "17400의 리뷰를 탐색함\n",
            "기대이상이다. 정말 역대급이다. 배트맨 다크나이트의 고딕한 분위기 마저도 비슷하다. 10\n",
            "---------------------------------------------------------\n",
            "17700의 리뷰를 탐색함\n",
            "미친 연기력으로 웃음속에 모든것을 담아냄 10\n",
            "---------------------------------------------------------\n",
            "18000의 리뷰를 탐색함\n",
            "제발제발제발 로버트 패틴슨이랑 호아킨 피닉스랑 조커 대 배트맨으로 만나게해주세요ㅠ..이대로 배트맨으로 이어지면 닼나 넘을것같은데 8\n",
            "---------------------------------------------------------\n",
            "18300의 리뷰를 탐색함\n",
            "진짜 이 연기를 보고 아무렇지 않을 수가 없다아무렇지 않은 게 이상할 거 같다미쳤다 10\n",
            "---------------------------------------------------------\n",
            "18600의 리뷰를 탐색함\n",
            "아하하하핳아호아킨 피닉스 연기에  넋을 잃고 보다가   로버트드니로 나온줄도 몰랐다  근데 화장실 춤추는 씬, 택견 슬로무모션 보는듯한 느낌. 마지막은 갑자기 아이덴티티가 생각남ㅜㅜ 10\n",
            "---------------------------------------------------------\n",
            "18900의 리뷰를 탐색함\n",
            "많은 사람들은 히스 레져 조커를 좋아한다. 하지만 개인적으로는 그의 조커를 선호하지 않는다. 배트맨 팬으로서 다크나이트가 모두 조커때문에 빛난거라 들어서일까. 물론 그가 보여준 연기에 대해서는 할말이 없다. 히스레저... 10\n",
            "---------------------------------------------------------\n",
            "19200의 리뷰를 탐색함\n",
            "하나부터 100가지가 있다면 조커는 100을 초월한 200의 만족을 주었다 무엇보다 최근에 봤던 82년생과는 너무다도 다른 연기와 연출이 비교 하여 조커라는 영화의 격이 작은 언덕과 백두산의 차이처럼 느껴졌다 조커가... 10\n",
            "---------------------------------------------------------\n",
            "19500의 리뷰를 탐색함\n",
            "이 이상의 조커가 또 나올 수 있을까 10\n",
            "---------------------------------------------------------\n",
            "19800의 리뷰를 탐색함\n",
            " 10\n",
            "---------------------------------------------------------\n",
            "20100의 리뷰를 탐색함\n",
            "생각보단 많이 잔인합니다.17 18금이 있다면 그정도입니다. 그래도 배우가 연기는 잘했고 의미하는바를 잘 전달했다고 느끼고 있습니다. 9\n",
            "---------------------------------------------------------\n",
            "20400의 리뷰를 탐색함\n",
            "이것도 히어로 영화가 맞다. 아이언맨, 캡틴아메리카 전부 잔인한 현실적 묘사가 없었을뿐 살인을 했다. 조커는 단지 죽음의 모습을 보여준것 뿐이다. 악당이 아닌 히어로 조커의 영화 10\n",
            "---------------------------------------------------------\n",
            "20700의 리뷰를 탐색함\n",
            "내 죽음이 패니에 삶보다 가치있기를 10\n",
            "---------------------------------------------------------\n",
            "21000의 리뷰를 탐색함\n",
            "연기 디테일이 장난아니고, 웃음소리에 슬픔도 단순 오락도 그리고.. 무서움과 경고도 느껴진 것 같다. 10\n",
            "---------------------------------------------------------\n",
            "21300의 리뷰를 탐색함\n",
            "이 영화는 불이다. 9\n",
            "---------------------------------------------------------\n",
            "21600의 리뷰를 탐색함\n",
            "정신병이 있는 사람들에게 가장 힘든것은 정상인처럼 행동해야 한다는 것이다.현실이라고 다를까? 10\n",
            "---------------------------------------------------------\n",
            "21900의 리뷰를 탐색함\n",
            "러닝타임내내 감탄하면서 본 영화. OOO기에 미친다 10\n",
            "---------------------------------------------------------\n",
            "22200의 리뷰를 탐색함\n",
            "재밌게 봤습니다. 다만 놓친 부분이 많아서 다시 보고 싶습니다. 왜 조커가 탄생할 수밖에 없었는지 나타내는 스토리지만, 또 그게 굳이 조커일 필요는 없었다고 생각합니다. 8\n",
            "---------------------------------------------------------\n",
            "22500의 리뷰를 탐색함\n",
            "억눌렸던 광기의 폭발.  새롭게 탄생할 배트맨은 어떻게 그려질지 벌써부터 기대됩니다. 9\n",
            "---------------------------------------------------------\n",
            "22800의 리뷰를 탐색함\n",
            "너무너무너무 재밋엇어요 10\n",
            "---------------------------------------------------------\n",
            "23100의 리뷰를 탐색함\n",
            "보는내내 안타깝고 슬펐던 영화.. 10\n",
            "---------------------------------------------------------\n",
            "23400의 리뷰를 탐색함\n",
            "소름이 돋았다 보는 내내. 10\n",
            "---------------------------------------------------------\n",
            "23700의 리뷰를 탐색함\n",
            "미친놈을 이해하게 만드는 연기앞으로 조커역을 하게 될 배우들에게 미리 애도를 10\n",
            "---------------------------------------------------------\n",
            "24000의 리뷰를 탐색함\n",
            "호아킨 피닉스의 연기가 아주 좋습니다 10\n",
            "---------------------------------------------------------\n",
            "24300의 리뷰를 탐색함\n",
            "명작, 걸작, 마스터피스 10\n",
            "---------------------------------------------------------\n",
            "24600의 리뷰를 탐색함\n",
            "조커라는 캐릭터의 개인사를 어둡고 긴장감 있게 풀어낸 것은 좋았지만, 감상하기에 불편한 감이 없지 않아 있었습니다. 빌런 캐릭터를 이렇게 심도있게 잘 풀어낸 것은 좋은 시도라고 생각됩니다. 8\n",
            "---------------------------------------------------------\n",
            "24900의 리뷰를 탐색함\n",
            "미쳤다 히어로 영화캐릭터 역사상 빌런이 히어로를 뛰어넘는 유일한 영화! 조커 3부작 나와야 된다 9\n",
            "---------------------------------------------------------\n",
            "25200의 리뷰를 탐색함\n",
            "내 기준 최고의 연기를 보여줬던 배우는 히스레저였는데, 조금씩 호아킨에게 흔들린다.. 10\n",
            "---------------------------------------------------------\n",
            "25500의 리뷰를 탐색함\n",
            "최고입니다!개인적으로는 히스레저 조커가 더 강렬! 10\n",
            "---------------------------------------------------------\n",
            "25800의 리뷰를 탐색함\n",
            "당연한 얘기지만 피해망상 정신병자 영화 82키로 김지영 따위와는 비교도 할수없는 걸작임 ^^ 10\n",
            "---------------------------------------------------------\n",
            "26100의 리뷰를 탐색함\n",
            "미친게아니라 미치게만들었다 계단에서의 춤은 진짜 명장면 음악과함께 파고들었다 8\n",
            "---------------------------------------------------------\n",
            "26400의 리뷰를 탐색함\n",
            "재미없는데 왜이렇게 인기가 많은지 모르겠다... 그리고 왜 19세가 아니지.. 많이 선정적임 6\n",
            "---------------------------------------------------------\n",
            "26700의 리뷰를 탐색함\n",
            "다크나이트 조커  둘다 안본 사람이라면 조커 보고 다크나이트 보면 더 재밉게 즐길수 있다. 8\n",
            "---------------------------------------------------------\n",
            "27000의 리뷰를 탐색함\n",
            "마음에 안들었음. 1\n",
            "---------------------------------------------------------\n",
            "27300의 리뷰를 탐색함\n",
            "조커의 내면의 고통 외로움 소외감을 조명하고 싶었다면 그 대표 첫 사건이 어쩌다 마주친 일회성 시비 청소년이어선 안되지. 현실엔 그것보다 훨씬 잔인하고 처절한 정신적, 신체적 폭력이 존재하는데 조커에서 보여주는 사건... 2\n",
            "---------------------------------------------------------\n",
            "27600의 리뷰를 탐색함\n",
            "보다가 6번졸앗음ㅡㅡ잠을많이자고 갓는데 2\n",
            "---------------------------------------------------------\n",
            "27900의 리뷰를 탐색함\n",
            "난 다크나이트의 계산적인 조커가 훨씬 더 좋았어. 만약 이 친구 이름이 조커가 아니었다면 나름 재밌게 즐길 수 있었겠지만 조커라는 이름을 썼다면 좀더 예측이 안됐어야 하지 않을까? 끝까지 감정적인 한 명의 인간으로 ... 1\n",
            "---------------------------------------------------------\n",
            "28200의 리뷰를 탐색함\n",
            "연기들이 좋았으나 너무 정신이 나갈것같이 몽롱해지는 영화같아서 정신적으로 영향이 끼쳐서 두번은 안보고싶음 4\n",
            "---------------------------------------------------------\n",
            "28500의 리뷰를 탐색함\n",
            "이 영화는 왜 만든거지..보고나서 찝찝하네 하 2\n",
            "---------------------------------------------------------\n",
            "28800의 리뷰를 탐색함\n",
            "연기 액션 영상미. 너무 잘만든 영화다. 하지만 사회가 만든 악당이라는 생각은 안든다. 사람의 악당으로써의 각성이 아니라 싸페가 싸페했다. 조커를 좋아하던 사람으로써 조커를 더이상 좋아하지 못하게 만들어버렸다. 악당... 2\n",
            "---------------------------------------------------------\n",
            "29100의 리뷰를 탐색함\n",
            "졸려죽는줄 알았어요 평점 1점도 아깝네요;; 1\n",
            "---------------------------------------------------------\n",
            "29400의 리뷰를 탐색함\n",
            "별루.. 재미없고 긴장감도 없고 웃음소리만 듣고 끝.. 이해도 안됨 2\n",
            "---------------------------------------------------------\n",
            "29700의 리뷰를 탐색함\n",
            "악당이 다른 히어로물들에 비해 약함 초능력이라도 있었음 좋겠음 담배피는 장면 과다 노출과 살인하는 잔혹성을 감안하면 15금이 아닌 19금으로 상향조정될 필요가 있음 약간 지루한 감도 있구요 액션신이 적어서 그런 거 ... 6\n",
            "---------------------------------------------------------\n",
            "30000의 리뷰를 탐색함\n",
            " 조커는 사람죽이고 그런맛에 보는건데 이상한춤을추고 웃는 소리만 듣다지겨워서 처음으로 중간에 보다가 나온 영화임  막말로 딱 토렌트에 어울리는 영화임 액션씬을 기대하고 가시는분들은 보지마십쇼 돈아깝습니다 1\n",
            "---------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEvE_PY0rh8D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "b2e1d471-61b8-4dba-baa9-49e0f3c3f112"
      },
      "source": [
        "score_df.head()"
      ],
      "execution_count": 288,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>착하게 사는것은 높은 계단을 오르는것과 같지만 포기하고 내려갈때는 너무나도 빠르고 ...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>하여간 역대 조커들은 너무 완벽해. 시저 로메로, 잭니콜슨, 로저 스톤버너, 히스레...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>명작들만 골라서 번역하는 박지훈이야말로 이시대의 조커 아닐까?</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>마블은 10년간 공들여 만든 \"타노스\"로 관객을 열광시키고 DC는 10년간 똥을 싸...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>조커 분장 후 계단씬 지린다..</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             comment score\n",
              "0  착하게 사는것은 높은 계단을 오르는것과 같지만 포기하고 내려갈때는 너무나도 빠르고 ...    10\n",
              "1  하여간 역대 조커들은 너무 완벽해. 시저 로메로, 잭니콜슨, 로저 스톤버너, 히스레...    10\n",
              "2                 명작들만 골라서 번역하는 박지훈이야말로 이시대의 조커 아닐까?    10\n",
              "3  마블은 10년간 공들여 만든 \"타노스\"로 관객을 열광시키고 DC는 10년간 똥을 싸...    10\n",
              "4                                  조커 분장 후 계단씬 지린다..    10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 288
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlZ10SAl-FWD",
        "colab_type": "text"
      },
      "source": [
        "# 조커 리뷰 전처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klTQQDnId310",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from konlpy.tag import Mecab\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "stopwords=['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']\n",
        "tokenizer = Mecab()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVo4ThYpd6dr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8f6e9638-c90c-45b9-9b7c-fbc3d3ffccee"
      },
      "source": [
        "print('전체 샘플의 수 : {}'.format(len(score_df)))"
      ],
      "execution_count": 290,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "전체 샘플의 수 : 30002\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tL_rV55pewtF",
        "colab_type": "text"
      },
      "source": [
        "[한글 불용어](https://www.ranks.nl/stopwords/korean)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fkb1U3CMf7PT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "579740e0-6b6c-468e-ebc5-b50a23d85500"
      },
      "source": [
        "temp = tokenizer.morphs(score_df.loc[2,'comment'])\n",
        "print(temp)\n",
        "temp = [word for word in temp if not word in stopwords]\n",
        "print(temp)"
      ],
      "execution_count": 292,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['명작', '들', '만', '골라서', '번역', '하', '는', '박지훈', '이야말로', '이', '시대', '의', '조커', '아닐까']\n",
            "['명작', '만', '골라서', '번역', '하', '박지훈', '이야말로', '시대', '조커', '아닐까']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXPbuGWWgQFR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenized=[]\n",
        "for sentence in score_df['comment']:\n",
        "    temp = []\n",
        "    temp = tokenizer.morphs(sentence) # 토큰화\n",
        "    temp = [word for word in temp if not word in stopwords] # 불용어 제거\n",
        "    tokenized.append(temp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxtvZfksgWAh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "42c9aa1f-d4cc-4d9b-a3e9-f8100ae77dc8"
      },
      "source": [
        "print(tokenized[:10])"
      ],
      "execution_count": 294,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['착하', '게', '사', '것', '높', '계단', '을', '오르', '것', '같', '지만', '포기', '하', '고', '내려갈', '때', '너무나', '빠르', '고', '즐겁', '다'], ['하여간', '역대', '조커', '너무', '완벽', '해', '시저', '로메로', '잭니콜슨', '로저', '스톤', '버너', '히스레저', '박명수', '호아킨', '피닉스'], ['명작', '만', '골라서', '번역', '하', '박지훈', '이야말로', '시대', '조커', '아닐까'], ['마블', '년', '간', '공들여', '만든', '타노스', '로', '관객', '을', '열광', '시키', '고', '년', '간', '똥', '을', '싸', '조커', '하나', '로', '다시', '부활', '한다'], ['조커', '분장', '후', '계단', '씬', '지', '린다'], ['작', '친구', '이마', '입맞춤', '하', '던', '그리고', '닿', '을', '수', '없', '잠금', '을', '풀', '며', '사과', '하', '던', '그', '아서', '였', '던', '마지막', '순간'], ['나락', '떨어진', '불행', '인간', '손', '을', '아무', '잡', '아', '주', '지', '않', '을', '때', '그', '손', '을', '잡', '아', '준', '건', '광기', '였', '다'], ['봉오동', '전투', '점', '을', '주', '고', '조커', '점', '을', '주', '김현수', '평론가', '누구', '인가'], ['연기', '스토리', '오지', '는데', '장면', '마다', '깔리', '음악', '압권', '임', '진짜'], ['이게', '세', '아니', '라니', '영등', '위', '제정신', '인가', '마지막', '나', '모르', '게', '조커', '따라', '웃', '고', '있', '더라', '정신', '적', '엄청', '위험', '영화', '임', '그리고', '번역', '오류', '없', '다', '하', '는데', '정작', '중요', '편지', '읽', '장면', '에서', '핵심', '단어', '맘대로', '빼놓', '고', '지', '맘', '대로']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aq4o2Jt6gbMi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8f3ac355-dc39-4e46-9c24-b654d7022af3"
      },
      "source": [
        "vocab = FreqDist(np.hstack(tokenized))\n",
        "print('단어 집합의 크기 : {}'.format(len(vocab)))"
      ],
      "execution_count": 295,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "단어 집합의 크기 : 16309\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVkujo6bgcjk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "573105bb-31dd-4ae8-a5d4-5a2f746221c9"
      },
      "source": [
        "vocab['재밌']"
      ],
      "execution_count": 296,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1016"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 296
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxOTEp4RgcrY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3652bccc-aa48-4b1e-ae95-217d14df5263"
      },
      "source": [
        "vocab_size = 500\n",
        "# 상위 vocab_size개의 단어만 보존\n",
        "vocab = vocab.most_common(vocab_size)\n",
        "print('단어 집합의 크기 : {}'.format(len(vocab)))"
      ],
      "execution_count": 297,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "단어 집합의 크기 : 500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UJkRl8dgq_N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_to_index = {word[0] : index + 2 for index, word in enumerate(vocab)}\n",
        "word_to_index['pad'] = 1\n",
        "word_to_index['unk'] = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0W6v-Vl-gtZD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoded = []\n",
        "for line in tokenized: #입력 데이터에서 1줄씩 문장을 읽음\n",
        "    temp = []\n",
        "    for w in line: #각 줄에서 1개씩 글자를 읽음\n",
        "      try:\n",
        "        temp.append(word_to_index[w]) # 글자를 해당되는 정수로 변환\n",
        "      except KeyError: # 단어 집합에 없는 단어일 경우 unk로 대체된다.\n",
        "        temp.append(word_to_index['unk']) # unk의 인덱스로 변환\n",
        "\n",
        "    encoded.append(temp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgrX1_p0gvLd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "b81f809e-7a31-4909-be58-06342511e8b6"
      },
      "source": [
        "print(encoded[:10])"
      ],
      "execution_count": 300,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0, 10, 381, 19, 213, 139, 7, 0, 19, 25, 23, 0, 5, 4, 0, 64, 285, 0, 4, 0, 2], [0, 200, 6, 30, 91, 72, 0, 0, 0, 0, 0, 0, 115, 0, 29, 50], [145, 35, 0, 0, 5, 0, 0, 349, 6, 0], [257, 224, 499, 0, 190, 0, 20, 331, 7, 0, 0, 4, 224, 499, 0, 7, 0, 6, 106, 20, 163, 0, 160], [6, 481, 236, 139, 181, 12, 0], [360, 476, 0, 0, 5, 47, 156, 0, 7, 16, 14, 0, 7, 0, 127, 0, 5, 47, 21, 51, 43, 47, 167, 247], [0, 0, 0, 161, 0, 7, 477, 0, 57, 58, 12, 40, 7, 64, 21, 0, 7, 0, 57, 367, 134, 110, 43, 2], [0, 0, 99, 7, 58, 4, 6, 99, 7, 58, 0, 0, 211, 254], [9, 75, 0, 36, 102, 387, 0, 123, 0, 135, 38], [197, 208, 59, 0, 0, 415, 0, 254, 167, 15, 120, 10, 6, 0, 78, 4, 11, 400, 140, 17, 479, 204, 3, 135, 156, 0, 0, 14, 2, 5, 36, 0, 0, 0, 0, 102, 27, 0, 0, 0, 0, 4, 12, 0, 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMIN8RWYg2dA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "outputId": "dae5d1bd-759c-4f19-98b3-7f6cc9a64edb"
      },
      "source": [
        "max_len = max(len(l) for l in encoded)\n",
        "print('리뷰의 최대 길이 : %d' % max_len)\n",
        "print('리뷰의 최소 길이 : %d' % min(len(l) for l in encoded))\n",
        "print('리뷰의 평균 길이 : %f' % (sum(map(len, encoded))/len(encoded)))\n",
        "plt.hist([len(s) for s in encoded], bins=50)\n",
        "plt.xlabel('length of sample')\n",
        "plt.ylabel('number of sample')\n",
        "plt.show()"
      ],
      "execution_count": 301,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "리뷰의 최대 길이 : 164\n",
            "리뷰의 최소 길이 : 0\n",
            "리뷰의 평균 길이 : 16.647623\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8DVYNy1g29t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for line in encoded:\n",
        "    if len(line) < max_len: # 현재 샘플이 정해준 길이보다 짧으면\n",
        "        line += [word_to_index['pad']] * (max_len - len(line)) # 나머지는 전부 'pad' 토큰으로 채운다."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYwH0O0mg7QF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "fde1bb44-754d-4e4f-e2de-6ae5d7b6e860"
      },
      "source": [
        "print('리뷰의 최대 길이 : %d' % max(len(l) for l in encoded))\n",
        "print('리뷰의 최소 길이 : %d' % min(len(l) for l in encoded))\n",
        "print('리뷰의 평균 길이 : %f' % (sum(map(len, encoded))/len(encoded)))"
      ],
      "execution_count": 303,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "리뷰의 최대 길이 : 164\n",
            "리뷰의 최소 길이 : 164\n",
            "리뷰의 평균 길이 : 164.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZx6Zbqeg8V1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "e7703141-bbfd-431a-ebac-5a27a40ea85a"
      },
      "source": [
        "print(encoded[:3])"
      ],
      "execution_count": 304,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0, 10, 381, 19, 213, 139, 7, 0, 19, 25, 23, 0, 5, 4, 0, 64, 285, 0, 4, 0, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 200, 6, 30, 91, 72, 0, 0, 0, 0, 0, 0, 115, 0, 29, 50, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [145, 35, 0, 0, 5, 0, 0, 349, 6, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7F8xQe49g-YN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = score_df[:20000]\n",
        "test_df = score_df[20000:]\n",
        "\n",
        "train_df.to_csv(\"train_data.csv\", index=False)\n",
        "test_df.to_csv(\"test_data.csv\", index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCZDR79b6sKk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchtext import data # torchtext.data 임포트\n",
        "from konlpy.tag import Mecab\n",
        "\n",
        "# Mecab을 토크나이저로 사용\n",
        "tokenizer = Mecab()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nl6PvG4F7pEK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 필드 정의\n",
        "TEXT = data.Field(sequential=True,\n",
        "                  use_vocab=True,\n",
        "                  tokenize=tokenizer.morphs, # 토크나이저로는 Mecab 사용.\n",
        "                  lower=True,\n",
        "                  batch_first=True,\n",
        "                  fix_length=20)\n",
        "\n",
        "LABEL = data.Field(sequential=False,\n",
        "                   use_vocab=False,\n",
        "                   is_target=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6URNg2L6u2s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchtext.data import TabularDataset\n",
        "train_data, test_data = TabularDataset.splits(\n",
        "    path='.', train='train_data.csv', test='test_data.csv', format='csv',\n",
        "    fields=[('comment', TEXT), ('score', LABEL)], skip_header=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OS0Sfrgh61JD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "b574c5bc-5b53-4580-f5da-022c923af713"
      },
      "source": [
        "print('훈련 샘플의 개수 : {}'.format(len(train_data)))\n",
        "print('테스트 샘플의 개수 : {}'.format(len(test_data)))"
      ],
      "execution_count": 343,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "훈련 샘플의 개수 : 20000\n",
            "테스트 샘플의 개수 : 10002\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSRTIqWS63OW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "bd06ad93-2743-4436-8dde-9e01887e598c"
      },
      "source": [
        "print(vars(train_data[0]))"
      ],
      "execution_count": 325,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'comment': ['착하', '게', '사', '는', '것', '은', '높', '은', '계단', '을', '오르', '는', '것', '과', '같', '지만', '포기', '하', '고', '내려갈', '때', '는', '너무나', '도', '빠르', '고', '즐겁', '다'], 'score': '10'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TxXeyXw8BrV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dd421ab7-9a18-436f-f62e-c4dd944361d7"
      },
      "source": [
        "TEXT.build_vocab(train_data, min_freq=1)\n",
        "print('단어 집합의 크기 : {}'.format(len(TEXT.vocab)))"
      ],
      "execution_count": 326,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "단어 집합의 크기 : 12956\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9fr6haT8Gw4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEXT.build_vocab(train_data, min_freq=10, max_size=10000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P84OOliz8ILW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9894e8bf-57a0-462e-8b4c-f855b7b629e8"
      },
      "source": [
        "print('단어 집합의 크기 : {}'.format(len(TEXT.vocab)))"
      ],
      "execution_count": 329,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "단어 집합의 크기 : 2402\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5z1mYqIN8JOz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "66dffd48-a7b5-482c-878b-1029a4d10ec1"
      },
      "source": [
        "print(TEXT.vocab.stoi)"
      ],
      "execution_count": 330,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "defaultdict(<function _default_unk_index at 0x7ffa2c514b70>, {'<unk>': 0, '<pad>': 1, '는': 2, '이': 3, '다': 4, '영화': 5, '가': 6, '의': 7, '고': 8, '조커': 9, '하': 10, '을': 11, '에': 12, '은': 13, '보': 14, '를': 15, '한': 16, '연기': 17, '게': 18, '도': 19, '있': 20, '었': 21, '지': 22, '들': 23, '없': 24, '수': 25, '나': 26, '것': 27, '되': 28, '그': 29, '로': 30, '적': 31, '최고': 32, '호아킨': 33, '에서': 34, '했': 35, '으로': 36, '았': 37, '지만': 38, '같': 39, '사람': 40, '습니다': 41, '음': 42, '과': 43, '할': 44, '어': 45, '너무': 46, '와': 47, '진짜': 48, '않': 49, '였': 50, '생각': 51, '잘': 52, '피닉스': 53, '좋': 54, '던': 55, '는데': 56, '만': 57, '내': 58, '말': 59, '아서': 60, '면': 61, '인': 62, '안': 63, '기': 64, '정말': 65, '봤': 66, '거': 67, '네요': 68, '사회': 69, '때': 70, '싶': 71, '소름': 72, '인생': 73, '주': 74, '아': 75, '듯': 76, '아니': 77, '어요': 78, '연출': 79, '까지': 80, '연기력': 81, '면서': 82, '번': 83, '더': 84, '해': 85, '함': 86, '웃': 87, '그냥': 88, '라는': 89, '에게': 90, '완벽': 91, '미친': 92, '본': 93, '내내': 94, '만들': 95, '겠': 96, '미쳤': 97, '라': 98, '알': 99, '이해': 100, '서': 101, '재밌': 102, '스토리': 103, '될': 104, '보다': 105, '입니다': 106, '배우': 107, '장면': 108, '처음': 109, '웃음': 110, '왜': 111, '남': 112, '라고': 113, '광기': 114, '세상': 115, '볼': 116, '몰입': 117, '하나': 118, '탄생': 119, '자체': 120, '정도': 121, '다고': 122, '중': 123, '해서': 124, '음악': 125, '우리': 126, '계단': 127, '모든': 128, '끝': 129, '돋': 130, '며': 131, '느낌': 132, '또': 133, '다는': 134, '히스레저': 135, '현실': 136, '명작': 137, '많': 138, '된': 139, '점': 140, '줄': 141, '네': 142, '이런': 143, '공감': 144, '시간': 145, '감정': 146, '는지': 147, '모르': 148, '전': 149, '필요': 150, '표현': 151, '다크': 152, '받': 153, '다른': 154, '기대': 155, '속': 156, '인간': 157, '부터': 158, '작품': 159, '건': 160, '성': 161, '다시': 162, '지루': 163, '마음': 164, '마지막': 165, '그리고': 166, '두': 167, '정신': 168, '배트맨': 169, '일': 170, '한다': 171, '씬': 172, '못': 173, '우울': 174, '살': 175, '이상': 176, '합니다': 177, '모두': 178, '임': 179, '호아킨피닉스': 180, '올해': 181, '자': 182, '나오': 183, '나이트': 184, '이렇게': 185, '걸': 186, '과정': 187, '삶': 188, '가장': 189, '누구': 190, '니': 191, '기분': 192, '다면': 193, '아닌': 194, '위험': 195, 'ㄷ': 196, '모습': 197, '자신': 198, '여운': 199, '역대': 200, '길': 201, '꼭': 202, '분': 203, '년': 204, '악당': 205, '만든': 206, '보여': 207, '난': 208, '야': 209, '예술': 210, '캐릭터': 211, '계속': 212, '액션': 213, '화': 214, '슬프': 215, '으면': 216, '악': 217, '히어로': 218, '된다': 219, '엔': 220, '후': 221, '세': 222, '주인공': 223, '뭐': 224, '내용': 225, '순간': 226, '어서': 227, '없이': 228, '처럼': 229, '개인': 230, '대단': 231, '소리': 232, '재미있': 233, '좀': 234, '세요': 235, '인지': 236, '평점': 237, '대한': 238, '눈물': 239, '마블': 240, '시': 241, '는다': 242, '몰': 243, '재미': 244, '이유': 245, '이야기': 246, '을까': 247, '다가': 248, '관람': 249, '러': 250, '비극': 251, '때문': 252, '슬픈': 253, '많이': 254, '이게': 255, '빌': 256, '급': 257, '저': 258, '살인': 259, '런': 260, '이건': 261, '개': 262, '밖': 263, '춤': 264, '같이': 265, '코미디': 266, '뿐': 267, '영상미': 268, '아요': 269, '율': 270, '대박': 271, '긴장감': 272, '너무나': 273, '입': 274, '지금': 275, '이나': 276, 'ㅋㅋ': 277, '만드': 278, 'ㅠㅠ': 279, '데': 280, '인가': 281, '그런': 282, '인데': 283, '높': 284, '미쳐': 285, '내면': 286, '진': 287, '근데': 288, '맞': 289, '압도': 290, '어떻게': 291, '느끼': 292, '만큼': 293, '분위기': 294, '인물': 295, '추천': 296, '히스레져': 297, '날': 298, '밖에': 299, '신': 300, '훌륭': 301, '감독': 302, '봐야': 303, '불편': 304, '슬픔': 305, '물': 306, '시작': 307, '감': 308, '긴': 309, '오랜만': 310, '눈': 311, '담배': 312, '맨': 313, '부분': 314, '깊': 315, '요': 316, '잼': 317, '힘들': 318, '넘': 319, '란': 320, '잔인': 321, '영화관': 322, '오': 323, '해야': 324, '느꼈': 325, '선': 326, '정신병': 327, '피': 328, '플렉': 329, '행복': 330, '입감': 331, '가지': 332, '광대': 333, '냐': 334, '감탄': 335, '시대': 336, '울': 337, '호불호': 338, '분노': 339, '랑': 340, '봐도': 341, '정당': 342, '관객': 343, '이거': 344, '재미없': 345, '참': 346, '가슴': 347, '걱정': 348, '영웅': 349, '작': 350, '나왔': 351, '굿': 352, '미국': 353, '그렇게': 354, '동안': 355, '미치': 356, '상황': 357, '준': 358, '극장': 359, '느껴': 360, '배경': 361, '범죄': 362, '마다': 363, '이번': 364, '역시': 365, '무엇': 366, '어떤': 367, '질': 368, '단': 369, '라면': 370, '매력': 371, '무섭': 372, '조금': 373, '폭력': 374, '기억': 375, '집중': 376, '춤추': 377, '그저': 378, '나올': 379, '특히': 380, '하지만': 381, '등': 382, '박수': 383, '불쌍': 384, '사': 385, '남자': 386, '아주': 387, '이후': 388, '씨': 389, '돈': 390, '됨': 391, '매우': 392, '위': 393, '줬': 394, '충격': 395, '디': 396, '인상': 397, '크': 398, '갔': 399, '기생충': 400, '는가': 401, '대': 402, '약자': 403, '영상': 404, '결국': 405, '놈': 406, '끝나': 407, '앞': 408, '완전': 409, '이제': 410, '뭔가': 411, '왔': 412, '잊': 413, '한국': 414, '몇': 415, '버리': 416, '긴장': 417, '에겐': 418, '의미': 419, '무서운': 420, '봄': 421, '절대': 422, '제': 423, '거나': 424, '표정': 425, '한번': 426, '나쁜': 427, '미': 428, '보이': 429, '어두운': 430, '행동': 431, '누군가': 432, '더라': 433, '못하': 434, '제대로': 435, '혼자': 436, '괴물': 437, '낸': 438, '존재': 439, '집': 440, '분장': 441, '은데': 442, '아직': 443, '초반': 444, '한테': 445, '고담': 446, '그렇': 447, '사랑': 448, '사실': 449, '생각나': 450, '어디': 451, '놓': 452, '멋있': 453, '어느': 454, '재': 455, '뒤': 456, '먹': 457, '여러': 458, '건지': 459, '아무': 460, '엄청난': 461, 'ㄹ': 462, '관심': 463, '당신': 464, '대해': 465, '슬펐': 466, '따라': 467, '환경': 468, 'ㅠ': 469, '무시': 470, '시리즈': 471, '극': 472, '누가': 473, '버린': 474, '베트': 475, '솔직히': 476, '명': 477, '버렸': 478, '불': 479, '새로운': 480, '애': 481, '평': 482, '후반부': 483, '간': 484, '됐': 485, '어야': 486, '제일': 487, '가치': 488, '님': 489, '암울': 490, '전혀': 491, '니까': 492, '든': 493, '별로': 494, '다만': 495, '마': 496, '머리': 497, '진심': 498, '친구': 499, '그래서': 500, '아름답': 501, '편': 502, '해요': 503, '치': 504, '히스': 505, '나온': 506, '다니': 507, '웨인': 508, '자기': 509, '죽': 510, '걸작': 511, '구나': 512, '느낄': 513, '다르': 514, '엄청': 515, '죽이': 516, '총': 517, 'ㅎㅎ': 518, '그대로': 519, '났': 520, '무슨': 521, '으나': 522, '감동': 523, '압권': 524, '완성': 525, '해도': 526, '희극': 527, '고통': 528, '쓰': 529, '얼마나': 530, '오늘': 531, '주변': 532, '그것': 533, '끼치': 534, '망상': 535, '보고': 536, '어도': 537, '중간': 538, '도록': 539, '라도': 540, '범죄자': 541, '설명': 542, '숨': 543, '잡': 544, '너': 545, '드': 546, '아닐까': 547, '강렬': 548, '굉장히': 549, '대사': 550, '뻔': 551, '연민': 552, '위해': 553, '잃': 554, '려고': 555, '보여준': 556, '순수': 557, '심리': 558, '아깝': 559, '오락': 560, '통쾌': 561, '한편': 562, '갈': 563, '다음': 564, '스럽': 565, '일까': 566, '큰': 567, 'ㅇ': 568, '문제': 569, '비교': 570, '이입': 571, '킨': 572, '나라': 573, '뛰어넘': 574, '싫': 575, '에요': 576, '위한': 577, '째': 578, '형': 579, '힘든': 580, '믿': 581, '봐라': 582, '이미': 583, '점점': 584, '충분히': 585, '함께': 586, '그러': 587, '담시': 588, '아님': 589, '얼굴': 590, '진정': 591, '차': 592, '땐': 593, '려': 594, '수준': 595, '어둡': 596, '어린': 597, '이걸': 598, '여': 599, '죽음': 600, '추': 601, '감히': 602, '노': 603, '배려': 604, '부족': 605, '빠져': 606, '아이': 607, '아프': 608, '약간': 609, '처절': 610, '곳': 611, '내려오': 612, '무례': 613, '비': 614, '악마': 615, '첫': 616, 'ㅜㅜ': 617, '그만큼': 618, '느껴졌': 619, '또한': 620, '무': 621, '분명': 622, '상': 623, '연출력': 624, '자꾸': 625, '정신병자': 626, '밋': 627, '시키': 628, '악인': 629, '청불': 630, '최근': 631, 'ㅎ': 632, '다운': 633, '띵': 634, '상상': 635, '쓰레기': 636, '으며': 637, '장난': 638, '주연': 639, '척': 640, '태어나': 641, '갈수록': 642, '담': 643, '무겁': 644, '손': 645, '잘못': 646, '찝찝': 647, '그리': 648, '다큐': 649, '레저': 650, '불쾌': 651, '평가': 652, '해석': 653, '화려': 654, '감사': 655, '그래도': 656, '글': 657, '딱': 658, '미칠': 659, '바': 660, '쇼': 661, '싸이코': 662, '오히려': 663, '정의': 664, '조크': 665, '충분': 666, '갈릴': 667, '괜찮': 668, '당하': 669, '못한': 670, '우': 671, '이랑': 672, '입도': 673, '찾': 674, '평범': 675, '하나하나': 676, '마세요': 677, '마저': 678, '몸': 679, '무서웠': 680, '살아가': 681, '씁쓸': 682, '예의': 683, '온': 684, '인정': 685, '졌': 686, '타인': 687, '가진': 688, '됩니다': 689, '등장': 690, '불안': 691, '빠지': 692, '실망': 693, '아야': 694, '취향': 695, '후회': 696, '그러나': 697, '상처': 698, '소외': 699, '이것': 700, '잇': 701, '코믹스': 702, '평론가': 703, '마스터': 704, '메세지': 705, '변화': 706, '장르': 707, '쩔': 708, '쯤': 709, '한다는': 710, '간다': 711, '강추': 712, '공포': 713, '과연': 714, '눈빛': 715, '마치': 716, '몰랐': 717, '묘사': 718, '수작': 719, '전개': 720, '전율': 721, '지하철': 722, '가득': 723, '걍': 724, '못했': 725, '병': 726, '본인': 727, '죠': 728, '착하': 729, '팬': 730, '한마디': 731, 'ㅋㅋㅋ': 732, '꿈': 733, '만족': 734, '미소': 735, '미치광이': 736, '생': 737, '엔딩': 738, '요소': 739, '차이': 740, '항상': 741, '머레이': 742, '바로': 743, '선택': 744, '제발': 745, '평생': 746, '폭발': 747, '한데': 748, '걸릴': 749, '동시': 750, '물론': 751, '번역': 752, '변해': 753, '아팠': 754, '엄마': 755, '와킨': 756, '절망': 757, '짓': 758, '찍': 759, '그런데': 760, '맘': 761, '멋진': 762, '무조건': 763, '신들린': 764, '심오': 765, '요즘': 766, '갑니다': 767, '거의': 768, '그게': 769, '드라마': 770, '듯이': 771, '만점': 772, '멘탈': 773, '별': 774, '본다': 775, '전체': 776, '정상': 777, '타임': 778, 'ㅋ': 779, '겪': 780, '떠나': 781, '부': 782, '최악': 783, '가까이': 784, '건가': 785, '노력': 786, '온몸': 787, '원': 788, '으면서': 789, '응원': 790, '일단': 791, '중요': 792, '청소년': 793, '피스': 794, '혼돈': 795, '가능': 796, '낮': 797, '닿': 798, '몸짓': 799, '상태': 800, '아름다운': 801, '엄청나': 802, '좋아하': 803, '질환': 804, '짱': 805, '해피': 806, '환자': 807, '희망': 808, '개연': 809, '더욱': 810, '던데': 811, '든다': 812, '렸': 813, '얘기': 814, '입장': 815, '총기': 816, '나가': 817, '둘': 818, '명장면': 819, '보단': 820, '봐': 821, '봐서': 822, '브루스': 823, '에선': 824, '오래': 825, '원래': 826, '카타르시스': 827, '하루': 828, '그린': 829, '단순': 830, '단연': 831, '반': 832, '발견': 833, '변하': 834, '보였': 835, '스스로': 836, '여자': 837, '역': 838, '우울증': 839, '지리': 840, '첨': 841, '코미디언': 842, '타': 843, '갈리': 844, '감정선': 845, '꺼': 846, '댓글': 847, '뛰어난': 848, '모를': 849, '불행': 850, '세계': 851, '안타깝': 852, '어쩌면': 853, '언제': 854, '적나라': 855, '통해': 856, '피로': 857, '광': 858, '그랬': 859, '기에': 860, '대로': 861, '메시지': 862, '무거운': 863, '비슷': 864, '연상': 865, '이전': 866, '중반': 867, '간만에': 868, '걸까': 869, '그걸': 870, '넘치': 871, '느낀': 872, '대중': 873, '레전드': 874, '비판': 875, '사운드': 876, '아닌가': 877, '아카데미': 878, '조': 879, '즐겁': 880, '호아': 881, '흥미': 882, '기준': 883, '듣': 884, '만든다': 885, '반전': 886, '보내': 887, '순': 888, '쉽': 889, '초': 890, '화장실': 891, '후반': 892, '감상': 893, '건강': 894, '궁금': 895, '깊이': 896, '막': 897, '만나': 898, '묻': 899, '배': 900, '부모': 901, '살짝': 902, '스러운': 903, '씩': 904, '완전히': 905, '유일': 906, '착한': 907, '케': 908, '코메디': 909, '한다면': 910, '현': 911, 'ㅈ': 912, '거리': 913, '노래': 914, '다소': 915, '설득력': 916, '시선': 917, '여기': 918, '왕': 919, '을지': 920, '장애': 921, '주관': 922, '진지': 923, '힘': 924, '개봉': 925, '구': 926, '나쁘': 927, '나와서': 928, '드립니다': 929, '라서': 930, '리뷰': 931, '먹먹': 932, '멋지': 933, '못할': 934, '서로': 935, '엇': 936, '역할': 937, '우주': 938, '타락': 939, '포인트': 940, '확실히': 941, '희열': 942, '기존': 943, '끔찍': 944, '끝내': 945, '끼쳤': 946, '나중': 947, '달': 948, '답답': 949, '돌': 950, '따': 951, '뛰': 952, '뛰어나': 953, '로서': 954, '림': 955, '명연기': 956, '모순': 957, '법': 958, '빛': 959, '살인마': 960, '상업': 961, '예고편': 962, '인상깊': 963, '전부': 964, '준다': 965, '쩐': 966, '패스': 967, '현대': 968, '경계': 969, '기원': 970, '끝난': 971, '놀랍': 972, '단순히': 973, '대체': 974, '뗄': 975, '렸다': 976, '묵직': 977, '보여준다': 978, '빠져들': 979, '아픈': 980, '열광': 981, '옆': 982, '예상': 983, '이야': 984, '일어나': 985, '일품': 986, '조차': 987, '확실': 988, '각성': 989, '갓': 990, '거기': 991, '곱씹': 992, '더니': 993, '되게': 994, '따뜻': 995, '루즈': 996, '모방': 997, '아쉽': 998, '아픔': 999, '올': 1000, '잊혀': 1001, '자리': 1002, '친절': 1003, '혼란': 1004, '가취': 1005, '굳': 1006, '그럴': 1007, '던지': 1008, '된다는': 1009, '라니': 1010, '부활': 1011, '연기자': 1012, '이란': 1013, '주제': 1014, '탓': 1015, '학대': 1016, '그런지': 1017, '금': 1018, '남기': 1019, '납득': 1020, '동정': 1021, '본다면': 1022, '불가': 1023, '비추': 1024, '사건': 1025, '상당히': 1026, '서사': 1027, '설득': 1028, '시켜': 1029, '씹': 1030, '아도': 1031, '어려운': 1032, '용': 1033, '진실': 1034, '판': 1035, '풀': 1036, '호아퀸': 1037, '끌': 1038, '놀라': 1039, '대작': 1040, '들어가': 1041, '리얼': 1042, '머릿속': 1043, '바라': 1044, '비참': 1045, '상영': 1046, '스크린': 1047, '심장': 1048, '어둠': 1049, '어라': 1050, '올라가': 1051, '왠지': 1052, '위로': 1053, '으론': 1054, '잔잔': 1055, '조조': 1056, '할지': 1057, '혹은': 1058, '화면': 1059, '구요': 1060, '극단': 1061, '극한': 1062, '나온다': 1063, '미화': 1064, '바뀌': 1065, '봅니다': 1066, '세계관': 1067, '시절': 1068, '시켰': 1069, '써': 1070, '아닙니다': 1071, '악역': 1072, '역사': 1073, '와서': 1074, '이름': 1075, '자극': 1076, '자막': 1077, '저런': 1078, '쩌': 1079, '찬사': 1080, '카메라': 1081, '토마스': 1082, '회차': 1083, '과거': 1084, '그려': 1085, '내려가': 1086, '너무너무': 1087, '느껴질': 1088, '만화': 1089, '배트': 1090, '번역가': 1091, '별점': 1092, '보통': 1093, '사이': 1094, '색감': 1095, '섬뜩': 1096, '스릴러': 1097, '시민': 1098, '쓴': 1099, '아무리': 1100, '아쉬운': 1101, '열': 1102, '입술': 1103, '진다': 1104, '짐': 1105, '철학': 1106, '첼로': 1107, '틈': 1108, '현재': 1109, '환호': 1110, 'ㅜ': 1111, '가족': 1112, '각본': 1113, '갖': 1114, '고서': 1115, '기어린': 1116, '나옴': 1117, '다큐멘터리': 1118, '답': 1119, '러닝': 1120, '바라보': 1121, '부정': 1122, '부조리': 1123, '불구': 1124, '비긴즈': 1125, '쉬': 1126, '영향': 1127, '오르': 1128, '웃기': 1129, '이토록': 1130, '자마자': 1131, '토드': 1132, '합리': 1133, '환상': 1134, '감명깊': 1135, '경찰차': 1136, '나와': 1137, '나요': 1138, '내려올': 1139, '단어': 1140, '떨어지': 1141, '미안': 1142, '버림': 1143, '보인다': 1144, '복잡': 1145, '빠져서': 1146, '빼': 1147, '실제': 1148, '아들': 1149, '어렵': 1150, '어벤져스': 1151, '어울리': 1152, '예정': 1153, '잔혹': 1154, '져': 1155, '최': 1156, '춤출': 1157, '탄탄': 1158, '태어난': 1159, '한동안': 1160, '해라': 1161, '흐름': 1162, '경찰': 1163, '까': 1164, '닮': 1165, '등급': 1166, '마냥': 1167, '무언가': 1168, '문': 1169, '버릴': 1170, '봐야지': 1171, '생기': 1172, '스': 1173, '시킨': 1174, '앗': 1175, '어머니': 1176, '웅장': 1177, '원작': 1178, '이터': 1179, '인해': 1180, '춤사위': 1181, '터지': 1182, '필립스': 1183, '한가': 1184, '했었': 1185, '가정': 1186, '그릴': 1187, '낳': 1188, '느껴진다': 1189, '능력': 1190, '대해서': 1191, '됬': 1192, '뭔지': 1193, '밑바닥': 1194, '바닥': 1195, '섹시': 1196, '셈': 1197, '시원': 1198, '실': 1199, '실제로': 1200, '심지어': 1201, '싸': 1202, '앉': 1203, '옹호': 1204, '으니': 1205, '으로서': 1206, '음향': 1207, '자연': 1208, '전달': 1209, '짜리': 1210, '카드': 1211, '커': 1212, '쾌감': 1213, '포기': 1214, '표출': 1215, '한다고': 1216, '흠': 1217, 'ㄴ': 1218, '가시': 1219, '경험': 1220, '고자': 1221, '공허': 1222, '관점': 1223, '괜히': 1224, '권': 1225, '귀': 1226, '근래': 1227, '기괴': 1228, '넣': 1229, '논란': 1230, '농담': 1231, '뇌': 1232, '늘': 1233, '덜': 1234, '린다': 1235, '미장센': 1236, '사이코패스': 1237, '시나리오': 1238, '약한': 1239, '울컥': 1240, '일어날': 1241, '저렇게': 1242, '존': 1243, '주위': 1244, '지나': 1245, '진행': 1246, '짧': 1247, '출': 1248, '평소': 1249, '표': 1250, '피폐': 1251, '황금': 1252, '가볍': 1253, '걸리': 1254, '고민': 1255, '극찬': 1256, '깔리': 1257, '꿀': 1258, '난쟁이': 1259, '남겨': 1260, '놀랐': 1261, '당했': 1262, '대한민국': 1263, '래디': 1264, '력': 1265, '맛': 1266, '박지훈': 1267, '부여': 1268, '비난': 1269, '사자상': 1270, '섬세': 1271, '수많': 1272, '숨죽이': 1273, '식이': 1274, '안쓰럽': 1275, '어제': 1276, '예매': 1277, '외면': 1278, '우려': 1279, '조화': 1280, '줘서': 1281, '지독': 1282, '칠': 1283, '택시': 1284, '터': 1285, '텐데': 1286, '틀': 1287, '판단': 1288, '폭동': 1289, '푹': 1290, '훨씬': 1291, '흐르': 1292, 'ㅅ': 1293, '감성': 1294, '강한': 1295, '나락': 1296, '난다': 1297, '낫': 1298, '도시': 1299, '돋보이': 1300, '드라이버': 1301, '듬': 1302, '따위': 1303, '려는': 1304, '롭': 1305, '성공': 1306, '아닌데': 1307, '약': 1308, '억지로': 1309, '완성도': 1310, '으로써': 1311, '이끌': 1312, '일지': 1313, '조롱': 1314, '존중': 1315, '줘야': 1316, '진정한': 1317, '찌질': 1318, '차위': 1319, '한지': 1320, '할까': 1321, '햇': 1322, '가난': 1323, '경지': 1324, '다행': 1325, '더라도': 1326, '로써': 1327, '로운': 1328, '멀리': 1329, '멀리서': 1330, '멋': 1331, '밝': 1332, '봐요': 1333, '브금': 1334, '빨간': 1335, '셨': 1336, '스타일': 1337, '식': 1338, '쏘': 1339, '어떻': 1340, '연결': 1341, '예요': 1342, '완벽히': 1343, '의문': 1344, '이리': 1345, '일반': 1346, '자본주의': 1347, '장': 1348, '점수': 1349, '정말로': 1350, '존나': 1351, '쥐': 1352, '찐따': 1353, '차별': 1354, '채': 1355, '평등': 1356, '풍자': 1357, '가히': 1358, '갠': 1359, '겁니다': 1360, '그동안': 1361, '그래': 1362, '깨닫': 1363, '나이': 1364, '내려갈': 1365, '대변': 1366, '더라면': 1367, '돈다': 1368, '동화': 1369, '디테일': 1370, '따라가': 1371, '레딧': 1372, '리': 1373, '마시': 1374, '마주': 1375, '상대': 1376, '속편': 1377, '시티': 1378, '신경': 1379, '어쩔': 1380, '어찌': 1381, '얼마': 1382, '옷': 1383, '울음': 1384, '위대': 1385, '유쾌': 1386, '음울': 1387, '자유': 1388, '잠': 1389, '절규': 1390, '지옥': 1391, '쳐': 1392, '특유': 1393, '파괴': 1394, '팝콘': 1395, '품': 1396, '해졌': 1397, '호야': 1398, '거짓': 1399, '겁나': 1400, '그럼에도': 1401, '길래': 1402, '깨': 1403, '꽉': 1404, '꽤': 1405, '나름': 1406, '넋': 1407, '놀란': 1408, '당연': 1409, '더군요': 1410, '또는': 1411, '막히': 1412, '맡': 1413, '매일': 1414, '뭘': 1415, '방금': 1416, '변신': 1417, '병원': 1418, '빨리': 1419, '상평': 1420, '새': 1421, '소': 1422, '슬퍼': 1423, '심': 1424, '연속': 1425, '올라갈': 1426, '우린': 1427, '의심': 1428, '자면': 1429, '잖아': 1430, '전반': 1431, '정치': 1432, '졸': 1433, '짠': 1434, '차라리': 1435, '학생': 1436, '해질': 1437, '했어요': 1438, '호': 1439, '흘리': 1440, '가면': 1441, '간지': 1442, '개꿀': 1443, '게임': 1444, '계기': 1445, '관계': 1446, '굉장': 1447, '그때': 1448, '기득': 1449, '기립': 1450, '능가': 1451, '단점': 1452, '단지': 1453, '돼': 1454, '만약': 1455, '매': 1456, '멍': 1457, '무비': 1458, '미침': 1459, '반성': 1460, '백': 1461, '비웃': 1462, '빠르': 1463, '세로': 1464, '소재': 1465, '소화': 1466, '스러웠': 1467, '스트레스': 1468, '쓸쓸': 1469, '아닌지': 1470, '아닐': 1471, '알려': 1472, '어느새': 1473, '얻': 1474, '여서': 1475, '열심히': 1476, '영혼': 1477, '오지': 1478, '원맨쇼': 1479, '은지': 1480, '자살': 1481, '잠재': 1482, '저지르': 1483, '적절': 1484, '제목': 1485, '죽일': 1486, '짜릿': 1487, '찢': 1488, '찬': 1489, '천': 1490, '키': 1491, '트': 1492, '피해자': 1493, '행위': 1494, '황홀': 1495, '후속작': 1496, '흠잡': 1497, '가까운': 1498, '갑': 1499, '구성': 1500, '김지영': 1501, '냐고': 1502, '놀라운': 1503, '느껴짐': 1504, '다룬': 1505, '다를': 1506, '다양': 1507, '대신': 1508, '더라구요': 1509, '두말': 1510, '드디어': 1511, '떠오르': 1512, '베스트': 1513, '비로소': 1514, '빈부': 1515, '빨': 1516, '생활': 1517, '설정': 1518, '소장': 1519, '손가락': 1520, '수록': 1521, '아름다웠': 1522, '아무것': 1523, '아이러니': 1524, '약하': 1525, '어마어마': 1526, '외': 1527, '욕': 1528, '우울해': 1529, '의도': 1530, '이라도': 1531, '절': 1532, '천재': 1533, '희대': 1534, '힘겹': 1535, 'ㅡㅡ': 1536, '강력': 1537, '결말': 1538, '결코': 1539, '굳이': 1540, '금연': 1541, '끼칠': 1542, '당한': 1543, '돌아보': 1544, '등등': 1545, '랄까': 1546, '로웠': 1547, '릭터': 1548, '마음속': 1549, '맛있': 1550, '멈추': 1551, '모른다': 1552, '발': 1553, '봐야겠다': 1554, '빨려': 1555, '뼈': 1556, '색': 1557, '생각났': 1558, '시점': 1559, '아마': 1560, '안타까운': 1561, '어른': 1562, '어릴': 1563, '엿': 1564, '오랫만': 1565, '오스카': 1566, '으니까': 1567, '이러': 1568, '이미지': 1569, '일상': 1570, '입꼬리': 1571, '잠시': 1572, '잭': 1573, '정서': 1574, '조명': 1575, '존재감': 1576, '종일': 1577, '죄': 1578, '주의': 1579, '지려': 1580, '짠하': 1581, '착각': 1582, '촬영': 1583, '킬링': 1584, '포': 1585, '개지': 1586, '결과': 1587, '고조': 1588, '교훈': 1589, '기력': 1590, '난리': 1591, '대비': 1592, '덕분': 1593, '도대체': 1594, '도덕': 1595, '될까': 1596, '두렵': 1597, '똥': 1598, '라기': 1599, '려면': 1600, '매료': 1601, '먼저': 1602, '멸시': 1603, '무대': 1604, '반영': 1605, '배역': 1606, '벌리': 1607, '보낸다': 1608, '뽑': 1609, '상담': 1610, '새롭': 1611, '아까움': 1612, '아동': 1613, '악한': 1614, '역설': 1615, '옳': 1616, '와우': 1617, '자아': 1618, '직접': 1619, '질문': 1620, '짜증': 1621, '추가': 1622, '탑': 1623, '값': 1624, '건데': 1625, '괴롭히': 1626, '구분': 1627, '군중': 1628, '깨달': 1629, '끈': 1630, '나약': 1631, '나타났': 1632, '냈': 1633, '다리': 1634, '달리': 1635, '대부분': 1636, '댄스': 1637, '든지': 1638, '람': 1639, '로부터': 1640, '명대사': 1641, '명품': 1642, '못해': 1643, '묘한': 1644, '및': 1645, '반응': 1646, '방향': 1647, '보임': 1648, '복지': 1649, '부자': 1650, '블랙': 1651, '비화': 1652, '빠': 1653, '빠진': 1654, '사이코': 1655, '살아갈': 1656, '서서히': 1657, '선악': 1658, '성인': 1659, '셔서': 1660, '소지': 1661, '숨겨진': 1662, '승화': 1663, '아까운': 1664, '아름다움': 1665, '야지': 1666, '오버랩': 1667, '외로움': 1668, '우아': 1669, '유명': 1670, '으려': 1671, '의해': 1672, '읽': 1673, '즐거움': 1674, '지나갔': 1675, '지키': 1676, '짙': 1677, '친': 1678, '케릭': 1679, '태어났': 1680, '테러': 1681, '토크': 1682, '특별': 1683, '한없이': 1684, '함부로': 1685, '해냈': 1686, '확': 1687, '후유증': 1688, '가벼운': 1689, '가질': 1690, '가치관': 1691, '갈비뼈': 1692, '강하': 1693, '걸린': 1694, '격차': 1695, '계층': 1696, '고생': 1697, '과악': 1698, '관': 1699, '그런가': 1700, '그야말로': 1701, '깔': 1702, '끊': 1703, '끼': 1704, '나머지': 1705, '나타나': 1706, '네여': 1707, '누': 1708, '느낀다': 1709, '니콜슨': 1710, '당': 1711, '동작': 1712, '딴': 1713, '똑같': 1714, '맴': 1715, '메소드': 1716, '멱살': 1717, '미친놈': 1718, '반대': 1719, '받아들이': 1720, '밟': 1721, '방법': 1722, '버린다': 1723, '베': 1724, '변할': 1725, '볼까': 1726, '비명': 1727, '뽕': 1728, '삐': 1729, '선사': 1730, '쉴': 1731, '슈퍼': 1732, '신선': 1733, '실존': 1734, '심각': 1735, '애잔': 1736, '어딘가': 1737, '어쩌': 1738, '언제나': 1739, '연': 1740, '연쇄': 1741, '영': 1742, '영화제': 1743, '오랜': 1744, '웃긴': 1745, '임팩트': 1746, '지도': 1747, '직업': 1748, '찰리': 1749, '채플린': 1750, '쳤': 1751, '출연': 1752, '층': 1753, '틀림없': 1754, '팔': 1755, '프로': 1756, '프리퀄': 1757, '흥행': 1758, 'ㅠㅠㅠ': 1759, 'ㅡ': 1760, '감명': 1761, '걷': 1762, '겟': 1763, '결론': 1764, '경이': 1765, '귓가': 1766, '끝판': 1767, '나갈': 1768, '느라': 1769, '는구나': 1770, '니다': 1771, '다섯': 1772, '단언': 1773, '당연히': 1774, '당위': 1775, '대리': 1776, '대하': 1777, '도저히': 1778, '뜻': 1779, '라며': 1780, '머': 1781, '멋졌': 1782, '모호': 1783, '무서움': 1784, '바란다': 1785, '박자': 1786, '밤': 1787, '방아쇠': 1788, '베니스': 1789, '볼수록': 1790, '불우': 1791, '빡': 1792, '사고': 1793, '사상': 1794, '삼': 1795, '생애': 1796, '선동': 1797, '세기': 1798, '시킨다': 1799, '시킬': 1800, '신나': 1801, '심정': 1802, '심하': 1803, '아쉬움': 1804, '아쉬웠': 1805, '아침': 1806, '애초': 1807, '억압': 1808, '엄청났': 1809, '엇다': 1810, '에로': 1811, '여태': 1812, '으': 1813, '을수록': 1814, '이기': 1815, '잠깐': 1816, '젊': 1817, '정': 1818, '정점': 1819, '정체': 1820, '죽여': 1821, '줍니다': 1822, '지나치': 1823, '지지': 1824, '짓밟': 1825, '찢어진': 1826, '참고': 1827, '책임': 1828, '커버': 1829, '탈': 1830, '터져': 1831, '테': 1832, '포함': 1833, '하층민': 1834, '해진': 1835, '혁명': 1836, '가상': 1837, '가해자': 1838, '강요': 1839, '거지': 1840, '관가': 1841, '구도': 1842, '군요': 1843, '그건': 1844, '그만': 1845, '극도': 1846, '깜짝': 1847, '나서': 1848, '나올까': 1849, '내려놓': 1850, '내일': 1851, '낼': 1852, '네이버': 1853, '다기': 1854, '다름': 1855, '도움': 1856, '동생': 1857, '동의': 1858, '동조': 1859, '돼서': 1860, '될지': 1861, '들렸': 1862, '디시': 1863, '딩크': 1864, '때론': 1865, '땜': 1866, '똑똑': 1867, '렷': 1868, '로버트': 1869, '류': 1870, '만난': 1871, '몇몇': 1872, '무서울': 1873, '뭔': 1874, '발생': 1875, '방송': 1876, '방식': 1877, '벗어나': 1878, '부적응': 1879, '빠질': 1880, '살려': 1881, '살아왔': 1882, '살해': 1883, '상당': 1884, '상징': 1885, '성격': 1886, '수저': 1887, '순삭': 1888, '숨기': 1889, '슬플': 1890, '시각': 1891, '시사': 1892, '시종일관': 1893, '썩': 1894, '아래': 1895, '악행': 1896, '알리': 1897, '앓': 1898, '압': 1899, '어용': 1900, '에게서': 1901, '연극': 1902, '열연': 1903, '예측': 1904, '온전히': 1905, '원했': 1906, '유지': 1907, '유치': 1908, '으신': 1909, '의견': 1910, '의한': 1911, '이래서': 1912, '이루': 1913, '이면': 1914, '이용': 1915, '이젠': 1916, '이하': 1917, '인한': 1918, '잭니콜슨': 1919, '저렇': 1920, '정작': 1921, '줌': 1922, '즐거운': 1923, '즐기': 1924, '지금껏': 1925, '짜': 1926, '찜찜': 1927, '최초': 1928, '충동': 1929, '취급': 1930, '캐리': 1931, '편하': 1932, '평론': 1933, '포스터': 1934, '한참': 1935, '해짐': 1936, '핵': 1937, '했으나': 1938, '행오버': 1939, '흘렀': 1940, 'ㅂ': 1941, '각': 1942, '각자': 1943, '갈등': 1944, '갑자기': 1945, '거대': 1946, '게끔': 1947, '경고': 1948, '과장': 1949, '괴롭': 1950, '기회': 1951, '끼리': 1952, '남주': 1953, '내리': 1954, '뇌리': 1955, '느': 1956, '다물': 1957, '다시금': 1958, '던가': 1959, '데리': 1960, '돌아가': 1961, '동일': 1962, '드니로': 1963, '듭니다': 1964, '떠올랐': 1965, '마디': 1966, '맥스': 1967, '맴도': 1968, '모': 1969, '무게': 1970, '물들': 1971, '밑': 1972, '바랍니다': 1973, '반드시': 1974, '반복': 1975, '배신': 1976, '보냅니다': 1977, '보여서': 1978, '보일': 1979, '불만': 1980, '비해': 1981, '빠져드': 1982, '빵': 1983, '살리': 1984, '생각난다': 1985, '선한': 1986, '성장': 1987, '세력': 1988, '세밀': 1989, '스러울': 1990, '스릴': 1991, '슬': 1992, '시스템': 1993, '신기': 1994, '심신': 1995, '쌓': 1996, '아냐': 1997, '아무런': 1998, '안타까웠': 1999, '어려웠': 2000, '여러모로': 2001, '여야': 2002, '예': 2003, '오랫동안': 2004, '움': 2005, '원인': 2006, '위선': 2007, '으로부터': 2008, '을까요': 2009, '이대로': 2010, '이세상': 2011, '일반인': 2012, '자세': 2013, '자주': 2014, '전설': 2015, '절로': 2016, '절제': 2017, '젤': 2018, '조국': 2019, '조용': 2020, '죽였': 2021, '죽인': 2022, '지경': 2023, '지나가': 2024, '지났': 2025, '쪽': 2026, '쫄': 2027, '최소한': 2028, '치명': 2029, '탁월': 2030, '탄': 2031, '티': 2032, '패': 2033, '필': 2034, '하고': 2035, '하늘': 2036, '한숨': 2037, '해소': 2038, '해진다': 2039, '향한': 2040, '혐오': 2041, '후련': 2042, '흥미진진': 2043, '가깝': 2044, '가끔': 2045, '경의': 2046, '경이롭': 2047, '고독': 2048, '곧': 2049, '공존': 2050, '과언': 2051, '관통': 2052, '구조': 2053, '권력': 2054, '꼽': 2055, '끼친다': 2056, '나무랄': 2057, '나타내': 2058, '난해': 2059, '남음': 2060, '내안': 2061, '눈물나': 2062, '는다면': 2063, '니깐': 2064, '단면': 2065, '당해': 2066, '댓': 2067, '동료': 2068, '동요': 2069, '된다면': 2070, '들어갔': 2071, '또라이': 2072, '뚫': 2073, '레알': 2074, '레져': 2075, '마땅': 2076, '막스': 2077, '막힐': 2078, '며칠': 2079, '명분': 2080, '몸부림': 2081, '무너지': 2082, '미래': 2083, '미묘': 2084, '미약': 2085, '바랬': 2086, '박평식': 2087, '벌써': 2088, '보여줌': 2089, '뻔한': 2090, '사라지': 2091, '상영관': 2092, '상자': 2093, '서민': 2094, '세대': 2095, '술': 2096, '스러워': 2097, '시청': 2098, '십': 2099, '아라': 2100, '아버지': 2101, '안정': 2102, '애매': 2103, '어떠': 2104, '어떡': 2105, '어린아이': 2106, '어색': 2107, '억울': 2108, '업': 2109, '엔드게임': 2110, '여러분': 2111, '였을': 2112, '옴': 2113, '와중': 2114, '외톨이': 2115, '울리': 2116, '웰메이드': 2117, '잔상': 2118, '저리': 2119, '절정': 2120, '제정신': 2121, '존경': 2122, '죄책감': 2123, '중간중간': 2124, '지극히': 2125, '지루함': 2126, '진짜로': 2127, '찰떡': 2128, '창조': 2129, '찾아보': 2130, '처연': 2131, '천천히': 2132, '철저히': 2133, '쳣다': 2134, '치밀': 2135, '켠': 2136, '통': 2137, '해방감': 2138, '해준다': 2139, '향해': 2140, '후기': 2141, '흡입력': 2142, '히': 2143, '검색': 2144, '결정': 2145, '곁': 2146, '고요': 2147, '광인': 2148, '교차': 2149, '국내': 2150, '국민': 2151, '권총': 2152, '규제': 2153, '금방': 2154, '기본': 2155, '꼴': 2156, '끊이': 2157, '내게': 2158, '내요': 2159, '냄새': 2160, '넌': 2161, '넘어서': 2162, '놓치': 2163, '는다는': 2164, '다루': 2165, '대화': 2166, '더라고요': 2167, '덕': 2168, '두고두고': 2169, '드리': 2170, '들리': 2171, '듦': 2172, '딩': 2173, '따지': 2174, '땔': 2175, '라이': 2176, '루': 2177, '리버피닉스': 2178, '마찬가지': 2179, '맙시다': 2180, '매혹': 2181, '먼가': 2182, '명배우': 2183, '목소리': 2184, '몫': 2185, '묘하': 2186, '무리': 2187, '문제점': 2188, '미쳐서': 2189, '미쳐야': 2190, '밀': 2191, '박': 2192, '반부': 2193, '발자국': 2194, '복수': 2195, '본능': 2196, '볼땐': 2197, '봐왔': 2198, '빠졌': 2199, '사진': 2200, '상식': 2201, '새끼': 2202, '세여': 2203, '소개': 2204, '스마일': 2205, '시위대': 2206, '신파': 2207, '심야': 2208, '쏠': 2209, '아슬아슬': 2210, '악은': 2211, '안쓰러운': 2212, '어땠을까': 2213, '여지': 2214, '역작': 2215, '영알': 2216, '외국': 2217, '외롭': 2218, '용기': 2219, '우분': 2220, '우상': 2221, '웃음거리': 2222, '유니버스': 2223, '의식': 2224, '의외': 2225, '의지': 2226, '이렇': 2227, '이제야': 2228, '인정받': 2229, '자세히': 2230, '점대': 2231, '점주': 2232, '젖': 2233, '조카': 2234, '좌절': 2235, '지켜보': 2236, '짝': 2237, '책': 2238, '초점': 2239, '최강': 2240, '추종': 2241, '커서': 2242, '컸': 2243, '클로즈업': 2244, '피해': 2245, '하드': 2246, '할수록': 2247, '해방': 2248, '허나': 2249, '허무': 2250, '호평': 2251, '회자': 2252, '흑화': 2253, '흡연': 2254, '가리': 2255, '감정이입': 2256, '감추': 2257, '강자': 2258, '거울': 2259, '걸음걸이': 2260, '검': 2261, '경우': 2262, '계': 2263, '곱': 2264, '공격': 2265, '괴로운': 2266, '국': 2267, '그림자': 2268, '그토록': 2269, '극대': 2270, '긍정': 2271, '기대감': 2272, '김현수': 2273, '꺼내': 2274, '꾼': 2275, '끄': 2276, '끊임없이': 2277, '나빠': 2278, '날개': 2279, '납니다': 2280, '내려': 2281, '냉대': 2282, '넘어섰': 2283, '놀라웠': 2284, '단독': 2285, '달랐': 2286, '담긴': 2287, '담아내': 2288, '대악': 2289, '던져': 2290, '돌아오': 2291, '동정심': 2292, '동질감': 2293, '된다고': 2294, '두려움': 2295, '드러나': 2296, '따라서': 2297, '따윈': 2298, '립니': 2299, '마무리': 2300, '마침내': 2301, '명확': 2302, '몰라': 2303, '몰라도': 2304, '무척': 2305, '문득': 2306, '문장': 2307, '문제작': 2308, '미리': 2309, '부르': 2310, '부유층': 2311, '분명히': 2312, '분출': 2313, '비흡연자': 2314, '빙의': 2315, '빛나': 2316, '뻔하': 2317, '사연': 2318, '사용': 2319, '사장': 2320, '살린': 2321, '살인자': 2322, '생생': 2323, '선물': 2324, '선하': 2325, '세관': 2326, '손색': 2327, '수식어': 2328, '수위': 2329, '수트': 2330, '스러움': 2331, '스런': 2332, '스케일': 2333, '슬퍼서': 2334, '슴': 2335, '실화': 2336, '썼': 2337, '쏴': 2338, '쓸': 2339, '아빠': 2340, '아킨': 2341, '악해': 2342, '엄지': 2343, '여도': 2344, '여전히': 2345, '예전': 2346, '오로지': 2347, '오름': 2348, '오직': 2349, '올리': 2350, '왠만': 2351, '왤케': 2352, '외로운': 2353, '운': 2354, '울부짖': 2355, '위주': 2356, '으시': 2357, '이때': 2358, '이성': 2359, '이어지': 2360, '일부': 2361, '일으키': 2362, '자라': 2363, '장난아': 2364, '전작': 2365, '전하': 2366, '정보': 2367, '제외': 2368, '조마조마': 2369, '죄송': 2370, '준비': 2371, '줘': 2372, '줘도': 2373, '쥬': 2374, '지린': 2375, '지식': 2376, '직전': 2377, '진한': 2378, '찐': 2379, '철저': 2380, '최대': 2381, '충': 2382, '칸': 2383, '칼': 2384, '컷': 2385, '코': 2386, '클라': 2387, '틀린': 2388, '판타지': 2389, '평화': 2390, '플롯': 2391, '한방': 2392, '할로윈': 2393, '했을까': 2394, '허구': 2395, '헐리우드': 2396, '호킨스': 2397, '황제': 2398, '효과': 2399, '흘렸': 2400, '흠뻑': 2401})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SowTULg38RvR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchtext.data import Iterator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9SxJbBm8W4e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 5\n",
        "train_loader = Iterator(dataset=train_data, batch_size = batch_size)\n",
        "test_loader = Iterator(dataset=test_data, batch_size = batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5V55VTb8X4u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "ad1dcec6-bec1-4719-a106-04a720f5161d"
      },
      "source": [
        "print('훈련 데이터의 미니 배치 수 : {}'.format(len(train_loader)))\n",
        "print('테스트 데이터의 미니 배치 수 : {}'.format(len(test_loader)))"
      ],
      "execution_count": 333,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "훈련 데이터의 미니 배치 수 : 4000\n",
            "테스트 데이터의 미니 배치 수 : 2001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMViOOjx8Y9l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "outputId": "cb05a262-d85a-4f5d-c665-20dba131fc97"
      },
      "source": [
        "batch = next(iter(train_loader)) # 첫번째 미니배치\n",
        "print(batch.comment)\n",
        "print(batch.score)"
      ],
      "execution_count": 348,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[   9,    2,  741,   87,   21,   38,    5,   15,   14,    2,  123,   26,\n",
            "            2,  369,   16,   83,   19,   87,   22,  725],\n",
            "        [ 145,    3,    6,    2,  141,   19,  849,  293,  243,  673,    6, 1809,\n",
            "           55,    5,    1,    1,    1,    1,    1,    1],\n",
            "        [1566,    0,  639,    0,    3,    4,    1,    1,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1],\n",
            "        [  14,    8,   26,  101,  839,  684,   76,   16,  192,  195,   16,    5,\n",
            "           87,   11,   70,  363,  347,   11,  504,   18],\n",
            "        [  58,   73,  109,   36,  359,   34,   83,   93,    5,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1]])\n",
            "tensor([10, 10,  8, 10, 10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bM9Wc72X9bRi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODKHhTrM-Awl",
        "colab_type": "text"
      },
      "source": [
        "# 한번 분류 모델을 짜보자"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdS9-fuP-VsI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "learning_rate = 0.05\n",
        "training_epochs = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVHPuq-Z-LVy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Classifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.layer = nn.Sequential(nn.Linear(20, 32),\n",
        "                                   nn.ReLU(),\n",
        "                                   nn.Linear(32, 32),\n",
        "                                   nn.ReLU(),\n",
        "                                   nn.Linear(32, 11))\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer(x)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6OM6LEE_gqL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Classifier()\n",
        "criterion = torch.nn.CrossEntropyLoss()    # 비용 함수에 소프트맥스 함수 포함되어져 있음.\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GotKb8X_pcg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5d0a93df-d249-4163-cf03-c16817194f75"
      },
      "source": [
        "total_batch = len(train_loader)\n",
        "print('총 배치의 수 : {}'.format(total_batch))"
      ],
      "execution_count": 384,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "총 배치의 수 : 4000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_X-PnBCh_7iI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ea507e51-d5a1-499d-e1f4-6a71bf643c09"
      },
      "source": [
        "for epoch in range(training_epochs):\n",
        "    avg_cost = 0\n",
        "\n",
        "    for X, Y in train_loader: # 미니 배치 단위로 꺼내온다. X는 미니 배치, Y느 ㄴ레이블.\n",
        "        # image is already size of (28x28), no reshape\n",
        "        # label is not one-hot encoded\n",
        "        X = X.to(torch.float)\n",
        "        Y = Y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        hypothesis = model(X)\n",
        "        cost = criterion(hypothesis, Y)\n",
        "        cost.backward()\n",
        "        optimizer.step()\n",
        "        print(cost)\n",
        "        avg_cost += cost / total_batch\n",
        "\n",
        "    print('[Epoch: {:>4}] cost = {:>.9}'.format(epoch + 1, avg_cost))"
      ],
      "execution_count": 386,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43m스트리밍 출력 내용이 길어서 마지막 5000줄이 삭제되었습니다.\u001b[0m\n",
            "tensor(0.2001, grad_fn=<NllLossBackward>)\n",
            "tensor(2.1353, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6331, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1467, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4686, grad_fn=<NllLossBackward>)\n",
            "tensor(2.4034, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0847, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2176, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2086, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2215, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2104, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2233, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1730, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2252, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2253, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0529, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6849, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7180, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7180, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7168, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4880, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6921, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6926, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6922, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6910, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2230, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2159, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7184, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2245, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2239, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3799, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6897, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4331, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7134, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6904, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7124, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2113, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6914, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5114, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2067, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1970, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0220, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6884, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2059, grad_fn=<NllLossBackward>)\n",
            "tensor(2.5115, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0370, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2118, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2133, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6581, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6934, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7240, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0218, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7232, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0097, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2347, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6832, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6837, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7218, grad_fn=<NllLossBackward>)\n",
            "tensor(2.4183, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2430, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2463, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6875, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6877, grad_fn=<NllLossBackward>)\n",
            "tensor(2.0626, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2529, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6864, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4226, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2582, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2586, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7252, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2551, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2515, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6800, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7261, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2378, grad_fn=<NllLossBackward>)\n",
            "tensor(2.5940, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2302, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2267, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6780, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1890, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2160, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3969, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0411, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1450, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1421, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7386, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2046, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2027, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6734, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6729, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1954, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1925, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5166, grad_fn=<NllLossBackward>)\n",
            "tensor(2.6540, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1895, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7568, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1372, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0113, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2229, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2022, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6567, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5695, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2112, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6450, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2185, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6509, grad_fn=<NllLossBackward>)\n",
            "tensor(2.0063, grad_fn=<NllLossBackward>)\n",
            "tensor(1.7198, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0116, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2482, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1249, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2580, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1694, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2610, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2599, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2568, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0003, grad_fn=<NllLossBackward>)\n",
            "tensor(2.3748, grad_fn=<NllLossBackward>)\n",
            "tensor(1.7865, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4865, grad_fn=<NllLossBackward>)\n",
            "tensor(1.8851, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7686, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6620, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7707, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2655, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2660, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6664, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2629, grad_fn=<NllLossBackward>)\n",
            "tensor(2.4636, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2613, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2610, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7647, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1774, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0537, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1601, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1774, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9772, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7509, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7482, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2544, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7411, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7369, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1397, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6899, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6991, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1823, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2608, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7082, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1495, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6977, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2730, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2740, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1365, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6795, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0196, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6720, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7373, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2730, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2702, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2655, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1415, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7414, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4241, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2496, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0951, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6814, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2401, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2362, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2311, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0816, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2191, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4509, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6655, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9918, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2061, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0557, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1997, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1432, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1976, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7481, grad_fn=<NllLossBackward>)\n",
            "tensor(1.7766, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1416, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2015, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6202, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2073, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2040, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2127, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1969, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2176, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2190, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2187, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6575, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2155, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6562, grad_fn=<NllLossBackward>)\n",
            "tensor(1.9848, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2098, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2075, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2041, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2122, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6560, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3188, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1959, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6787, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0083, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1384, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5583, grad_fn=<NllLossBackward>)\n",
            "tensor(1.9362, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7471, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6607, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6620, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7398, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7375, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2224, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1754, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1117, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1241, grad_fn=<NllLossBackward>)\n",
            "tensor(1.7886, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1561, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2449, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7267, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2518, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7245, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6699, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1375, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7199, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7177, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7148, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1618, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2629, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6823, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0383, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2628, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6923, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4653, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1327, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6841, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6820, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1205, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7032, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2643, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6744, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6724, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1539, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4315, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2668, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0229, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0173, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0685, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6655, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7186, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1160, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1147, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5536, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5483, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6603, grad_fn=<NllLossBackward>)\n",
            "tensor(2.2249, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7344, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3020, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6632, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3072, grad_fn=<NllLossBackward>)\n",
            "tensor(1.7830, grad_fn=<NllLossBackward>)\n",
            "tensor(2.0011, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9973, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0118, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3254, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9917, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6645, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3285, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7571, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3216, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6597, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7568, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3028, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1150, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6553, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2836, grad_fn=<NllLossBackward>)\n",
            "tensor(1.7008, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3225, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2185, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6501, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2702, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5900, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6464, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2557, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2607, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2565, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2507, grad_fn=<NllLossBackward>)\n",
            "tensor(1.7060, grad_fn=<NllLossBackward>)\n",
            "tensor(1.7022, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2240, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6442, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2071, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6464, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7758, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6482, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2185, grad_fn=<NllLossBackward>)\n",
            "tensor(1.7186, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6510, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6517, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2117, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7746, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6643, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2157, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3288, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6527, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2216, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2240, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7586, grad_fn=<NllLossBackward>)\n",
            "tensor(1.8324, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2267, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7503, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6604, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0974, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7439, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2300, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2298, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0987, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2283, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0735, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2253, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7393, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2196, grad_fn=<NllLossBackward>)\n",
            "tensor(1.9337, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7369, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6497, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6659, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6654, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2101, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2094, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5332, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1200, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7331, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1136, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2129, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2144, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3486, grad_fn=<NllLossBackward>)\n",
            "tensor(2.0584, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0591, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7378, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2146, grad_fn=<NllLossBackward>)\n",
            "tensor(1.8679, grad_fn=<NllLossBackward>)\n",
            "tensor(2.1095, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0154, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6644, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2168, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2164, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2145, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5340, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2030, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2105, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2095, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7371, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5057, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7342, grad_fn=<NllLossBackward>)\n",
            "tensor(1.7034, grad_fn=<NllLossBackward>)\n",
            "tensor(1.7412, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2070, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2084, grad_fn=<NllLossBackward>)\n",
            "tensor(1.7485, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2096, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2093, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2077, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2507, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9447, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2037, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2019, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1990, grad_fn=<NllLossBackward>)\n",
            "tensor(1.7202, grad_fn=<NllLossBackward>)\n",
            "tensor(1.9871, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1943, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1941, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2572, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7270, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7264, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1943, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7252, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1934, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1919, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1735, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2584, grad_fn=<NllLossBackward>)\n",
            "tensor(2.3293, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7156, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7299, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2379, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2282, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2168, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6942, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9824, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2245, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2410, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6856, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2520, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9703, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7258, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7249, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6833, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7218, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2623, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2610, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2577, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1792, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1739, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6857, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0147, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2341, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2286, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6868, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7142, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5056, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7141, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6910, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6921, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1807, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6903, grad_fn=<NllLossBackward>)\n",
            "tensor(2.5263, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1656, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7204, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2128, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1175, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0166, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6760, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2169, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6733, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9746, grad_fn=<NllLossBackward>)\n",
            "tensor(1.7948, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2161, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6701, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7434, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6693, grad_fn=<NllLossBackward>)\n",
            "tensor(1.9010, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7467, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7468, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7457, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2690, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2204, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1916, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7311, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2259, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2263, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4783, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9794, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6691, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2297, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7093, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2331, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7032, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4817, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4692, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7075, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1810, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1651, grad_fn=<NllLossBackward>)\n",
            "tensor(1.9037, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1552, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4461, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2600, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5498, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7037, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2749, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1304, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7034, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7012, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7060, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2875, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5367, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2871, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1258, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2849, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2824, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1212, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2754, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2710, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0925, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2587, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1530, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2464, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1589, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6968, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1538, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1457, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7047, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0623, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4918, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0556, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2373, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7244, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1550, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2379, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6623, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0520, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0828, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2377, grad_fn=<NllLossBackward>)\n",
            "tensor(2.0108, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2398, grad_fn=<NllLossBackward>)\n",
            "tensor(2.6038, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1563, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2482, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0458, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2521, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2515, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6547, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6546, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4151, grad_fn=<NllLossBackward>)\n",
            "tensor(2.6110, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2472, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2477, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2891, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6512, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1768, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7708, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7711, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3111, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4629, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2407, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6539, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4510, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7680, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6554, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7676, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7664, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7640, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0877, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6581, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1824, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4089, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0305, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0197, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2483, grad_fn=<NllLossBackward>)\n",
            "tensor(1.9399, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0142, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2543, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2547, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2531, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2497, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0993, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6718, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0211, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6258, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6712, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2365, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2342, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2304, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2254, grad_fn=<NllLossBackward>)\n",
            "tensor(1.7619, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7631, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2155, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1381, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2115, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2093, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2258, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2258, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1425, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0956, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9876, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6689, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7550, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2676, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2162, grad_fn=<NllLossBackward>)\n",
            "tensor(2.7338, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2179, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2183, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7558, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6701, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7550, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2148, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2129, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2097, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2054, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0500, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2356, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1935, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1902, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1850, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6853, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0316, grad_fn=<NllLossBackward>)\n",
            "tensor(1.7771, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6836, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2579, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2555, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1889, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1912, grad_fn=<NllLossBackward>)\n",
            "tensor(2.2294, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7593, grad_fn=<NllLossBackward>)\n",
            "tensor(1.8149, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1993, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2008, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2010, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1998, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1975, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1942, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1900, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1852, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6942, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6955, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7467, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1691, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6981, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5055, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6976, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1618, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6949, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1598, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2911, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1587, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3619, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1591, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6205, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6861, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0887, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5751, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1669, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1686, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2657, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7573, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1761, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4858, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1830, grad_fn=<NllLossBackward>)\n",
            "tensor(2.6521, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1926, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6645, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2009, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6623, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7586, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7585, grad_fn=<NllLossBackward>)\n",
            "tensor(2.3010, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2003, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2223, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2267, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6100, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9860, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6026, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1649, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2532, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1528, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2640, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1049, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2696, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2694, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6601, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6600, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9940, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0580, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6577, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1496, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0474, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2647, grad_fn=<NllLossBackward>)\n",
            "tensor(1.7605, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1432, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2648, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1155, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7733, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1261, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6477, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6483, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6484, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6479, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9801, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7802, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3209, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3204, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4805, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3148, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3351, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3020, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1449, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3021, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2978, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7877, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7865, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6284, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1115, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2663, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6686, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1197, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5617, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2501, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6353, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7642, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7608, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2372, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2329, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7488, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6505, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7413, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2147, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6588, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2061, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0943, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7285, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0577, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6716, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1872, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0799, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1806, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7237, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0428, grad_fn=<NllLossBackward>)\n",
            "tensor(1.9127, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3945, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7230, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7220, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5749, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1695, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3763, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1702, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7119, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1693, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7082, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7057, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2730, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2675, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6964, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3112, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7415, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6876, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1813, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1833, grad_fn=<NllLossBackward>)\n",
            "tensor(2.4315, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7405, grad_fn=<NllLossBackward>)\n",
            "tensor(1.8241, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1944, grad_fn=<NllLossBackward>)\n",
            "tensor(1.8421, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6856, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2039, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6875, grad_fn=<NllLossBackward>)\n",
            "tensor(1.9709, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1622, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2195, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7448, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1389, grad_fn=<NllLossBackward>)\n",
            "tensor(2.2230, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2448, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1753, grad_fn=<NllLossBackward>)\n",
            "tensor(1.9178, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0613, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7471, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7458, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1340, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3093, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4634, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6986, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4915, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3399, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7447, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7436, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4726, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0952, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7364, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7331, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3558, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1326, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3485, grad_fn=<NllLossBackward>)\n",
            "tensor(2.0882, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4949, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7074, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7269, grad_fn=<NllLossBackward>)\n",
            "tensor(1.7921, grad_fn=<NllLossBackward>)\n",
            "tensor(1.7143, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3283, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3244, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3180, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1544, grad_fn=<NllLossBackward>)\n",
            "tensor(2.4397, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7282, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2939, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4178, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1623, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6993, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7009, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7014, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7132, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7015, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7010, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7112, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1687, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1639, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7030, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7002, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7065, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6939, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6907, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4768, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2589, grad_fn=<NllLossBackward>)\n",
            "tensor(1.8806, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2622, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5008, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2655, grad_fn=<NllLossBackward>)\n",
            "tensor(1.9645, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7334, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2711, grad_fn=<NllLossBackward>)\n",
            "tensor(1.7168, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0619, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1305, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4532, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6700, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2802, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5580, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2814, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7373, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6727, grad_fn=<NllLossBackward>)\n",
            "tensor(1.9252, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2811, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6717, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6703, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0931, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2857, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1260, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0454, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2846, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1254, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4551, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2870, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6545, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2860, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5360, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2381, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7578, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7549, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7509, grad_fn=<NllLossBackward>)\n",
            "tensor(2.2549, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2758, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1274, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0890, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6675, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7286, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7255, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7216, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7171, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6816, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4092, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7050, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4914, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1373, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6968, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6972, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2575, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0863, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2546, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6881, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7043, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2449, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0727, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6250, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1546, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1737, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6859, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2436, grad_fn=<NllLossBackward>)\n",
            "tensor(1.9436, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2485, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6857, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2517, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6829, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6808, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2496, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6757, grad_fn=<NllLossBackward>)\n",
            "tensor(1.7555, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7155, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7175, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2426, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0918, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6653, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6641, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2330, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2295, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2246, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2187, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1769, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2078, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2027, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7335, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6603, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1878, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6616, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0444, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7391, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7396, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1588, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2324, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7382, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2247, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1776, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0409, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1814, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1819, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6627, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6626, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1811, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1801, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6613, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2160, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7327, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2861, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0297, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1822, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2021, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6619, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6617, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1907, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1863, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7168, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1976, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1989, grad_fn=<NllLossBackward>)\n",
            "tensor(2.1598, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7082, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7039, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2066, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1326, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2104, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1704, grad_fn=<NllLossBackward>)\n",
            "tensor(1.8093, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2181, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2201, grad_fn=<NllLossBackward>)\n",
            "tensor(1.7866, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6783, grad_fn=<NllLossBackward>)\n",
            "tensor(2.6983, grad_fn=<NllLossBackward>)\n",
            "tensor(1.9328, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2316, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2341, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6729, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1258, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6919, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5507, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2048, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4935, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6993, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7009, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6662, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5934, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5117, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4745, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2828, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1173, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6751, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1114, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4515, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6805, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3224, grad_fn=<NllLossBackward>)\n",
            "tensor(2.0229, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3338, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3370, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0621, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3376, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0628, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6236, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1050, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7182, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3375, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7118, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3315, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6864, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6995, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6872, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6925, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6579, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2964, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6036, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6912, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2426, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2759, grad_fn=<NllLossBackward>)\n",
            "tensor(2.3624, grad_fn=<NllLossBackward>)\n",
            "tensor(2.0134, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6829, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2753, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2747, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6848, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6882, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5131, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1292, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6805, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1121, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1315, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6782, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1412, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6777, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2665, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2646, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6747, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7036, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6723, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0908, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7080, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1267, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6651, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7122, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2520, grad_fn=<NllLossBackward>)\n",
            "tensor(2.0409, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6620, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6622, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2556, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1358, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2534, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7117, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6612, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6610, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0786, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5393, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4817, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1254, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1980, grad_fn=<NllLossBackward>)\n",
            "[Epoch:    9] cost = 0.831118762\n",
            "tensor(0.2622, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6460, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2716, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1333, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1046, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7377, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1268, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2784, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4950, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2736, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7352, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2639, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6441, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7298, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7277, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6473, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6484, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2338, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7212, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2243, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2187, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7167, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6561, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6576, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1979, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1932, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1873, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7142, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1822, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1789, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1749, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6690, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1666, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7139, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1590, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1552, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6790, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1477, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7180, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6847, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6857, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4147, grad_fn=<NllLossBackward>)\n",
            "tensor(2.3033, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1379, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6761, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2626, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1420, grad_fn=<NllLossBackward>)\n",
            "tensor(2.2105, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7158, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2128, grad_fn=<NllLossBackward>)\n",
            "tensor(1.7230, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7155, grad_fn=<NllLossBackward>)\n",
            "tensor(1.7067, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1800, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1203, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1988, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6447, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1498, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7271, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2329, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0277, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6311, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2544, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2591, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2611, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7460, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6227, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6216, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7493, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7495, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6197, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2546, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2513, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2462, grad_fn=<NllLossBackward>)\n",
            "tensor(1.7550, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2371, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2329, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7323, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7278, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2181, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2698, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2076, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6419, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7092, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7064, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7029, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1864, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6601, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6632, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6652, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1762, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1736, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1901, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6912, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1923, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1695, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2027, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6744, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6751, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1754, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1739, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6767, grad_fn=<NllLossBackward>)\n",
            "tensor(2.1441, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6767, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1956, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2007, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2040, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1306, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6547, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0928, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6844, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6860, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6453, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6436, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2334, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6397, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6374, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0319, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7017, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7046, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5474, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6277, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2982, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2620, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7096, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0719, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0694, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3451, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2794, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2844, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6283, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6273, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2882, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6178, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2855, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6208, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2789, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2734, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4249, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6133, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2613, grad_fn=<NllLossBackward>)\n",
            "tensor(2.3061, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7348, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6087, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2469, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2915, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7367, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6087, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2678, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2484, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7358, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2016, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2118, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2068, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5681, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1993, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6216, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0505, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1943, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6213, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6205, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0466, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1936, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7475, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1942, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7509, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7510, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0368, grad_fn=<NllLossBackward>)\n",
            "tensor(2.0577, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7513, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1904, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2049, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6100, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7522, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2099, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2920, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7476, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6139, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7402, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1715, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0241, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7307, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6717, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2240, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1224, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2286, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6309, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6323, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6330, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0332, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1095, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1888, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5245, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0930, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0860, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2714, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5619, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6346, grad_fn=<NllLossBackward>)\n",
            "tensor(1.9905, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3000, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5347, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3091, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7155, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7139, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3109, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6550, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3042, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1323, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7017, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6574, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0359, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6975, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6572, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6968, grad_fn=<NllLossBackward>)\n",
            "tensor(1.8742, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6567, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6557, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3417, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3353, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2562, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6511, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2471, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1133, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6476, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5175, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2340, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0555, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7187, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7210, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1311, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2312, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1017, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2499, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7238, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4648, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2467, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2319, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1335, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2338, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7294, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6375, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2336, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2325, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6379, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2280, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6376, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2214, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6367, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6359, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1621, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5181, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6320, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2115, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2108, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2087, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2053, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2009, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6274, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3904, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1164, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7635, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6294, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6374, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0824, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7702, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6271, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6599, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1870, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3425, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6199, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1961, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7789, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6169, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2002, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5141, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7811, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6152, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6148, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6923, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6129, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0927, grad_fn=<NllLossBackward>)\n",
            "tensor(1.9687, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5351, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6083, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7978, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7994, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2377, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7989, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2393, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2379, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4874, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1719, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6141, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7862, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4599, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2283, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7797, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2257, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6226, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7719, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4405, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6255, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7684, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7672, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2259, grad_fn=<NllLossBackward>)\n",
            "tensor(1.7007, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2263, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2254, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2228, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2188, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7479, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2093, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7419, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1992, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6473, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1894, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1843, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6555, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7311, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1703, grad_fn=<NllLossBackward>)\n",
            "tensor(1.9284, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7274, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1616, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1591, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6762, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2035, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2450, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1545, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2800, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2395, grad_fn=<NllLossBackward>)\n",
            "tensor(2.2618, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1616, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6760, grad_fn=<NllLossBackward>)\n",
            "tensor(2.1047, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1739, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1783, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1812, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5713, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6674, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6653, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1912, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1799, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2549, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1983, grad_fn=<NllLossBackward>)\n",
            "tensor(1.7002, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2018, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5870, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6160, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1319, grad_fn=<NllLossBackward>)\n",
            "tensor(2.8790, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5768, grad_fn=<NllLossBackward>)\n",
            "tensor(2.2906, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2355, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2418, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5450, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5908, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1813, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6586, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6604, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7339, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2729, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1254, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6328, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4282, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2397, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2869, grad_fn=<NllLossBackward>)\n",
            "tensor(1.9369, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7431, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1982, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6750, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0256, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2930, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7395, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1861, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2883, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6110, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2844, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2810, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2756, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1493, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2640, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0574, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7157, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2468, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2403, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7057, grad_fn=<NllLossBackward>)\n",
            "tensor(2.1393, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0338, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6820, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2055, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2034, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7019, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2334, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7116, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2370, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4932, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7018, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1733, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7037, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4683, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1691, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6961, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2584, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2607, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1670, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6906, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2640, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2631, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1791, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6869, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6035, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1151, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2575, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2579, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2562, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0959, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2488, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6755, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2388, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2329, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1659, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7211, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2178, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2130, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2072, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6720, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6067, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2386, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1888, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7239, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2653, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6803, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1798, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7170, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1769, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1580, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1729, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2507, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2342, grad_fn=<NllLossBackward>)\n",
            "tensor(4.2218, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0608, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6985, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6994, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6994, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1979, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2013, grad_fn=<NllLossBackward>)\n",
            "tensor(2.0534, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6975, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6938, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6304, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2214, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2246, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6956, grad_fn=<NllLossBackward>)\n",
            "tensor(2.0748, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6927, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2352, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1646, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2404, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7004, grad_fn=<NllLossBackward>)\n",
            "tensor(2.0849, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5323, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1374, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2596, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1321, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1219, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4678, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1662, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0899, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6982, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0843, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6999, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5525, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0917, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2947, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2928, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7023, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7014, grad_fn=<NllLossBackward>)\n",
            "tensor(1.9300, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2801, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0956, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2745, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4986, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2666, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2617, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7045, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7032, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7013, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2399, grad_fn=<NllLossBackward>)\n",
            "tensor(1.8207, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2301, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2250, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6942, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0000, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2092, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2038, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1977, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7463, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1857, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1798, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7538, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1685, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7568, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2550, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7580, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1547, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7094, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1507, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7100, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1468, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6457, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1441, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7609, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7110, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1419, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1410, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1395, grad_fn=<NllLossBackward>)\n",
            "tensor(1.7416, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1370, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7121, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1354, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7105, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1337, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1326, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7075, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1300, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1285, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1267, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1530, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7825, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1216, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0407, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7085, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1185, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4598, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1180, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7851, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1279, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7119, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7776, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6830, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1237, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7125, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1108, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1297, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7581, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1327, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1337, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1339, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1334, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3349, grad_fn=<NllLossBackward>)\n",
            "tensor(1.8898, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1361, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7118, grad_fn=<NllLossBackward>)\n",
            "tensor(1.8793, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7023, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7423, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6913, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6614, grad_fn=<NllLossBackward>)\n",
            "tensor(2.0472, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2379, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1862, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6629, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2028, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7455, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7463, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1056, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2251, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2277, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2284, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2273, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2246, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1740, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2187, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1784, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5327, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2707, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2171, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6517, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2180, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2169, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6532, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7341, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2105, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2074, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2033, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7302, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1940, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0762, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1518, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1521, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6667, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1775, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7304, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7306, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1726, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7289, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0751, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1347, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1296, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7243, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4022, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1647, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1634, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1613, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1586, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6956, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7218, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7216, grad_fn=<NllLossBackward>)\n",
            "tensor(2.1872, grad_fn=<NllLossBackward>)\n",
            "tensor(2.8301, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2518, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7009, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1651, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1688, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6936, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2085, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7178, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1819, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7195, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7193, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1899, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1912, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1911, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0904, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6793, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7174, grad_fn=<NllLossBackward>)\n",
            "tensor(2.1197, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2051, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1938, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0551, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0548, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1709, grad_fn=<NllLossBackward>)\n",
            "tensor(2.0091, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6832, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6652, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6791, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7106, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2423, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6759, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4893, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6750, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1256, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6744, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5566, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2871, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6748, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3394, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7238, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7238, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0916, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3103, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3105, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3077, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1152, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4473, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0973, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2909, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2867, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2805, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2726, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7013, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6825, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5294, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2406, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1357, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6831, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2782, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2178, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2123, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2059, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6793, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1642, grad_fn=<NllLossBackward>)\n",
            "tensor(2.0455, grad_fn=<NllLossBackward>)\n",
            "tensor(2.2635, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1890, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0106, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7260, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7273, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1893, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1393, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7282, grad_fn=<NllLossBackward>)\n",
            "tensor(2.0950, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1895, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6758, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1917, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1916, grad_fn=<NllLossBackward>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1919, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7245, grad_fn=<NllLossBackward>)\n",
            "tensor(2.1291, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7213, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2003, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6820, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1866, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2151, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2001, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2249, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2284, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5564, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2328, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6882, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2343, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6878, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6868, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0779, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2301, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7022, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2251, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2213, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6153, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2156, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2235, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6763, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2091, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2274, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7169, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2042, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2022, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6736, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1965, grad_fn=<NllLossBackward>)\n",
            "tensor(1.7200, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6739, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1934, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1924, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1903, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2000, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1863, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2422, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2012, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6753, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1877, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7038, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1889, grad_fn=<NllLossBackward>)\n",
            "tensor(2.2041, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0988, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1892, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1883, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6962, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6950, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1909, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1994, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0952, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6906, grad_fn=<NllLossBackward>)\n",
            "tensor(2.1298, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6912, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6904, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2069, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6879, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2125, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6855, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1532, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2172, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6794, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1344, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2218, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2226, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2218, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6636, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2174, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2141, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1593, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2076, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7174, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2015, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1232, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6524, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1911, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5813, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7277, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1877, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1868, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7333, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1831, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1107, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7361, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1071, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7377, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0959, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6680, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7385, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2943, grad_fn=<NllLossBackward>)\n",
            "tensor(1.9961, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6319, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7382, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6972, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1409, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2353, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2412, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2446, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2457, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1187, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6317, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1272, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4934, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7394, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6921, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6362, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1164, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6401, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2652, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6424, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2678, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7321, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2651, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5431, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1134, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6482, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5025, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6530, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1747, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1627, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1922, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2876, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0848, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2947, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2960, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2945, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2904, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2842, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6869, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6833, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6793, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6750, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2513, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1438, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1391, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1316, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7055, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6585, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7095, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2208, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1503, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3063, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1542, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2118, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2161, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1504, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1474, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6583, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1446, grad_fn=<NllLossBackward>)\n",
            "tensor(2.9048, grad_fn=<NllLossBackward>)\n",
            "tensor(1.7311, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6997, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1075, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6751, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2963, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0600, grad_fn=<NllLossBackward>)\n",
            "tensor(1.9362, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1488, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1551, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3000, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6373, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3119, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5524, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3206, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1452, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0511, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6899, grad_fn=<NllLossBackward>)\n",
            "tensor(1.9414, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3306, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3292, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6946, grad_fn=<NllLossBackward>)\n",
            "tensor(1.8778, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7202, grad_fn=<NllLossBackward>)\n",
            "tensor(1.9209, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1211, grad_fn=<NllLossBackward>)\n",
            "tensor(2.2895, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3258, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7246, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2598, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7246, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7234, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0612, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4553, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1208, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3138, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7186, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7183, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4288, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7212, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7157, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7143, grad_fn=<NllLossBackward>)\n",
            "tensor(2.0495, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5521, grad_fn=<NllLossBackward>)\n",
            "tensor(2.2759, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2125, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3209, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1478, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7530, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6985, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4881, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3367, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1192, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3407, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3399, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3359, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3291, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7639, grad_fn=<NllLossBackward>)\n",
            "tensor(1.8344, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1613, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3021, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5090, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0071, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2852, grad_fn=<NllLossBackward>)\n",
            "tensor(1.9102, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1355, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7478, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1276, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6866, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2627, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6890, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1779, grad_fn=<NllLossBackward>)\n",
            "tensor(1.9415, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0091, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7428, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2483, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1866, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2447, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6911, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9931, grad_fn=<NllLossBackward>)\n",
            "tensor(1.9437, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2389, grad_fn=<NllLossBackward>)\n",
            "tensor(1.9088, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1400, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7457, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6868, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2529, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2541, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6814, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6792, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1824, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6739, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2538, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0841, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1779, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6615, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1715, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9803, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7769, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2686, grad_fn=<NllLossBackward>)\n",
            "tensor(1.9393, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2721, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1400, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2728, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2704, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2660, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9845, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2944, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2503, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7680, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0702, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0403, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2356, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6584, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7583, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2253, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6613, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5085, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2156, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6649, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7505, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7488, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4274, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7444, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2062, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4480, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6869, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2098, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7352, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3046, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6798, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2104, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2103, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6815, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2014, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5689, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6671, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6804, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6790, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4241, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4677, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2390, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6741, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6731, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2520, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7332, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6696, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7348, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1460, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1427, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1378, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1316, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1242, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2838, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6692, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7301, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6695, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0394, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4591, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6670, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7358, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3238, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3257, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7379, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6615, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6599, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3162, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7343, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3046, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2966, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6503, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2779, grad_fn=<NllLossBackward>)\n",
            "tensor(2.5326, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7224, grad_fn=<NllLossBackward>)\n",
            "tensor(1.9916, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2602, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5634, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2600, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2595, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2569, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5227, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2499, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2455, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2398, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6451, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2281, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6908, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2170, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1906, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6744, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6885, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1679, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6799, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1899, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1862, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1843, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1817, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1990, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2788, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6924, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2051, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1758, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6895, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1759, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6897, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0723, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6886, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1742, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1732, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6861, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6985, grad_fn=<NllLossBackward>)\n",
            "tensor(1.7301, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1714, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6109, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1750, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1763, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7058, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1546, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5644, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2008, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1571, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7102, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7108, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6067, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2017, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7083, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7065, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2121, grad_fn=<NllLossBackward>)\n",
            "tensor(1.7557, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1205, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1459, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5971, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2578, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1266, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6975, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2528, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2567, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6718, grad_fn=<NllLossBackward>)\n",
            "tensor(2.3939, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0804, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2690, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5341, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0991, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7076, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1008, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0546, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6714, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2974, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6694, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2988, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7212, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5301, grad_fn=<NllLossBackward>)\n",
            "tensor(2.6347, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1521, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3027, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3050, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7260, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0972, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7229, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5050, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4994, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0935, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0929, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3005, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3007, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0931, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0502, grad_fn=<NllLossBackward>)\n",
            "tensor(1.8210, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6995, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0662, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2934, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2893, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6929, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4678, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6898, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7131, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6877, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2640, grad_fn=<NllLossBackward>)\n",
            "tensor(1.9219, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1461, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7181, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2596, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1206, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2585, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2567, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2532, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1553, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2451, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2407, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7157, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7146, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2255, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7110, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2545, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7067, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6795, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7018, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6986, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1865, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2096, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7021, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2108, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6892, grad_fn=<NllLossBackward>)\n",
            "tensor(2.2100, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6856, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2226, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0441, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6881, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6882, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6882, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2344, grad_fn=<NllLossBackward>)\n",
            "tensor(2.1163, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6859, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4788, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5676, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6932, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2587, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6788, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6771, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2694, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7027, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7035, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6709, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0799, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4821, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7050, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2647, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1792, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2566, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6689, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7038, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0558, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2363, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6704, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7042, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2209, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0571, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7047, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2061, grad_fn=<NllLossBackward>)\n",
            "tensor(1.7150, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1976, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2290, grad_fn=<NllLossBackward>)\n",
            "tensor(2.2308, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7072, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2243, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0372, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6373, grad_fn=<NllLossBackward>)\n",
            "tensor(2.5289, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6944, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0272, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6875, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7100, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6818, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2225, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2247, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2252, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2239, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7295, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2187, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6286, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2129, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6745, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2070, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2033, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1986, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1620, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2867, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6768, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2257, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4926, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2842, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1970, grad_fn=<NllLossBackward>)\n",
            "tensor(1.7432, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1159, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7295, grad_fn=<NllLossBackward>)\n",
            "tensor(1.8664, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2196, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2219, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2279, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2307, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2314, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6404, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7067, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2353, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1116, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1507, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2375, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2373, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1574, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2356, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5930, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6951, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1483, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0504, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1450, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6908, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5854, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6918, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6883, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6929, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1152, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2705, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6931, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2761, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2760, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6869, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2710, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5219, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6904, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6914, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6913, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6782, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6902, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6768, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6890, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2610, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2578, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6032, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5333, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6746, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6851, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2453, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6749, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2393, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6841, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6746, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2276, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6837, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2187, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5264, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6254, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2072, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6794, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1565, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6811, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2035, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2024, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6490, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1992, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1654, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6796, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1972, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6771, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0996, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1942, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6734, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1905, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1879, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1696, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6699, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7003, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6745, grad_fn=<NllLossBackward>)\n",
            "tensor(2.6325, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2107, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7046, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6572, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6696, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1879, grad_fn=<NllLossBackward>)\n",
            "tensor(1.9440, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1909, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1528, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1833, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1959, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1775, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6671, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6653, grad_fn=<NllLossBackward>)\n",
            "tensor(2.0753, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6616, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6605, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2261, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2307, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6574, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1165, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6553, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2387, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6527, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1396, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2395, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1395, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6292, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2454, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6468, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6462, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2124, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5214, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2603, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2623, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1283, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2607, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5875, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1020, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7268, grad_fn=<NllLossBackward>)\n",
            "tensor(1.8607, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2510, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2485, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2443, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5665, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6596, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2049, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2307, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6664, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5361, grad_fn=<NllLossBackward>)\n",
            "tensor(2.0306, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1528, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6781, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1388, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6831, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5951, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6867, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0501, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2593, grad_fn=<NllLossBackward>)\n",
            "tensor(2.0809, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6920, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6925, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2149, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5323, grad_fn=<NllLossBackward>)\n",
            "tensor(2.0271, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1537, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3014, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6976, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3088, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3088, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3060, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1111, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7041, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2946, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1071, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4135, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6948, grad_fn=<NllLossBackward>)\n",
            "tensor(2.2375, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6918, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2786, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2760, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7018, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2669, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6872, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2552, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4958, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2437, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7022, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6829, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2278, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6459, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2205, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6815, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2150, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2112, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7054, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7052, grad_fn=<NllLossBackward>)\n",
            "tensor(2.0364, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1990, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1978, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1405, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6963, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1976, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1915, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6877, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1272, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6812, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6778, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7151, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6710, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6677, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1910, grad_fn=<NllLossBackward>)\n",
            "tensor(2.1007, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7328, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1925, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2006, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2032, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1827, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6436, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7442, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2123, grad_fn=<NllLossBackward>)\n",
            "tensor(1.8223, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2840, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0764, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0743, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2181, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6426, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2164, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0737, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7456, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2146, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1770, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2137, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2126, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2101, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2855, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2047, grad_fn=<NllLossBackward>)\n",
            "tensor(2.2282, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2020, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7328, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7281, grad_fn=<NllLossBackward>)\n",
            "tensor(2.0947, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2018, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1376, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2035, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6706, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1538, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1197, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2012, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1793, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6784, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1962, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1938, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6819, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1877, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1841, grad_fn=<NllLossBackward>)\n",
            "tensor(2.0670, grad_fn=<NllLossBackward>)\n",
            "tensor(1.7727, grad_fn=<NllLossBackward>)\n",
            "tensor(1.7678, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1864, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1900, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1921, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2060, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2426, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7155, grad_fn=<NllLossBackward>)\n",
            "tensor(2.2627, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2075, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2104, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7042, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7014, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6854, grad_fn=<NllLossBackward>)\n",
            "tensor(3.5527, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1295, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6876, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0839, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6353, grad_fn=<NllLossBackward>)\n",
            "tensor(2.4381, grad_fn=<NllLossBackward>)\n",
            "tensor(1.9581, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1860, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7054, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1101, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1015, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6897, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2987, grad_fn=<NllLossBackward>)\n",
            "tensor(1.8457, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6847, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1658, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1017, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1815, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0950, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7605, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4962, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3658, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1775, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1707, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6919, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3633, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3573, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3483, grad_fn=<NllLossBackward>)\n",
            "tensor(1.7607, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3309, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6819, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6792, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2030, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0322, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7529, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5593, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6764, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0924, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6779, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6780, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7455, grad_fn=<NllLossBackward>)\n",
            "tensor(1.9511, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6782, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0675, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0003, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0551, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6799, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5800, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2659, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1655, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2654, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2628, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2583, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2524, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2621, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1448, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5350, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4815, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1378, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6851, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7490, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2353, grad_fn=<NllLossBackward>)\n",
            "tensor(2.0984, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6825, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6802, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6775, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6743, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7582, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2566, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7607, grad_fn=<NllLossBackward>)\n",
            "tensor(2.0441, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2606, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2615, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0466, grad_fn=<NllLossBackward>)\n",
            "tensor(1.9401, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6689, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7499, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0778, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1521, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1472, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2762, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2138, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6715, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0573, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7424, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0475, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6192, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7428, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6733, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0293, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0928, grad_fn=<NllLossBackward>)\n",
            "tensor(1.7009, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3442, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1449, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6710, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3647, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1151, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3642, grad_fn=<NllLossBackward>)\n",
            "tensor(2.4558, grad_fn=<NllLossBackward>)\n",
            "tensor(1.8657, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3604, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7748, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0770, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7716, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3521, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5463, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3420, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6610, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7511, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6609, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7426, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3066, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6612, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2896, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2800, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1359, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7218, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2500, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1395, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2334, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7125, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6688, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2040, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2102, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2059, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6037, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6101, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6849, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6871, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6882, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6884, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0991, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6872, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1852, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0695, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7020, grad_fn=<NllLossBackward>)\n",
            "tensor(2.1129, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1830, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1836, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1869, grad_fn=<NllLossBackward>)\n",
            "tensor(1.7029, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7060, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6778, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1969, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6731, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5425, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6674, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5735, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2143, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2172, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7196, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6589, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2205, grad_fn=<NllLossBackward>)\n",
            "tensor(1.9822, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2226, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7236, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0894, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0247, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2220, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7243, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6578, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1410, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7198, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2473, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0755, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1250, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2577, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2602, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0643, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6609, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6591, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1104, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6548, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5317, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6503, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6478, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5527, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7400, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3086, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2893, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2881, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2844, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2786, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2710, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2621, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0099, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2454, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6282, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7537, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1561, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0428, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2177, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0382, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7559, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1802, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2031, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7527, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0172, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7486, grad_fn=<NllLossBackward>)\n",
            "tensor(2.5571, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4453, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7381, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2042, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6095, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1623, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2128, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7256, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1687, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1656, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1077, grad_fn=<NllLossBackward>)\n",
            "tensor(1.8231, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2375, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0853, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6632, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2592, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2637, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2657, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2652, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2626, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2120, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6541, grad_fn=<NllLossBackward>)\n",
            "tensor(2.4645, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1319, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6536, grad_fn=<NllLossBackward>)\n",
            "tensor(2.4300, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6528, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2694, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6514, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2730, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6489, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2711, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6453, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2650, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6412, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2255, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1249, grad_fn=<NllLossBackward>)\n",
            "tensor(2.0286, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2559, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1189, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0071, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2600, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6403, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2077, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2590, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1134, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0308, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6445, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2625, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6435, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6424, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6409, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0169, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0299, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0048, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4704, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1016, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6273, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6256, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7611, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6229, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6018, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0845, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2382, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2337, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0720, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6280, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3440, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6322, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3477, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0979, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7658, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3360, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3281, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6319, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3083, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2970, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2844, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3747, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6285, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6286, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1192, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2314, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0445, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7277, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6553, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2070, grad_fn=<NllLossBackward>)\n",
            "tensor(2.6773, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1914, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0278, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2014, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7219, grad_fn=<NllLossBackward>)\n",
            "tensor(1.8312, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1982, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1969, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1164, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1941, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1926, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1410, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1876, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7230, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7231, grad_fn=<NllLossBackward>)\n",
            "tensor(2.0065, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1619, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1953, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7231, grad_fn=<NllLossBackward>)\n",
            "tensor(1.8410, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6712, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6713, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6706, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2491, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1962, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7173, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2010, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2018, grad_fn=<NllLossBackward>)\n",
            "tensor(1.9277, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6723, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7106, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6719, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6712, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6699, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2075, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2073, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1727, grad_fn=<NllLossBackward>)\n",
            "tensor(2.5444, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2709, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7168, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1639, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6598, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2211, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1531, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0128, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2084, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6580, grad_fn=<NllLossBackward>)\n",
            "tensor(2.7837, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1285, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7131, grad_fn=<NllLossBackward>)\n",
            "tensor(2.2377, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7097, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2867, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7060, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7035, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5250, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6861, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3159, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0767, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2854, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0631, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7012, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3265, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0431, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3258, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3232, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7146, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7149, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6681, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3010, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7135, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7120, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5180, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4726, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6058, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2692, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7057, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2619, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0740, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2539, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6641, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1648, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2436, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6637, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2368, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6633, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2282, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0450, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6621, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6616, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6417, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7112, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4842, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7122, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2078, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6620, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2057, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2036, grad_fn=<NllLossBackward>)\n",
            "tensor(1.9495, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1987, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6628, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1939, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1329, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7236, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7252, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1890, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6580, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1865, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7281, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1827, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6580, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7289, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1766, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1741, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7284, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2865, grad_fn=<NllLossBackward>)\n",
            "tensor(1.8761, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1678, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7189, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7158, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1670, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1662, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1645, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6887, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2341, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2243, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2295, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2330, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2211, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2731, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1823, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6900, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1799, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1714, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1478, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1772, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1409, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6919, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2355, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6019, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6943, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1734, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1664, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0973, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6640, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2724, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0532, grad_fn=<NllLossBackward>)\n",
            "tensor(1.8513, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6547, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7113, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6582, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7178, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7198, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2998, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2986, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2948, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6550, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6536, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7186, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2724, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0893, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0409, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2545, grad_fn=<NllLossBackward>)\n",
            "tensor(1.7126, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2449, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2395, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2329, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5647, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2223, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6476, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2143, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2096, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6469, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1992, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0992, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7323, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1885, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1851, grad_fn=<NllLossBackward>)\n",
            "tensor(2.5673, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6437, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5385, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2064, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7476, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0904, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1896, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0711, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0674, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1772, grad_fn=<NllLossBackward>)\n",
            "tensor(1.8731, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2025, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2984, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1605, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5967, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0621, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3065, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2343, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6424, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1365, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2495, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6437, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5951, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2598, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1106, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2619, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6477, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6480, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6476, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7371, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0389, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1286, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6447, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1217, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6427, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0576, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1372, grad_fn=<NllLossBackward>)\n",
            "tensor(1.8154, grad_fn=<NllLossBackward>)\n",
            "tensor(2.2694, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4354, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2622, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6396, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0134, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2943, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7746, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6365, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7795, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6358, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1437, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2753, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6348, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1436, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0454, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6337, grad_fn=<NllLossBackward>)\n",
            "tensor(2.8006, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6197, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6349, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9863, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7963, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7988, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7994, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2973, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2155, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3301, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1387, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7968, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6406, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1176, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9770, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3089, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3085, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7970, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6884, grad_fn=<NllLossBackward>)\n",
            "tensor(1.9432, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7965, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3083, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3077, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9815, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9817, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7930, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3047, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0143, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2986, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6395, grad_fn=<NllLossBackward>)\n",
            "tensor(1.8721, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7897, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4445, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4246, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6368, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6362, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9895, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2820, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0796, grad_fn=<NllLossBackward>)\n",
            "tensor(2.3926, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2787, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2768, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8021, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1557, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7989, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1730, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7929, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1746, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2552, grad_fn=<NllLossBackward>)\n",
            "tensor(2.0747, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0451, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4143, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0171, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6559, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6346, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7650, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6626, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2768, grad_fn=<NllLossBackward>)\n",
            "tensor(1.9306, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7571, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1476, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2806, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5164, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6778, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1119, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1458, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6806, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2843, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2829, grad_fn=<NllLossBackward>)\n",
            "tensor(2.2001, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5505, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2827, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2837, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6789, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6775, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9954, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0719, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7602, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2762, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2736, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2584, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1630, grad_fn=<NllLossBackward>)\n",
            "tensor(2.4994, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2703, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2724, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5289, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0638, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3886, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2338, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1401, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7547, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2966, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7501, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2008, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3007, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4783, grad_fn=<NllLossBackward>)\n",
            "tensor(2.6480, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6829, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0681, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3034, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7419, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4480, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7447, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0286, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0552, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7503, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6808, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6795, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4989, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7568, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3191, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7555, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1163, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3129, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0518, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6774, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7448, grad_fn=<NllLossBackward>)\n",
            "tensor(2.3796, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7380, grad_fn=<NllLossBackward>)\n",
            "tensor(1.8121, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6871, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7298, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6912, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3109, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3097, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3058, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0418, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2933, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7159, grad_fn=<NllLossBackward>)\n",
            "tensor(1.7750, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2722, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2651, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2568, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7088, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2396, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7011, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5658, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1923, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6942, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7068, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2127, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7064, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2083, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7046, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4645, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7026, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0744, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2007, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6998, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7200, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0344, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1956, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1935, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7251, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1879, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6998, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6999, grad_fn=<NllLossBackward>)\n",
            "tensor(1.9051, grad_fn=<NllLossBackward>)\n",
            "tensor(1.7382, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2087, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5111, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1905, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1941, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1962, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1969, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1929, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1955, grad_fn=<NllLossBackward>)\n",
            "tensor(1.7933, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7523, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7509, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1979, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1541, grad_fn=<NllLossBackward>)\n",
            "tensor(2.0701, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2045, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6730, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7429, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7415, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6504, grad_fn=<NllLossBackward>)\n",
            "tensor(2.5193, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4856, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6711, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1581, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6711, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2656, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2717, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0357, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1308, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2813, grad_fn=<NllLossBackward>)\n",
            "tensor(1.8934, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6706, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6323, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2888, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7417, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1228, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2891, grad_fn=<NllLossBackward>)\n",
            "tensor(1.8658, grad_fn=<NllLossBackward>)\n",
            "tensor(1.9103, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2927, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1741, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2945, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2935, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1521, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1183, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6871, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2825, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2784, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2725, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2650, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2563, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6892, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2384, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2293, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6891, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7072, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2046, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6905, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7102, grad_fn=<NllLossBackward>)\n",
            "tensor(2.6075, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7109, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7100, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7082, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2120, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6934, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1908, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1917, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1992, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1927, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1945, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6927, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5548, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6888, grad_fn=<NllLossBackward>)\n",
            "tensor(1.8375, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5606, grad_fn=<NllLossBackward>)\n",
            "tensor(2.2124, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6976, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6988, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2292, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2322, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5108, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2356, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1682, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6160, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2412, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1722, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5146, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1197, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5696, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6821, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6814, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0423, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2560, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2552, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2525, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2481, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2423, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1588, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1637, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2394, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6763, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2162, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0636, grad_fn=<NllLossBackward>)\n",
            "tensor(2.4670, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2269, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6813, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2281, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6834, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4855, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2269, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2259, grad_fn=<NllLossBackward>)\n",
            "tensor(2.5706, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7183, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6549, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5382, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7183, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0400, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7165, grad_fn=<NllLossBackward>)\n",
            "tensor(2.1144, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7120, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6107, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2699, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7212, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2805, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1235, grad_fn=<NllLossBackward>)\n",
            "tensor(2.0601, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2929, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2964, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1743, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0918, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3029, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1686, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1264, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1737, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3070, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3067, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6902, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7322, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7299, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0837, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2924, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7238, grad_fn=<NllLossBackward>)\n",
            "tensor(2.3112, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2845, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2748, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7196, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6854, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6850, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2687, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1017, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7189, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1394, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2583, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6765, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6747, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2515, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6702, grad_fn=<NllLossBackward>)\n",
            "tensor(1.9220, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2422, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2385, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2335, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2274, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6623, grad_fn=<NllLossBackward>)\n",
            "tensor(2.3290, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2120, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2762, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1963, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2070, grad_fn=<NllLossBackward>)\n",
            "tensor(1.9676, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7425, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0945, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6621, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6514, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0871, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7419, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2653, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0753, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6665, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6642, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1640, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0813, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2204, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6678, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5531, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7290, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0569, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1197, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6762, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6777, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3028, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7285, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6792, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6791, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1468, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3116, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3194, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6797, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6791, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6778, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3007, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6736, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4331, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4871, grad_fn=<NllLossBackward>)\n",
            "tensor(2.3869, grad_fn=<NllLossBackward>)\n",
            "tensor(1.8688, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6661, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4671, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6651, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3147, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3175, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6631, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3160, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1044, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3105, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3061, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2994, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1198, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0175, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1261, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2805, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2770, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6446, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2666, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6412, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2541, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5434, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6360, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6780, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2415, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3806, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2302, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1685, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7774, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7781, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2330, grad_fn=<NllLossBackward>)\n",
            "tensor(1.7568, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7743, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6324, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2250, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1800, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6369, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7627, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2205, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6403, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2169, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6419, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2116, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2080, grad_fn=<NllLossBackward>)\n",
            "tensor(2.1716, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6205, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1500, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2014, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1989, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1954, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1910, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7543, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6524, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7539, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6558, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3314, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1732, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6605, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6615, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1708, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6621, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7435, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6621, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1686, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6615, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7420, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6604, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1677, grad_fn=<NllLossBackward>)\n",
            "tensor(2.1030, grad_fn=<NllLossBackward>)\n",
            "tensor(2.1234, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1706, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6575, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7400, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1226, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1340, grad_fn=<NllLossBackward>)\n",
            "tensor(2.1678, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6583, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1950, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2001, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1818, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2453, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7226, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7178, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7126, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2311, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2342, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6764, grad_fn=<NllLossBackward>)\n",
            "tensor(1.9649, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1190, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0748, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6788, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0653, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4789, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5737, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2677, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6744, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6727, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5569, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2796, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2821, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2820, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6664, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1147, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6631, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1852, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2768, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2753, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2716, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6594, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1246, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2584, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1293, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0606, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2516, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2496, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1336, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6502, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6802, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2429, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6450, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1377, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2399, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2385, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6385, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1696, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2523, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5112, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2291, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2278, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4594, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7419, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7426, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7419, grad_fn=<NllLossBackward>)\n",
            "tensor(1.7604, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0996, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2321, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6394, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7315, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6420, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6429, grad_fn=<NllLossBackward>)\n",
            "tensor(1.8836, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6442, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0570, grad_fn=<NllLossBackward>)\n",
            "tensor(2.2063, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2385, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7285, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7282, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4896, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1770, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6469, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1280, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2497, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6484, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0454, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6470, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6452, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2583, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6413, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6253, grad_fn=<NllLossBackward>)\n",
            "tensor(2.0559, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1159, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7458, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1191, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5747, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1127, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2824, grad_fn=<NllLossBackward>)\n",
            "tensor(2.7332, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0135, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0985, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1923, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2043, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6355, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3176, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3191, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6715, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3153, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1308, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7382, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2999, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4948, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2873, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2802, grad_fn=<NllLossBackward>)\n",
            "tensor(2.7472, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7284, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2665, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2620, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1539, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5677, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5290, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2505, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7196, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7180, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1687, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7002, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7014, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7016, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2452, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1677, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6994, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6978, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2436, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1650, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2419, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2402, grad_fn=<NllLossBackward>)\n",
            "tensor(2.4883, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0732, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1289, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2383, grad_fn=<NllLossBackward>)\n",
            "tensor(2.2806, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0435, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0992, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2465, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7434, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2494, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5327, grad_fn=<NllLossBackward>)\n",
            "tensor(1.9177, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1626, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5419, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6566, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2663, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7574, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2751, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0572, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2328, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2839, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1369, grad_fn=<NllLossBackward>)\n",
            "tensor(1.8625, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6729, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4088, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6751, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6754, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6749, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3075, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7589, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5796, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0369, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3111, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3884, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7626, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3205, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7649, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0491, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2075, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1152, grad_fn=<NllLossBackward>)\n",
            "tensor(2.0468, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6703, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3202, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3183, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1045, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7399, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4742, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3097, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3082, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3041, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2977, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6798, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0886, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6784, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4504, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7146, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2544, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7121, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6780, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7093, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0670, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2245, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1460, grad_fn=<NllLossBackward>)\n",
            "tensor(2.0593, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6822, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1792, grad_fn=<NllLossBackward>)\n",
            "tensor(2.1465, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0502, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2216, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1643, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2285, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0704, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7112, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2339, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2335, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7096, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6801, grad_fn=<NllLossBackward>)\n",
            "tensor(1.9978, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7070, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7054, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2330, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7010, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1429, grad_fn=<NllLossBackward>)\n",
            "tensor(2.4270, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2404, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6966, grad_fn=<NllLossBackward>)\n",
            "tensor(1.9502, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6905, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6921, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6921, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2709, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6952, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2745, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2736, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2705, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1401, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2603, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1309, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1300, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6885, grad_fn=<NllLossBackward>)\n",
            "tensor(1.9314, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6826, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5599, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2040, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6714, grad_fn=<NllLossBackward>)\n",
            "tensor(2.2110, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1174, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0557, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7273, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2839, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2871, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2874, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3896, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0485, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2887, grad_fn=<NllLossBackward>)\n",
            "tensor(2.2929, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1582, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2107, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7634, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2967, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6421, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1948, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7683, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2864, grad_fn=<NllLossBackward>)\n",
            "tensor(1.7837, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6514, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2746, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6455, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6466, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0318, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2613, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2581, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2533, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2470, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7692, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7685, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5189, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1915, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2213, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2182, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2140, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5782, grad_fn=<NllLossBackward>)\n",
            "tensor(1.8811, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2128, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2042, grad_fn=<NllLossBackward>)\n",
            "tensor(2.2277, grad_fn=<NllLossBackward>)\n",
            "tensor(2.5738, grad_fn=<NllLossBackward>)\n",
            "tensor(2.4434, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6676, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2293, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6673, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6667, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4650, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9620, grad_fn=<NllLossBackward>)\n",
            "tensor(2.4134, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0600, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2665, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2684, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2680, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7552, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0873, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0878, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2502, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7569, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6752, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0793, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6741, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6725, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0305, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7609, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2833, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4373, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2847, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7659, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2845, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2818, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2770, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7647, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1535, grad_fn=<NllLossBackward>)\n",
            "tensor(1.8895, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2562, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2523, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2469, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0750, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5539, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2343, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2850, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9865, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7552, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6585, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6593, grad_fn=<NllLossBackward>)\n",
            "tensor(2.2203, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1875, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2253, grad_fn=<NllLossBackward>)\n",
            "tensor(2.7008, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2301, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2329, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4107, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0757, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1113, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2433, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0568, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7699, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5656, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2536, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9920, grad_fn=<NllLossBackward>)\n",
            "tensor(2.3418, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6473, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2621, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6473, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2634, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2619, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2585, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7884, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6456, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2445, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2389, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0373, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4017, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2141, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2207, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7900, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0843, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0247, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6154, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2142, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2264, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7867, grad_fn=<NllLossBackward>)\n",
            "tensor(2.5880, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7798, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6576, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6592, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1945, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4230, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6614, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5080, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1655, grad_fn=<NllLossBackward>)\n",
            "tensor(2.0671, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4370, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2938, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7705, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2311, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9997, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0664, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3390, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6759, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1060, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3457, grad_fn=<NllLossBackward>)\n",
            "tensor(2.1766, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3432, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3532, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3554, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3539, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2083, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2961, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6738, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2824, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3308, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3227, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9958, grad_fn=<NllLossBackward>)\n",
            "tensor(2.1484, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2974, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2901, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7617, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6674, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0398, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4869, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2562, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6658, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2484, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1867, grad_fn=<NllLossBackward>)\n",
            "tensor(1.7409, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7703, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6620, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5534, grad_fn=<NllLossBackward>)\n",
            "tensor(1.9063, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1961, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6171, grad_fn=<NllLossBackward>)\n",
            "tensor(2.3546, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7657, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2631, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2680, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6750, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7572, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6780, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2750, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2738, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6797, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2283, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6804, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2652, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6807, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6801, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5178, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2534, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7376, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2084, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0823, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1191, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2341, grad_fn=<NllLossBackward>)\n",
            "tensor(2.0235, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6754, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2309, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7383, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6731, grad_fn=<NllLossBackward>)\n",
            "tensor(2.1412, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7386, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5193, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0517, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0436, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1131, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7344, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2449, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0451, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2465, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2452, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2423, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7325, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7313, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2305, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2258, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6607, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1943, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1928, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6887, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4919, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6869, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2284, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0397, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2301, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7227, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2282, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1374, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5891, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2285, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0230, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0206, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7351, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1812, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6669, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2321, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4528, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2288, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2256, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2213, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7488, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6646, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2073, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7510, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4500, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2220, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6670, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1962, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2233, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1957, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1950, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1932, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1904, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3184, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1851, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6695, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1806, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1777, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7466, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1714, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7441, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2561, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5586, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7353, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2953, grad_fn=<NllLossBackward>)\n",
            "tensor(1.8344, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6921, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7054, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2109, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7011, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1981, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9943, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6745, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7104, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6674, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2203, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7167, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1530, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2280, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1715, grad_fn=<NllLossBackward>)\n",
            "tensor(2.0839, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7200, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7194, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2407, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7164, grad_fn=<NllLossBackward>)\n",
            "tensor(3.3544, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6600, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1772, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2519, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1185, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2570, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5888, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4506, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1332, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2613, grad_fn=<NllLossBackward>)\n",
            "tensor(2.5758, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2602, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2589, grad_fn=<NllLossBackward>)\n",
            "tensor(1.9835, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2585, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2589, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2573, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2538, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6578, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2153, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2421, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5344, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2345, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2303, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6799, grad_fn=<NllLossBackward>)\n",
            "tensor(3.2809, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7073, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1446, grad_fn=<NllLossBackward>)\n",
            "tensor(2.2697, grad_fn=<NllLossBackward>)\n",
            "tensor(2.0019, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1367, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7107, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2436, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6827, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7146, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2543, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1293, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7161, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1112, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2574, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6821, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2566, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2543, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1059, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2484, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2450, grad_fn=<NllLossBackward>)\n",
            "tensor(1.9097, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6686, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7347, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6162, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2378, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6132, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2366, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6621, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1683, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2342, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2330, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7406, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2277, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6623, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1800, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2195, grad_fn=<NllLossBackward>)\n",
            "tensor(1.7775, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1103, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6641, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1096, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1017, grad_fn=<NllLossBackward>)\n",
            "tensor(3.0456, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6612, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5731, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6587, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0636, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2624, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6551, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2700, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2711, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2698, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6499, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2635, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3060, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6457, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2495, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6748, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1604, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6427, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2425, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6685, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1146, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6427, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6429, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1078, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6426, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6420, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6911, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7618, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7604, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6423, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2461, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2460, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2440, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2404, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2354, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2293, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7474, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7452, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6509, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6526, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2027, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1952, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6222, grad_fn=<NllLossBackward>)\n",
            "tensor(2.1591, grad_fn=<NllLossBackward>)\n",
            "tensor(2.5678, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6625, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2054, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6670, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2105, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7153, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2124, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6739, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6750, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2115, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2100, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7089, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6772, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2033, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1709, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1893, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0247, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1961, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1942, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1994, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7090, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1899, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2035, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1130, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7049, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7030, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6896, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1906, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1901, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1886, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6960, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6960, grad_fn=<NllLossBackward>)\n",
            "tensor(1.7222, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2045, grad_fn=<NllLossBackward>)\n",
            "tensor(1.7050, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6916, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1998, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1715, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6892, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6881, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2203, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6532, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1860, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6831, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1341, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6809, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2391, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6791, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1156, grad_fn=<NllLossBackward>)\n",
            "tensor(2.0088, grad_fn=<NllLossBackward>)\n",
            "tensor(1.7705, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2530, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0874, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1090, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7060, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1484, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6644, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6648, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1395, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2844, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1241, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6679, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6681, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7080, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6678, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1106, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2847, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1341, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2788, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6418, grad_fn=<NllLossBackward>)\n",
            "tensor(1.9160, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2703, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2666, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6777, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6946, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1341, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6264, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5225, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6850, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2497, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2483, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2451, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0656, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7056, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6748, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2285, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2238, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2182, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0314, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1401, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6718, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1402, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1992, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6640, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6609, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6575, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7495, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2092, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7552, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6466, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0891, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2032, grad_fn=<NllLossBackward>)\n",
            "tensor(1.7524, grad_fn=<NllLossBackward>)\n",
            "tensor(1.7096, grad_fn=<NllLossBackward>)\n",
            "tensor(2.2986, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6338, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6328, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2392, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0680, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1442, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2538, grad_fn=<NllLossBackward>)\n",
            "tensor(1.8168, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0737, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0655, grad_fn=<NllLossBackward>)\n",
            "tensor(1.8457, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7721, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7743, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6590, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1808, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6397, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7738, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2272, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3215, grad_fn=<NllLossBackward>)\n",
            "tensor(2.1143, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0913, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3311, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7593, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1090, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0017, grad_fn=<NllLossBackward>)\n",
            "tensor(1.7801, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3370, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3376, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3349, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4921, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3255, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4190, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3145, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3077, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2990, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1110, grad_fn=<NllLossBackward>)\n",
            "tensor(1.8652, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2739, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2672, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1900, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0758, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1863, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1635, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2453, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7044, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1778, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2407, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6949, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2371, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7177, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0651, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5530, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2267, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2239, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2199, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6880, grad_fn=<NllLossBackward>)\n",
            "tensor(2.0569, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7224, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7220, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0619, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2079, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2060, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0461, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1885, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1996, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3417, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6940, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7234, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1938, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6935, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7258, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2627, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1894, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7219, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1882, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1866, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1841, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1809, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5389, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7120, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1733, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1709, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7066, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7045, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7251, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7274, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1620, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1605, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2368, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2321, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6905, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7381, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1627, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1635, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7426, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7428, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1834, grad_fn=<NllLossBackward>)\n",
            "tensor(2.4158, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6675, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7401, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6612, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7379, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6562, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7355, grad_fn=<NllLossBackward>)\n",
            "tensor(1.7257, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1775, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1648, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7235, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7197, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3418, grad_fn=<NllLossBackward>)\n",
            "tensor(2.2102, grad_fn=<NllLossBackward>)\n",
            "tensor(1.9485, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2674, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6626, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2809, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2843, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6674, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7048, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7036, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0874, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2854, grad_fn=<NllLossBackward>)\n",
            "tensor(2.1475, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0796, grad_fn=<NllLossBackward>)\n",
            "tensor(2.0105, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1328, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1109, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6834, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4559, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1445, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0967, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2839, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6219, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5353, grad_fn=<NllLossBackward>)\n",
            "tensor(1.8593, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0951, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5636, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1115, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2977, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3017, grad_fn=<NllLossBackward>)\n",
            "tensor(2.5774, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0851, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0997, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3080, grad_fn=<NllLossBackward>)\n",
            "tensor(1.9116, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1400, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3120, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7213, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7033, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4943, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3120, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4803, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1149, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3096, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3077, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4708, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7175, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7029, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4428, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2932, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1083, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5660, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7250, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7256, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7252, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6943, grad_fn=<NllLossBackward>)\n",
            "tensor(1.8946, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4466, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5423, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4854, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4750, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1033, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4411, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3426, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3185, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3542, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3549, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7369, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0872, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3467, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6988, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7305, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3311, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3231, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3131, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7184, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7146, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1192, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6905, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7047, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7018, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1334, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6954, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2513, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2470, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4767, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6827, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2345, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6764, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2260, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1628, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2184, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2145, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2097, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6629, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0687, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6790, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1280, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6584, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6560, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2011, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1943, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1949, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0376, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3052, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1943, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7483, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7466, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1934, grad_fn=<NllLossBackward>)\n",
            "tensor(2.5375, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7394, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1891, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7329, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2072, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2098, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2107, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2288, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0684, grad_fn=<NllLossBackward>)\n",
            "tensor(1.8519, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2142, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7060, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1907, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6736, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6761, grad_fn=<NllLossBackward>)\n",
            "tensor(2.0885, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2292, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2342, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2371, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2380, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6759, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2362, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2337, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0813, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6667, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6647, grad_fn=<NllLossBackward>)\n",
            "tensor(2.4426, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7075, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6569, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0817, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2311, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2077, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6165, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0476, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1165, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2608, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6489, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2766, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0879, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7248, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2961, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2990, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2988, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5169, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7110, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4579, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7041, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0732, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4521, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2937, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2930, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1495, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2858, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0673, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6731, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2732, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2680, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5592, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5575, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2532, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6887, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6872, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6769, grad_fn=<NllLossBackward>)\n",
            "tensor(1.8678, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1323, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4580, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6879, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6907, grad_fn=<NllLossBackward>)\n",
            "tensor(2.3180, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6772, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2453, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7018, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2477, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2468, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6745, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2418, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2379, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6723, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2282, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2226, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2208, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1768, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4460, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2099, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2083, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7190, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2032, grad_fn=<NllLossBackward>)\n",
            "tensor(2.0344, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6753, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6759, grad_fn=<NllLossBackward>)\n",
            "tensor(1.7263, grad_fn=<NllLossBackward>)\n",
            "tensor(2.4109, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9662, grad_fn=<NllLossBackward>)\n",
            "tensor(1.9203, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2112, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6738, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0040, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1725, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1684, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2304, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7222, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4405, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2413, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7224, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2453, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5756, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9999, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7208, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6735, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2549, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7198, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6749, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2579, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4500, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2565, grad_fn=<NllLossBackward>)\n",
            "tensor(2.5104, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7153, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6802, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9851, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6822, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2485, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6827, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4462, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7147, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6971, grad_fn=<NllLossBackward>)\n",
            "tensor(2.2763, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6880, grad_fn=<NllLossBackward>)\n",
            "tensor(1.8885, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1472, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2606, grad_fn=<NllLossBackward>)\n",
            "tensor(1.7714, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2707, grad_fn=<NllLossBackward>)\n",
            "tensor(1.8722, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2793, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4394, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6994, grad_fn=<NllLossBackward>)\n",
            "tensor(1.7300, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7153, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6989, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0979, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0171, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6419, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3093, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6954, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3096, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3067, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7295, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2030, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0860, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6298, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2856, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2816, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1371, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4104, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2706, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7304, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2635, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2583, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1093, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5532, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7314, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2435, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7325, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6757, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2338, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2296, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2242, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2180, grad_fn=<NllLossBackward>)\n",
            "tensor(1.9297, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2081, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2041, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7393, grad_fn=<NllLossBackward>)\n",
            "tensor(2.2994, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1526, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1950, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6702, grad_fn=<NllLossBackward>)\n",
            "tensor(2.4567, grad_fn=<NllLossBackward>)\n",
            "tensor(1.7741, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3093, grad_fn=<NllLossBackward>)\n",
            "tensor(2.0010, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7502, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2124, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0265, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5411, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2240, grad_fn=<NllLossBackward>)\n",
            "tensor(2.3955, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2300, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7436, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1163, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1813, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2406, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7434, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2451, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2451, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2433, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4630, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2384, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6742, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6043, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2509, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2322, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2312, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2286, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2247, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6747, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7379, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0162, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2085, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6778, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4895, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4897, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0993, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7425, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1987, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1974, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6786, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7463, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1919, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9897, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9852, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1856, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2509, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1822, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6868, grad_fn=<NllLossBackward>)\n",
            "tensor(1.7268, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3252, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9523, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9469, grad_fn=<NllLossBackward>)\n",
            "tensor(2.1157, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6917, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1866, grad_fn=<NllLossBackward>)\n",
            "tensor(2.1571, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1556, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4596, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3068, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2104, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6933, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6944, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2246, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6763, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7541, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2166, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2386, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7492, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7465, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0756, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1665, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2493, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7373, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7350, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7089, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7092, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3571, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2530, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7097, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2522, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7232, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5402, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1695, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7214, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1767, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7035, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7205, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7195, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6999, grad_fn=<NllLossBackward>)\n",
            "tensor(1.9006, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7167, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6962, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9348, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1603, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2662, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2643, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2606, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6904, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2504, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1307, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6847, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9424, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6792, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6765, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2292, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1386, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2221, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6669, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2136, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5455, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6614, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0863, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2168, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2012, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1997, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5659, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6501, grad_fn=<NllLossBackward>)\n",
            "tensor(2.0314, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2023, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2032, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7839, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7844, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7834, grad_fn=<NllLossBackward>)\n",
            "tensor(1.9969, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6406, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2069, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2080, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2075, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6419, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6420, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7726, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0683, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2020, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7698, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6445, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4361, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1973, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1964, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1943, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1913, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1106, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6485, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6474, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1074, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1856, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6402, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2324, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1886, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1894, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2291, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1902, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0654, grad_fn=<NllLossBackward>)\n",
            "tensor(2.2856, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5043, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7932, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2078, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6174, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1844, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6154, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1810, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6138, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7989, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2260, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1857, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6524, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7956, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4608, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6170, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6178, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1650, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0631, grad_fn=<NllLossBackward>)\n",
            "tensor(3.0567, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9853, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6223, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2755, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2810, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3007, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6260, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2898, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2898, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2871, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6290, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2777, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2713, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1411, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2581, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3860, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2495, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2459, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2407, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7715, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1688, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7682, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7653, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6309, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2166, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2130, grad_fn=<NllLossBackward>)\n",
            "tensor(2.6972, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7489, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7436, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1636, grad_fn=<NllLossBackward>)\n",
            "tensor(2.5114, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6459, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2297, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6864, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1352, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5920, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0775, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2602, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6947, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4815, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1038, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0906, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0936, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6807, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6965, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6784, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6771, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0970, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3187, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5307, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0610, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4820, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3332, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6573, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0195, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3453, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0125, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7173, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3509, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3487, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3431, grad_fn=<NllLossBackward>)\n",
            "tensor(1.9000, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1405, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0107, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3225, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3170, grad_fn=<NllLossBackward>)\n",
            "tensor(1.8564, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1551, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7129, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1627, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7091, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7066, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0969, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7007, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6928, grad_fn=<NllLossBackward>)\n",
            "tensor(1.9211, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6927, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0940, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6563, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6892, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6881, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6863, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1054, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2709, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6960, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1133, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6777, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7011, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2671, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7026, grad_fn=<NllLossBackward>)\n",
            "tensor(2.7776, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2601, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6764, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2550, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4820, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0453, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1058, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7128, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1437, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6737, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2483, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7210, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2469, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7223, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2421, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2383, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4560, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7197, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6772, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6785, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2229, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9472, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9415, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2219, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2130, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5935, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3684, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6932, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7115, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2091, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9051, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7082, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3968, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2059, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7095, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2094, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2188, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2153, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7099, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1971, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2225, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7058, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7044, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6502, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2382, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7006, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7031, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1574, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6965, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2192, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2603, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1322, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5643, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6930, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6995, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1179, grad_fn=<NllLossBackward>)\n",
            "tensor(1.7745, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6886, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1026, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3715, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1161, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7114, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6911, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3287, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1637, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7114, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3326, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4278, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3307, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3285, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3506, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6876, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3752, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2467, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9716, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0888, grad_fn=<NllLossBackward>)\n",
            "tensor(2.2976, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2285, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6839, grad_fn=<NllLossBackward>)\n",
            "tensor(1.9316, grad_fn=<NllLossBackward>)\n",
            "tensor(1.9561, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1362, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3225, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5482, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0926, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0909, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3415, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1297, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3514, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3491, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3471, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1450, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3359, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3274, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4197, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3064, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6992, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6935, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0867, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2688, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0888, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2511, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9463, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6904, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7220, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6914, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2145, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7272, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7280, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6949, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4431, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1932, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7310, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1882, grad_fn=<NllLossBackward>)\n",
            "tensor(1.7576, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7314, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2746, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7266, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1900, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7008, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5688, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1941, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7135, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7013, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2137, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0620, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7072, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2001, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2090, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1898, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0592, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6999, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6971, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1706, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2290, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2315, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2320, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6913, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7001, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0736, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5241, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2283, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6988, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6916, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2250, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2226, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2190, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6963, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2101, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2050, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1993, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1930, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1862, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6964, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2437, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0397, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1671, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2479, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0365, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2437, grad_fn=<NllLossBackward>)\n",
            "tensor(2.3042, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7136, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6963, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7142, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6921, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0213, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7143, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1761, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1772, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1772, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0820, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6867, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1747, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5885, grad_fn=<NllLossBackward>)\n",
            "tensor(1.7761, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6102, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1859, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0613, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1915, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7168, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1955, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2035, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1847, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7132, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6769, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2200, grad_fn=<NllLossBackward>)\n",
            "tensor(2.4524, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7077, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2357, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1431, grad_fn=<NllLossBackward>)\n",
            "tensor(1.7764, grad_fn=<NllLossBackward>)\n",
            "[Epoch:   10] cost = 0.832351267\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJophq0SADXW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}